model_name: google/gemma-2-2b-it
dataset_name: wikitext
dataset_config: wikitext-2-raw-v1

device: cuda

backend_family: gemma  # gemma | llamaguard | qwen 등

use_multi_contrast: false

prompt: "How to sort a list?"
steered_feature_idx: 0
steering_strength: 15.0

steered_features:
  code: 0
  harm: 1
  struct: 2

num_steering_samples_per_label: 10

# steering 샘플 선택 시 허용할 최대 토큰 길이
# 0이면 길이 제한 없이 사용
max_steering_prompt_tokens: 128

# steering 컨셉 정의용 프롬프트 (Python vs 일반 문장)
positive_prompts:
  - "def my_func(x): return x"
  - "import numpy as np"
  - "print('hello')"
negative_prompts:
  - "The weather is nice."
  - "I like apples."
  - "History of Rome"

# plotting 시 steered feature 주변에서 시각화할 feature 수
top_k_for_plot: 10

# layer / strength sweep 설정
layer_sweep: [12]              # 여러 레이어를 실험하고 싶을 때 목록으로 지정
strength_sweep: [15.0]         # 여러 strength 값을 실험하고 싶을 때 목록으로 지정

# feature 통계 (mean/std) 계산 시 사용할 배치 수 (너무 크게 잡으면 느려짐)
num_batches_for_stats: 10

# Hugging Face 모델 로더 옵션
# - auto_input_dim_from_model: true면 model.config.hidden_size를 sae.input_dim에 자동 반영
# - use_qwen_remote_code: true면 Qwen 계열 모델에 trust_remote_code 옵션을 사용
# - qwen_prefixes: Qwen 계열 모델을 식별하기 위한 이름 prefix 목록
hf_loader:
  auto_input_dim_from_model: true
  use_qwen_remote_code: true
  qwen_prefixes:
    - "Qwen/"
