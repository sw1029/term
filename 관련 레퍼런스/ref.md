마크다운 형식으로 레퍼런스 논문 혹은 근거의 출처를 간략하게 기입 부탁드립니다.

LLM 모델의 성능   
[1] A Survey of Large Language Models, 2023. --> [link](https://arxiv.org/html/2303.18223v16)  

모델의 행동 제어 조정 능력의 필요성  
[2] Constitutional AI: Harmlessness from AI Feedback, NeurIPS 2023. --> [link](https://arxiv.org/abs/2212.08073)

Prompting 기반 접근의 취약성
[3] Red Teaming Language Models, ACL 2023.  --> [link](https://arxiv.org/abs/2202.03286)  

Fine-tuning 기반 접근의 비용 
[4] LoRA: Low-Rank Adaptation of LLMs, ICLR 2022. --> [link](https://arxiv.org/abs/2106.09685)  

SAE
[5] Anthropic SAE (Sparse Autoencoder) --> [link](https://transformer-circuits.pub/2024/scaling-monosemanticity/) 
