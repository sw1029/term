{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "main.py sae.loss_option=3 sae.loss_module=option3_loss experiment.use_multi_contrast=true",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 0,
    "batch_size": 4,
    "epochs": 2,
    "max_steps": 3000,
    "concept_samples_per_label": 250,
    "loss_option": 3,
    "loss_module": "option3_loss"
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "steering": {
    "label": "harm",
    "feature_idx": 1,
    "strength": 15.0
  },
  "prompt": "# A script to help doing the deliveries.\n# Now using the Casava directory structure\n# The user is asked to provide a project ID, a run name, and an UPPMAX project\n\nimport sys\nimport os\nimport glob\nimport re\nimport grp\nfrom datetime import datetime\nimport argparse\nimport stat\nfrom subprocess import check_call, CalledProcessError\nfrom scilifelab.utils.misc import filtered_walk, query_yes_no, touch_file\nfrom scilifelab.utils.timestamp import utc_time\n\ndef fixProjName(pname):\n    newname = pname[0].upper()\n    postperiod = False\n    for i in range(1, len(pname)):\n        if pname[i] == \".\": \n            newname += pname[i]\n            postperiod = True\n        elif postperiod: \n            newname += pname[i].upper()\n            postperiod = False\n        else:\n            newname += pname[i]\n            postperiod = False\n    return newname\n            \ndef is_fastq(fname):\n    fastq_ext = [\".fastq.gz\",\n                 \".fastq\",\n                 \"_fastq.txt.gz\",\n                 \"_fastq.txt\",\n                 \".fastq..gz\",\n                 \"_fastq.txt..gz\"\n                 ]\n    for ext in fastq_ext:\n        if fname.endswith(ext):\n            return True\n    return False\n\n  \ndef create_final_name(fname, date, fc_id, sample_name):\n    \"\"\"Create the final name of the delivered file\n    \"\"\"\n    \n     # Split the file name according to CASAVA convention\n    m = re.match(r'(\\S+?)_(?:[ACGTN\\-]+|NoIndex|Undetermined)_L0*(\\d+)_R(\\d)_\\d+\\.fastq(.*)', fname)\n    if m is not None:\n        lane = m.group(2)\n        read = m.group(3)\n        ext = m.group(4)\n    else:\n        # Split the file name according to bcbb convention\n        m = re.match(r'(\\d+)_(\\d+)_([^_]+)_(\\d+)_(?:nophix_)?(\\d+)_fastq.txt(.*)', fname)\n        if m is None:\n            raise ValueError(\"Could not parse file name {:s} correctly!\".format(fname))\n        lane = m.group(1)\n        read = m.group(5)\n        ext = m.group(6)\n            \n    dest_file_name = \"{:s}.fastq{:s}\".format(\"_\".join([lane,\n                                                       date,\n                                                       fc_id,\n                                                       sample_name,\n                                                       read]),\n                                             ext.replace('..','.'))\n    return dest_file_name\n      \ndef get_file_copy_list(proj_base_dir, dest_proj_path, fcid, deliver_all_fcs, deliver_nophix, skip_list):\n    to_copy = []\n    for fqfile in filtered_walk(proj_base_dir, \n                                is_fastq, \n                                include_dirs=[fcid] if not deliver_all_fcs else None, \n                                exclude_dirs=skip_list):\n        \n        # Get the run_name and sample_name from the path\n        sample_name, run_name, _ = os.path.relpath(fqfile,proj_base_dir).split(os.sep,2)\n        date, fc_id = run_name.split('_')\n            \n        # Skip if we deliver from nophix and the parent dir is not nophix (or vice versa)\n        pdir = os.path.basename(os.path.dirname(fqfile))\n        if deliver_nophix and pdir != \"nophix\":\n            continue\n        if not deliver_nophix and pdir != run_name:\n            continue\n        \n        # Skip if a compressed version of the current file exists\n        if os.path.exists(\"{:s}.gz\".format(fqfile)):\n            print(\"WARNING: Both compressed and non-compressed versions of {:s} exists! \" \\\n                  \"Is compression/decompression in progress? Will deliver compressed version \" \\\n                  \"but you should make sure that the delivered files are complete!\".format(fqfile))\n            continue\n        \n        print(\"DEBUG: source_delivery_path = {:s}\".format(os.path.dirname(fqfile)))\n        \n        fname = os.path.basename(fqfile)\n        print(fname)\n      \n        dest_run_path = os.path.join(dest_proj_path, sample_name, run_name)\n        dest_file_name = create_final_name(fname,date,fc_id,sample_name)\n        to_copy.append([fqfile,\n                        dest_run_path,\n                        dest_file_name])\n    return to_copy\n\ndef rsync_files(to_copy, logfile, group, dry):\n    # Iterate over the files to copy and create directories and copy files as necessary \n    successful = 0\n    uid = os.getuid()\n    gid = os.getgid()\n    if group is not None and len(group) > 0:\n        gid = grp.getgrnam(group).gr_gid\n    for src_file, dst_dir, dst_name in to_copy:\n        dst_file = os.path.join(dst_dir, dst_name)\n        print \"Will copy (rsync) \", src_file, \"to \", dst_file\n        if not dry:\n            \n            # Create the destination directory if necessary\n            logfile.write(\"[{:s}] - Creating run-level delivery directory: {:s} \" \\\n                          \"(or leaving it in place if already present)\\n\".format(utc_time(),\n                                                                                 dst_dir))\n            if os.path.exists(dst_dir):\n                print(\"Directory {:s} already exists!\".format(dst_dir))\n            else:\n                try:\n                    # Create directory hierarchy with ug+rwX permissions\n                    os.makedirs(dst_dir, 0770)\n                except:\n                    print(\"Could not create run-level delivery directory!\")\n                    clean_exit(1,logfile,dry)\n            \n            # Rsync the file across \n            command_to_execute = ['rsync',\n                                  '-ac',\n                                  src_file,\n                                  dst_file]\n            \n            logfile.write(\"[{:s}] - Executing command: {:s}\\n\".format(utc_time(), \" \".join(command_to_execute)))\n            logfile.flush()\n            try:\n                check_call(command_to_execute)\n            except CalledProcessError, e:\n                logfile.write(\"[{:s}] - rsync exited with exit code {:d}\\n\".format(utc_time(), e.returncode))\n                raise e\n            \n            logfile.write(\"[{:s}] - rsync exited with exit code 0\\n\".format(utc_time()))\n            successful += 1\n        \n            print(\"{:d} of {:d} files copied successfully\".format(successful,len(to_copy)))\n    \n            # Modify the permissions to ug+rw\n            os.chmod(dst_file, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP)\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"A script to help doing the deliveries, now using the Casava directory structure. \" \\\n                                     \"The user is asked to provide a project ID, a run name, and an UPPMAX project\")\n\n    parser.add_argument('-c', '--casava-path', action=\"store\", dest=\"caspath\", default='/proj/a2010002/nobackup/illumina/', \n                        help=\"Specify a path to a Casava directory manually\")\n    parser.add_argument('-l', '--log-path', action=\"store\", dest=\"logpath\", default='/proj/a2010002/private/delivery_logs', \n                        help=\"Specify a path to a log file\")\n    parser.add_argument('-i', '--interactive', action=\"store_true\", dest=\"interactive\", default=False, \n                        help=\"Interactively select samples to be delivered\")\n    parser.add_argument('-d', '--dry-run', action=\"store_true\", dest=\"dry\", default=False, \n                        help=\"Dry run: nothing will be done\")\n    parser.add_argument('-a', '--deliver-all-fcs', action=\"store_true\", dest=\"deliver_all_fcs\", default=False, \n                        help=\"rsync samples from all flow cells. Default is to only deliver from specified flowcell\")\n    parser.add_argument('-p', '--nophix', action=\"store_true\", dest=\"deliver_nophix\", default=False, \n                        help=\"Deliver fastq files from nophix subdirectory. Default is to deliver from run directory\")\n    parser.add_argument('-g', '--group', action=\"store\", dest=\"group\", default=\"uppmax\",\n                        help=\"Group membership to set on copied files\")\n    parser.add_argument('project_name', action='store', help=\"Project name to deliver, e.g. J.Doe_10_01\")\n    parser.add_argument('flowcell_id', action='store', help=\"Flowcell id to deliver, e.g. 120824_BD1915ACXX\")\n    parser.add_argument('uppmax_id', action='store', help=\"UPPMAX project id to deliver to, e.g. b2012001\")\n    args = parser.parse_args()\n\n    print(\"\"\"\\n****** Deprication ******\\nPlease note that this script is deprecated and the functionality has been replaced by 'pm deliver raw-data'\\n\"\"\")\n    \n    if not args.project_name in os.listdir(args.caspath): \n        print(\"Could not find project. Check directory listing:\")\n        for f in os.listdir(args.caspath): \n            print(f)\n        clean_exit(0,None,args.dry)\n\n    fcid = args.flowcell_id\n    fcid_comp = fcid.split('_')\n    if len(fcid_comp) > 2:\n        fcid = fcid_comp[0] + '_' + fcid_comp[-1]\n        print(\"FCID format too long, trying {:s}\".format(fcid))\n\n    dt = datetime.now()\n    time_str = \"_\".join([str(dt.year),\n                         str(dt.month),\n                         str(dt.day),\n                         str(dt.hour),\n                         str(dt.minute),\n                         str(dt.second)])\n\n    logfilename = os.path.join(os.path.normpath(args.logpath),\"{:s}.log\".format(time_str)) \n    if not args.dry:\n        logfile = open(logfilename, \"w\")\n    else:\n        logfile = sys.stdout\n         \n    logfile.write(\"[{:s}] - Project to move files for:\\n{:s}\\n\".format(utc_time(), args.project_name))\n    logfile.flush()\n\n    proj_base_dir = os.path.join(args.caspath, args.project_name)\n    skip_list = []\n    if args.interactive:\n        for sample_dir in os.listdir(proj_base_dir):\n            if not os.path.isdir(os.path.join(proj_base_dir,sample_dir)):\n                continue\n            if not query_yes_no(\"Deliver sample {:s}?\".format(sample_dir), default=\"no\"):\n                skip_list.append(sample_dir)\n    \n    created_proj_dir_name = fixProjName(args.project_name)\n    del_path_top = '/proj/' +  args.uppmax_id + \"/INBOX/\" + created_proj_dir_name \n\n    to_copy = get_file_copy_list(proj_base_dir,\n                                 del_path_top,\n                                 fcid,\n                                 args.deliver_all_fcs,\n                                 args.deliver_nophix,\n                                 skip_list)\n    \n    # Prompt user if any of the files are non-compressed\n    for fqfile, _, _ in to_copy:\n        if os.path.splitext(fqfile)[1] == \".gz\":\n            continue\n        print(\"WARNING: The file {:s}, which you are about to deliver, does not seem to be compressed. \" \\\n              \"It is recommended that you compress files prior to delivery.\".format(fqfile))\n        if query_yes_no(\"Do you wish to continue delivering \" \\\n                        \"uncompressed fastq files?\", default=\"yes\"):\n            break\n        clean_exit(1,logfile,args.dry)\n            \n    rsync_files(to_copy,\n                logfile,\n                args.group,\n                args.dry)\n    \n    # Touch the flag for the Uppmax cronjob to fix the INBOX permissions\n    touch_file(os.path.join(\"/sw\",\"uppmax\",\"var\",\"inboxfix\",\"schedule\",args.uppmax_id))\n    \n    clean_exit(0,logfile,args.dry)\n        \ndef clean_exit(exitcode, logfile, dry=False):\n    \"\"\"Close the logfile and exit with the given exit code\n    \"\"\"\n    if not dry and logfile is not None:\n        logfile.close()\n    sys.exit(exitcode)\n\nif __name__ == \"__main__\":\n    main()\n    \n########## Tests ###########\n\nimport unittest\nimport shutil\nimport tempfile\nimport random\nimport uuid\n\nclass TestDataDelivery(unittest.TestCase):\n    \n    def test_fixProjName(self):\n        \"\"\"Fix project name\n        \"\"\"\n        \n        test_pnames = [(\"j.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"j.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"doe_11_01\",\"Doe_11_01\"),\n                       (\"j.d.doe_11_01\",\"J.D.Doe_11_01\"),]\n        \n        for test_pname, exp_pname in test_pnames:\n            obs_pname = fixProjName(test_pname)\n            self.assertEqual(obs_pname,\n                             exp_pname,\n                             \"Did not get the expected fix ({:s}) for project name {:s} (got {:s})\".format(exp_pname,test_pname,obs_pname))\n        \n    def test_is_fastq(self):\n        \"\"\"Determine if a file name corresponds to a fastq file\n        \"\"\"\n        \n        test_fnames = [(\"foo.fastq\",True),\n                       (\"foo.fastq.gz\",True),\n                       (\"foo_fastq.txt\",True),\n                       (\"foo_fastq.txt.gz\",True),\n                       (\"foo.fastq.bar\",False),\n                       (\"foo.txt\",False),]\n        \n        for test_fname, exp_result in test_fnames:\n            obs_result = is_fastq(test_fname)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected result ({:s}) for file name {:s}\".format(str(exp_result),test_fname))\n    \n    def _create_test_files(self, root):\n        \n        to_copy = []\n        for n in xrange(10):\n            fd, sfile = tempfile.mkstemp(suffix=\".tmp\", prefix=\"rsync_test_\", dir=root)\n            os.close(fd)\n            # Generate destination file hierarchies\n            ddir = root\n            for l in xrange(random.randint(1,5)):\n                ddir = os.path.join(ddir,str(uuid.uuid4()))\n            to_copy.append([sfile,ddir,\"{:s}.tmp\".format(str(uuid.uuid4()))])\n        \n        return to_copy\n    \n    def test_rsync_files(self):\n        \"\"\"Test the rsync functionality\n        \"\"\"\n        root = tempfile.mkdtemp(prefix=\"rsync_test_\")\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,None,False)\n            sys.stdout = old_stdout\n            \n        \n        # Verify the copy process\n        for src, ddir, dname in to_copy:\n            self.assertTrue(os.path.exists(src),\n                            \"The rsync process have removed source file\")\n            self.assertTrue(os.path.exists(ddir) and os.path.isdir(ddir),\n                            \"The expected destination directory was not created\")\n            dfile = os.path.join(ddir,dname)\n            self.assertTrue(os.path.exists(dfile) and os.path.isfile(dfile),\n                            \"The expected destination file was not created\")\n            exp_stat = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP\n            obs_stat = stat.S_IMODE(os.stat(dfile).st_mode)\n            self.assertEqual(obs_stat,\n                             exp_stat,\n                            \"The mode of the created file is not as expected\")\n            \n        shutil.rmtree(root)\n        \n    def test_rsync_set_group(self):\n        \"\"\"Test setting the group membership on rsync'd files\n        \"\"\"\n        \n        root = tempfile.mkdtemp(prefix=\"rsync_test_set_group_\")\n        avail_groups = os.getgroups()\n        exp_group = grp.getgrgid(avail_groups[random.randint(1,len(avail_groups))-1])[0]\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,exp_group,False)\n            sys.stdout = old_stdout\n            \n        # Verify the copy process set the correct group on created directories\n        for ddir in set([d[1] for d in to_copy]):\n            gid = os.stat(ddir).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on directory. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        # Verify the copy process set the correct group\n        for src, ddir, dname in to_copy:\n            dfile = os.path.join(ddir,dname)\n            gid = os.stat(dfile).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on file. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        \n    def test_create_final_name(self):\n        \"\"\"Create the destination file name\n        \"\"\"\n        \n        date = \"111111\"\n        fcid = \"A11A22BCXX\"\n        sample_name = \"P101_150B_index5\"\n        \n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq..gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n        \n        # Try without the _index part of file name\n        sample_name_noindex = \"P101_150\"\n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name_noindex))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name_noindex)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        # Try some illegal file names and assert that they raise exceptions\n        test_names = [\"1_{}_{}_1_nophix_1_fastq.gz\".format(date,fcid),\n                      \"a_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                      \"{}_CGATRGT_L1_R1_001.fastq.gz\".format(sample_name)]\n        for test_name in test_names:\n            with self.assertRaises(ValueError):\n                create_final_name(test_name,date,fcid,sample_name)\n        \n        # Try a file with undetermined reads\n        sample_name = \"lane1\"\n        test_names = [(\"{}_Undetermined_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),]    \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        \n    def test_get_file_copy_list(self):\n        \"\"\"Get list of files to copy and the destinations\n        \"\"\"\n                     \n        so = sys.stdout\n        dn = open(os.devnull,\"w\")\n        \n        # Create a file hierarchy to search for files\n        root = tempfile.mkdtemp(prefix=\"test_casava_data_delivery_\")\n        date = \"111111\"\n        fcs = [\"{}_{}\".format(date,fcid) for fcid in [\"FCA\",\"FCB\"]]\n        \n        # Create some sample files\n        exp_files = []\n        samples = []\n        for n in xrange(2):\n            sample = tempfile.mkdtemp(dir=root)\n            samples.append(os.path.basename(sample))\n            for fcid in fcs:\n                fcdir = os.path.join(sample,fcid)\n                nophixdir = os.path.join(fcdir,\"nophix\")\n                for d in [fcdir,nophixdir]:\n                    os.makedirs(d)\n                    test_names = [\"{:d}_{:s}_1_1_fastq.txt.gz\".format(random.randint(1,8),\n                                                                           fcid),\n                                  \"{}_CGATGT_L001_R1_001.fastq.gz\".format(samples[-1]),\n                                  \"{}_CGATGT_L001_R1_001.fastq..gz\".format(samples[-1]),]\n                    for test_name in test_names:\n                        test_file = os.path.join(d,test_name)\n                        open(test_file,\"w\").close()\n                        exp_files.append([samples[-1],\n                                          fcid,\n                                          os.path.basename(d) == \"nophix\",\n                                          test_file,\n                                          os.path.join(samples[-1],fcid),\n                                          create_final_name(os.path.basename(test_name),date,fcid.split(\"_\")[-1],samples[-1])])\n                    \n        # Get the list of files to copy under various conditions\n        \n        for deliver_all_fcs in [False, True]:\n            for fcid in fcs:\n                for deliver_nophix in [False, True]:\n                    for skip_sample_list in [[],[samples[0]],[samples[1]],samples]:\n                        sys.stdout = dn\n                        obs_to_copy = sorted(get_file_copy_list(root,\"\",fcid,deliver_all_fcs,deliver_nophix,skip_sample_list))\n                        sys.stdout = so\n                        exp_to_copy = sorted([ef[3:6] for ef in exp_files if (deliver_all_fcs or ef[1] == fcid) and \\\n                                              deliver_nophix == ef[2] and \\\n                                              ef[0] not in skip_sample_list])\n                        #import pdb; pdb.set_trace()\n                        self.assertListEqual(obs_to_copy,\n                                             exp_to_copy,\n                                             \"The files to copy result did not match the expected for \" \\\n                                             \"{:s}\".format(\", \".join([\"{:s}: {:s}\".format(k,v) for k, v in \\\n                                                                      dict(zip([\"deliver_all_fcs\",\n                                                                                \"fcid\",\n                                                                                \"deliver_nophix\",\n                                                                                \"skip_samples\"],\n                                                                               [str(deliver_all_fcs),\n                                                                                fcid,\n                                                                                str(deliver_nophix),\n                                                                                \" \".join(skip_sample_list)])).items()])))\n          \n                        \n        \n            ",
  "output": {
    "before": "# A script to help doing the deliveries.\n# Now using the Casava directory structure\n# The user is asked to provide a project ID, a run name, and an UPPMAX project\n\nimport sys\nimport os\nimport glob\nimport re\nimport grp\nfrom datetime import datetime\nimport argparse\nimport stat\nfrom subprocess import check_call, CalledProcessError\nfrom scilifelab.utils.misc import filtered_walk, query_yes_no, touch_file\nfrom scilifelab.utils.timestamp import utc_time\n\ndef fixProjName(pname):\n    newname = pname[0].upper()\n    postperiod = False\n    for i in range(1, len(pname)):\n        if pname[i] == \".\": \n            newname += pname[i]\n            postperiod = True\n        elif postperiod: \n            newname += pname[i].upper()\n            postperiod = False\n        else:\n            newname += pname[i]\n            postperiod = False\n    return newname\n            \ndef is_fastq(fname):\n    fastq_ext = [\".fastq.gz\",\n                 \".fastq\",\n                 \"_fastq.txt.gz\",\n                 \"_fastq.txt\",\n                 \".fastq..gz\",\n                 \"_fastq.txt..gz\"\n                 ]\n    for ext in fastq_ext:\n        if fname.endswith(ext):\n            return True\n    return False\n\n  \ndef create_final_name(fname, date, fc_id, sample_name):\n    \"\"\"Create the final name of the delivered file\n    \"\"\"\n    \n     # Split the file name according to CASAVA convention\n    m = re.match(r'(\\S+?)_(?:[ACGTN\\-]+|NoIndex|Undetermined)_L0*(\\d+)_R(\\d)_\\d+\\.fastq(.*)', fname)\n    if m is not None:\n        lane = m.group(2)\n        read = m.group(3)\n        ext = m.group(4)\n    else:\n        # Split the file name according to bcbb convention\n        m = re.match(r'(\\d+)_(\\d+)_([^_]+)_(\\d+)_(?:nophix_)?(\\d+)_fastq.txt(.*)', fname)\n        if m is None:\n            raise ValueError(\"Could not parse file name {:s} correctly!\".format(fname))\n        lane = m.group(1)\n        read = m.group(5)\n        ext = m.group(6)\n            \n    dest_file_name = \"{:s}.fastq{:s}\".format(\"_\".join([lane,\n                                                       date,\n                                                       fc_id,\n                                                       sample_name,\n                                                       read]),\n                                             ext.replace('..','.'))\n    return dest_file_name\n      \ndef get_file_copy_list(proj_base_dir, dest_proj_path, fcid, deliver_all_fcs, deliver_nophix, skip_list):\n    to_copy = []\n    for fqfile in filtered_walk(proj_base_dir, \n                                is_fastq, \n                                include_dirs=[fcid] if not deliver_all_fcs else None, \n                                exclude_dirs=skip_list):\n        \n        # Get the run_name and sample_name from the path\n        sample_name, run_name, _ = os.path.relpath(fqfile,proj_base_dir).split(os.sep,2)\n        date, fc_id = run_name.split('_')\n            \n        # Skip if we deliver from nophix and the parent dir is not nophix (or vice versa)\n        pdir = os.path.basename(os.path.dirname(fqfile))\n        if deliver_nophix and pdir != \"nophix\":\n            continue\n        if not deliver_nophix and pdir != run_name:\n            continue\n        \n        # Skip if a compressed version of the current file exists\n        if os.path.exists(\"{:s}.gz\".format(fqfile)):\n            print(\"WARNING: Both compressed and non-compressed versions of {:s} exists! \" \\\n                  \"Is compression/decompression in progress? Will deliver compressed version \" \\\n                  \"but you should make sure that the delivered files are complete!\".format(fqfile))\n            continue\n        \n        print(\"DEBUG: source_delivery_path = {:s}\".format(os.path.dirname(fqfile)))\n        \n        fname = os.path.basename(fqfile)\n        print(fname)\n      \n        dest_run_path = os.path.join(dest_proj_path, sample_name, run_name)\n        dest_file_name = create_final_name(fname,date,fc_id,sample_name)\n        to_copy.append([fqfile,\n                        dest_run_path,\n                        dest_file_name])\n    return to_copy\n\ndef rsync_files(to_copy, logfile, group, dry):\n    # Iterate over the files to copy and create directories and copy files as necessary \n    successful = 0\n    uid = os.getuid()\n    gid = os.getgid()\n    if group is not None and len(group) > 0:\n        gid = grp.getgrnam(group).gr_gid\n    for src_file, dst_dir, dst_name in to_copy:\n        dst_file = os.path.join(dst_dir, dst_name)\n        print \"Will copy (rsync) \", src_file, \"to \", dst_file\n        if not dry:\n            \n            # Create the destination directory if necessary\n            logfile.write(\"[{:s}] - Creating run-level delivery directory: {:s} \" \\\n                          \"(or leaving it in place if already present)\\n\".format(utc_time(),\n                                                                                 dst_dir))\n            if os.path.exists(dst_dir):\n                print(\"Directory {:s} already exists!\".format(dst_dir))\n            else:\n                try:\n                    # Create directory hierarchy with ug+rwX permissions\n                    os.makedirs(dst_dir, 0770)\n                except:\n                    print(\"Could not create run-level delivery directory!\")\n                    clean_exit(1,logfile,dry)\n            \n            # Rsync the file across \n            command_to_execute = ['rsync',\n                                  '-ac',\n                                  src_file,\n                                  dst_file]\n            \n            logfile.write(\"[{:s}] - Executing command: {:s}\\n\".format(utc_time(), \" \".join(command_to_execute)))\n            logfile.flush()\n            try:\n                check_call(command_to_execute)\n            except CalledProcessError, e:\n                logfile.write(\"[{:s}] - rsync exited with exit code {:d}\\n\".format(utc_time(), e.returncode))\n                raise e\n            \n            logfile.write(\"[{:s}] - rsync exited with exit code 0\\n\".format(utc_time()))\n            successful += 1\n        \n            print(\"{:d} of {:d} files copied successfully\".format(successful,len(to_copy)))\n    \n            # Modify the permissions to ug+rw\n            os.chmod(dst_file, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP)\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"A script to help doing the deliveries, now using the Casava directory structure. \" \\\n                                     \"The user is asked to provide a project ID, a run name, and an UPPMAX project\")\n\n    parser.add_argument('-c', '--casava-path', action=\"store\", dest=\"caspath\", default='/proj/a2010002/nobackup/illumina/', \n                        help=\"Specify a path to a Casava directory manually\")\n    parser.add_argument('-l', '--log-path', action=\"store\", dest=\"logpath\", default='/proj/a2010002/private/delivery_logs', \n                        help=\"Specify a path to a log file\")\n    parser.add_argument('-i', '--interactive', action=\"store_true\", dest=\"interactive\", default=False, \n                        help=\"Interactively select samples to be delivered\")\n    parser.add_argument('-d', '--dry-run', action=\"store_true\", dest=\"dry\", default=False, \n                        help=\"Dry run: nothing will be done\")\n    parser.add_argument('-a', '--deliver-all-fcs', action=\"store_true\", dest=\"deliver_all_fcs\", default=False, \n                        help=\"rsync samples from all flow cells. Default is to only deliver from specified flowcell\")\n    parser.add_argument('-p', '--nophix', action=\"store_true\", dest=\"deliver_nophix\", default=False, \n                        help=\"Deliver fastq files from nophix subdirectory. Default is to deliver from run directory\")\n    parser.add_argument('-g', '--group', action=\"store\", dest=\"group\", default=\"uppmax\",\n                        help=\"Group membership to set on copied files\")\n    parser.add_argument('project_name', action='store', help=\"Project name to deliver, e.g. J.Doe_10_01\")\n    parser.add_argument('flowcell_id', action='store', help=\"Flowcell id to deliver, e.g. 120824_BD1915ACXX\")\n    parser.add_argument('uppmax_id', action='store', help=\"UPPMAX project id to deliver to, e.g. b2012001\")\n    args = parser.parse_args()\n\n    print(\"\"\"\\n****** Deprication ******\\nPlease note that this script is deprecated and the functionality has been replaced by 'pm deliver raw-data'\\n\"\"\")\n    \n    if not args.project_name in os.listdir(args.caspath): \n        print(\"Could not find project. Check directory listing:\")\n        for f in os.listdir(args.caspath): \n            print(f)\n        clean_exit(0,None,args.dry)\n\n    fcid = args.flowcell_id\n    fcid_comp = fcid.split('_')\n    if len(fcid_comp) > 2:\n        fcid = fcid_comp[0] + '_' + fcid_comp[-1]\n        print(\"FCID format too long, trying {:s}\".format(fcid))\n\n    dt = datetime.now()\n    time_str = \"_\".join([str(dt.year),\n                         str(dt.month),\n                         str(dt.day),\n                         str(dt.hour),\n                         str(dt.minute),\n                         str(dt.second)])\n\n    logfilename = os.path.join(os.path.normpath(args.logpath),\"{:s}.log\".format(time_str)) \n    if not args.dry:\n        logfile = open(logfilename, \"w\")\n    else:\n        logfile = sys.stdout\n         \n    logfile.write(\"[{:s}] - Project to move files for:\\n{:s}\\n\".format(utc_time(), args.project_name))\n    logfile.flush()\n\n    proj_base_dir = os.path.join(args.caspath, args.project_name)\n    skip_list = []\n    if args.interactive:\n        for sample_dir in os.listdir(proj_base_dir):\n            if not os.path.isdir(os.path.join(proj_base_dir,sample_dir)):\n                continue\n            if not query_yes_no(\"Deliver sample {:s}?\".format(sample_dir), default=\"no\"):\n                skip_list.append(sample_dir)\n    \n    created_proj_dir_name = fixProjName(args.project_name)\n    del_path_top = '/proj/' +  args.uppmax_id + \"/INBOX/\" + created_proj_dir_name \n\n    to_copy = get_file_copy_list(proj_base_dir,\n                                 del_path_top,\n                                 fcid,\n                                 args.deliver_all_fcs,\n                                 args.deliver_nophix,\n                                 skip_list)\n    \n    # Prompt user if any of the files are non-compressed\n    for fqfile, _, _ in to_copy:\n        if os.path.splitext(fqfile)[1] == \".gz\":\n            continue\n        print(\"WARNING: The file {:s}, which you are about to deliver, does not seem to be compressed. \" \\\n              \"It is recommended that you compress files prior to delivery.\".format(fqfile))\n        if query_yes_no(\"Do you wish to continue delivering \" \\\n                        \"uncompressed fastq files?\", default=\"yes\"):\n            break\n        clean_exit(1,logfile,args.dry)\n            \n    rsync_files(to_copy,\n                logfile,\n                args.group,\n                args.dry)\n    \n    # Touch the flag for the Uppmax cronjob to fix the INBOX permissions\n    touch_file(os.path.join(\"/sw\",\"uppmax\",\"var\",\"inboxfix\",\"schedule\",args.uppmax_id))\n    \n    clean_exit(0,logfile,args.dry)\n        \ndef clean_exit(exitcode, logfile, dry=False):\n    \"\"\"Close the logfile and exit with the given exit code\n    \"\"\"\n    if not dry and logfile is not None:\n        logfile.close()\n    sys.exit(exitcode)\n\nif __name__ == \"__main__\":\n    main()\n    \n########## Tests ###########\n\nimport unittest\nimport shutil\nimport tempfile\nimport random\nimport uuid\n\nclass TestDataDelivery(unittest.TestCase):\n    \n    def test_fixProjName(self):\n        \"\"\"Fix project name\n        \"\"\"\n        \n        test_pnames = [(\"j.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"j.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"doe_11_01\",\"Doe_11_01\"),\n                       (\"j.d.doe_11_01\",\"J.D.Doe_11_01\"),]\n        \n        for test_pname, exp_pname in test_pnames:\n            obs_pname = fixProjName(test_pname)\n            self.assertEqual(obs_pname,\n                             exp_pname,\n                             \"Did not get the expected fix ({:s}) for project name {:s} (got {:s})\".format(exp_pname,test_pname,obs_pname))\n        \n    def test_is_fastq(self):\n        \"\"\"Determine if a file name corresponds to a fastq file\n        \"\"\"\n        \n        test_fnames = [(\"foo.fastq\",True),\n                       (\"foo.fastq.gz\",True),\n                       (\"foo_fastq.txt\",True),\n                       (\"foo_fastq.txt.gz\",True),\n                       (\"foo.fastq.bar\",False),\n                       (\"foo.txt\",False),]\n        \n        for test_fname, exp_result in test_fnames:\n            obs_result = is_fastq(test_fname)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected result ({:s}) for file name {:s}\".format(str(exp_result),test_fname))\n    \n    def _create_test_files(self, root):\n        \n        to_copy = []\n        for n in xrange(10):\n            fd, sfile = tempfile.mkstemp(suffix=\".tmp\", prefix=\"rsync_test_\", dir=root)\n            os.close(fd)\n            # Generate destination file hierarchies\n            ddir = root\n            for l in xrange(random.randint(1,5)):\n                ddir = os.path.join(ddir,str(uuid.uuid4()))\n            to_copy.append([sfile,ddir,\"{:s}.tmp\".format(str(uuid.uuid4()))])\n        \n        return to_copy\n    \n    def test_rsync_files(self):\n        \"\"\"Test the rsync functionality\n        \"\"\"\n        root = tempfile.mkdtemp(prefix=\"rsync_test_\")\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,None,False)\n            sys.stdout = old_stdout\n            \n        \n        # Verify the copy process\n        for src, ddir, dname in to_copy:\n            self.assertTrue(os.path.exists(src),\n                            \"The rsync process have removed source file\")\n            self.assertTrue(os.path.exists(ddir) and os.path.isdir(ddir),\n                            \"The expected destination directory was not created\")\n            dfile = os.path.join(ddir,dname)\n            self.assertTrue(os.path.exists(dfile) and os.path.isfile(dfile),\n                            \"The expected destination file was not created\")\n            exp_stat = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP\n            obs_stat = stat.S_IMODE(os.stat(dfile).st_mode)\n            self.assertEqual(obs_stat,\n                             exp_stat,\n                            \"The mode of the created file is not as expected\")\n            \n        shutil.rmtree(root)\n        \n    def test_rsync_set_group(self):\n        \"\"\"Test setting the group membership on rsync'd files\n        \"\"\"\n        \n        root = tempfile.mkdtemp(prefix=\"rsync_test_set_group_\")\n        avail_groups = os.getgroups()\n        exp_group = grp.getgrgid(avail_groups[random.randint(1,len(avail_groups))-1])[0]\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,exp_group,False)\n            sys.stdout = old_stdout\n            \n        # Verify the copy process set the correct group on created directories\n        for ddir in set([d[1] for d in to_copy]):\n            gid = os.stat(ddir).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on directory. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        # Verify the copy process set the correct group\n        for src, ddir, dname in to_copy:\n            dfile = os.path.join(ddir,dname)\n            gid = os.stat(dfile).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on file. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        \n    def test_create_final_name(self):\n        \"\"\"Create the destination file name\n        \"\"\"\n        \n        date = \"111111\"\n        fcid = \"A11A22BCXX\"\n        sample_name = \"P101_150B_index5\"\n        \n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq..gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n        \n        # Try without the _index part of file name\n        sample_name_noindex = \"P101_150\"\n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name_noindex))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name_noindex)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        # Try some illegal file names and assert that they raise exceptions\n        test_names = [\"1_{}_{}_1_nophix_1_fastq.gz\".format(date,fcid),\n                      \"a_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                      \"{}_CGATRGT_L1_R1_001.fastq.gz\".format(sample_name)]\n        for test_name in test_names:\n            with self.assertRaises(ValueError):\n                create_final_name(test_name,date,fcid,sample_name)\n        \n        # Try a file with undetermined reads\n        sample_name = \"lane1\"\n        test_names = [(\"{}_Undetermined_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),]    \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        \n    def test_get_file_copy_list(self):\n        \"\"\"Get list of files to copy and the destinations\n        \"\"\"\n                     \n        so = sys.stdout\n        dn = open(os.devnull,\"w\")\n        \n        # Create a file hierarchy to search for files\n        root = tempfile.mkdtemp(prefix=\"test_casava_data_delivery_\")\n        date = \"111111\"\n        fcs = [\"{}_{}\".format(date,fcid) for fcid in [\"FCA\",\"FCB\"]]\n        \n        # Create some sample files\n        exp_files = []\n        samples = []\n        for n in xrange(2):\n            sample = tempfile.mkdtemp(dir=root)\n            samples.append(os.path.basename(sample))\n            for fcid in fcs:\n                fcdir = os.path.join(sample,fcid)\n                nophixdir = os.path.join(fcdir,\"nophix\")\n                for d in [fcdir,nophixdir]:\n                    os.makedirs(d)\n                    test_names = [\"{:d}_{:s}_1_1_fastq.txt.gz\".format(random.randint(1,8),\n                                                                           fcid),\n                                  \"{}_CGATGT_L001_R1_001.fastq.gz\".format(samples[-1]),\n                                  \"{}_CGATGT_L001_R1_001.fastq..gz\".format(samples[-1]),]\n                    for test_name in test_names:\n                        test_file = os.path.join(d,test_name)\n                        open(test_file,\"w\").close()\n                        exp_files.append([samples[-1],\n                                          fcid,\n                                          os.path.basename(d) == \"nophix\",\n                                          test_file,\n                                          os.path.join(samples[-1],fcid),\n                                          create_final_name(os.path.basename(test_name),date,fcid.split(\"_\")[-1],samples[-1])])\n                    \n        # Get the list of files to copy under various conditions\n        \n        for deliver_all_fcs in [False, True]:\n            for fcid in fcs:\n                for deliver_nophix in [False, True]:\n                    for skip_sample_list in [[],[samples[0]],[samples[1]],samples]:\n                        sys.stdout = dn\n                        obs_to_copy = sorted(get_file_copy_list(root,\"\",fcid,deliver_all_fcs,deliver_nophix,skip_sample_list))\n                        sys.stdout = so\n                        exp_to_copy = sorted([ef[3:6] for ef in exp_files if (deliver_all_fcs or ef[1] == fcid) and \\\n                                              deliver_nophix == ef[2] and \\\n                                              ef[0] not in skip_sample_list])\n                        #import pdb; pdb.set_trace()\n                        self.assertListEqual(obs_to_copy,\n                                             exp_to_copy,\n                                             \"The files to copy result did not match the expected for \" \\\n                                             \"{:s}\".format(\", \".join([\"{:s}: {:s}\".format(k,v) for k, v in \\\n                                                                      dict(zip([\"deliver_all_fcs\",\n                                                                                \"fcid\",\n                                                                                \"deliver_nophix\",\n                                                                                \"skip_samples\"],\n                                                                               [str(deliver_all_fcs),\n                                                                                fcid,\n                                                                                str(deliver_nophix),\n                                                                                \" \".join(skip_sample_list)])).items()])))\n          \n                        \n        \n            \n        shutil.rmtree(root)\n        \n    def test_rsync_files_with_group(self):\n        \"\"\"Test the rsync functionality with group membership set\n        \"\"\"\n        \n        root = tempfile.mk",
    "after": "# A script to help doing the deliveries.\n# Now using the Casava directory structure\n# The user is asked to provide a project ID, a run name, and an UPPMAX project\n\nimport sys\nimport os\nimport glob\nimport re\nimport grp\nfrom datetime import datetime\nimport argparse\nimport stat\nfrom subprocess import check_call, CalledProcessError\nfrom scilifelab.utils.misc import filtered_walk, query_yes_no, touch_file\nfrom scilifelab.utils.timestamp import utc_time\n\ndef fixProjName(pname):\n    newname = pname[0].upper()\n    postperiod = False\n    for i in range(1, len(pname)):\n        if pname[i] == \".\": \n            newname += pname[i]\n            postperiod = True\n        elif postperiod: \n            newname += pname[i].upper()\n            postperiod = False\n        else:\n            newname += pname[i]\n            postperiod = False\n    return newname\n            \ndef is_fastq(fname):\n    fastq_ext = [\".fastq.gz\",\n                 \".fastq\",\n                 \"_fastq.txt.gz\",\n                 \"_fastq.txt\",\n                 \".fastq..gz\",\n                 \"_fastq.txt..gz\"\n                 ]\n    for ext in fastq_ext:\n        if fname.endswith(ext):\n            return True\n    return False\n\n  \ndef create_final_name(fname, date, fc_id, sample_name):\n    \"\"\"Create the final name of the delivered file\n    \"\"\"\n    \n     # Split the file name according to CASAVA convention\n    m = re.match(r'(\\S+?)_(?:[ACGTN\\-]+|NoIndex|Undetermined)_L0*(\\d+)_R(\\d)_\\d+\\.fastq(.*)', fname)\n    if m is not None:\n        lane = m.group(2)\n        read = m.group(3)\n        ext = m.group(4)\n    else:\n        # Split the file name according to bcbb convention\n        m = re.match(r'(\\d+)_(\\d+)_([^_]+)_(\\d+)_(?:nophix_)?(\\d+)_fastq.txt(.*)', fname)\n        if m is None:\n            raise ValueError(\"Could not parse file name {:s} correctly!\".format(fname))\n        lane = m.group(1)\n        read = m.group(5)\n        ext = m.group(6)\n            \n    dest_file_name = \"{:s}.fastq{:s}\".format(\"_\".join([lane,\n                                                       date,\n                                                       fc_id,\n                                                       sample_name,\n                                                       read]),\n                                             ext.replace('..','.'))\n    return dest_file_name\n      \ndef get_file_copy_list(proj_base_dir, dest_proj_path, fcid, deliver_all_fcs, deliver_nophix, skip_list):\n    to_copy = []\n    for fqfile in filtered_walk(proj_base_dir, \n                                is_fastq, \n                                include_dirs=[fcid] if not deliver_all_fcs else None, \n                                exclude_dirs=skip_list):\n        \n        # Get the run_name and sample_name from the path\n        sample_name, run_name, _ = os.path.relpath(fqfile,proj_base_dir).split(os.sep,2)\n        date, fc_id = run_name.split('_')\n            \n        # Skip if we deliver from nophix and the parent dir is not nophix (or vice versa)\n        pdir = os.path.basename(os.path.dirname(fqfile))\n        if deliver_nophix and pdir != \"nophix\":\n            continue\n        if not deliver_nophix and pdir != run_name:\n            continue\n        \n        # Skip if a compressed version of the current file exists\n        if os.path.exists(\"{:s}.gz\".format(fqfile)):\n            print(\"WARNING: Both compressed and non-compressed versions of {:s} exists! \" \\\n                  \"Is compression/decompression in progress? Will deliver compressed version \" \\\n                  \"but you should make sure that the delivered files are complete!\".format(fqfile))\n            continue\n        \n        print(\"DEBUG: source_delivery_path = {:s}\".format(os.path.dirname(fqfile)))\n        \n        fname = os.path.basename(fqfile)\n        print(fname)\n      \n        dest_run_path = os.path.join(dest_proj_path, sample_name, run_name)\n        dest_file_name = create_final_name(fname,date,fc_id,sample_name)\n        to_copy.append([fqfile,\n                        dest_run_path,\n                        dest_file_name])\n    return to_copy\n\ndef rsync_files(to_copy, logfile, group, dry):\n    # Iterate over the files to copy and create directories and copy files as necessary \n    successful = 0\n    uid = os.getuid()\n    gid = os.getgid()\n    if group is not None and len(group) > 0:\n        gid = grp.getgrnam(group).gr_gid\n    for src_file, dst_dir, dst_name in to_copy:\n        dst_file = os.path.join(dst_dir, dst_name)\n        print \"Will copy (rsync) \", src_file, \"to \", dst_file\n        if not dry:\n            \n            # Create the destination directory if necessary\n            logfile.write(\"[{:s}] - Creating run-level delivery directory: {:s} \" \\\n                          \"(or leaving it in place if already present)\\n\".format(utc_time(),\n                                                                                 dst_dir))\n            if os.path.exists(dst_dir):\n                print(\"Directory {:s} already exists!\".format(dst_dir))\n            else:\n                try:\n                    # Create directory hierarchy with ug+rwX permissions\n                    os.makedirs(dst_dir, 0770)\n                except:\n                    print(\"Could not create run-level delivery directory!\")\n                    clean_exit(1,logfile,dry)\n            \n            # Rsync the file across \n            command_to_execute = ['rsync',\n                                  '-ac',\n                                  src_file,\n                                  dst_file]\n            \n            logfile.write(\"[{:s}] - Executing command: {:s}\\n\".format(utc_time(), \" \".join(command_to_execute)))\n            logfile.flush()\n            try:\n                check_call(command_to_execute)\n            except CalledProcessError, e:\n                logfile.write(\"[{:s}] - rsync exited with exit code {:d}\\n\".format(utc_time(), e.returncode))\n                raise e\n            \n            logfile.write(\"[{:s}] - rsync exited with exit code 0\\n\".format(utc_time()))\n            successful += 1\n        \n            print(\"{:d} of {:d} files copied successfully\".format(successful,len(to_copy)))\n    \n            # Modify the permissions to ug+rw\n            os.chmod(dst_file, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP)\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"A script to help doing the deliveries, now using the Casava directory structure. \" \\\n                                     \"The user is asked to provide a project ID, a run name, and an UPPMAX project\")\n\n    parser.add_argument('-c', '--casava-path', action=\"store\", dest=\"caspath\", default='/proj/a2010002/nobackup/illumina/', \n                        help=\"Specify a path to a Casava directory manually\")\n    parser.add_argument('-l', '--log-path', action=\"store\", dest=\"logpath\", default='/proj/a2010002/private/delivery_logs', \n                        help=\"Specify a path to a log file\")\n    parser.add_argument('-i', '--interactive', action=\"store_true\", dest=\"interactive\", default=False, \n                        help=\"Interactively select samples to be delivered\")\n    parser.add_argument('-d', '--dry-run', action=\"store_true\", dest=\"dry\", default=False, \n                        help=\"Dry run: nothing will be done\")\n    parser.add_argument('-a', '--deliver-all-fcs', action=\"store_true\", dest=\"deliver_all_fcs\", default=False, \n                        help=\"rsync samples from all flow cells. Default is to only deliver from specified flowcell\")\n    parser.add_argument('-p', '--nophix', action=\"store_true\", dest=\"deliver_nophix\", default=False, \n                        help=\"Deliver fastq files from nophix subdirectory. Default is to deliver from run directory\")\n    parser.add_argument('-g', '--group', action=\"store\", dest=\"group\", default=\"uppmax\",\n                        help=\"Group membership to set on copied files\")\n    parser.add_argument('project_name', action='store', help=\"Project name to deliver, e.g. J.Doe_10_01\")\n    parser.add_argument('flowcell_id', action='store', help=\"Flowcell id to deliver, e.g. 120824_BD1915ACXX\")\n    parser.add_argument('uppmax_id', action='store', help=\"UPPMAX project id to deliver to, e.g. b2012001\")\n    args = parser.parse_args()\n\n    print(\"\"\"\\n****** Deprication ******\\nPlease note that this script is deprecated and the functionality has been replaced by 'pm deliver raw-data'\\n\"\"\")\n    \n    if not args.project_name in os.listdir(args.caspath): \n        print(\"Could not find project. Check directory listing:\")\n        for f in os.listdir(args.caspath): \n            print(f)\n        clean_exit(0,None,args.dry)\n\n    fcid = args.flowcell_id\n    fcid_comp = fcid.split('_')\n    if len(fcid_comp) > 2:\n        fcid = fcid_comp[0] + '_' + fcid_comp[-1]\n        print(\"FCID format too long, trying {:s}\".format(fcid))\n\n    dt = datetime.now()\n    time_str = \"_\".join([str(dt.year),\n                         str(dt.month),\n                         str(dt.day),\n                         str(dt.hour),\n                         str(dt.minute),\n                         str(dt.second)])\n\n    logfilename = os.path.join(os.path.normpath(args.logpath),\"{:s}.log\".format(time_str)) \n    if not args.dry:\n        logfile = open(logfilename, \"w\")\n    else:\n        logfile = sys.stdout\n         \n    logfile.write(\"[{:s}] - Project to move files for:\\n{:s}\\n\".format(utc_time(), args.project_name))\n    logfile.flush()\n\n    proj_base_dir = os.path.join(args.caspath, args.project_name)\n    skip_list = []\n    if args.interactive:\n        for sample_dir in os.listdir(proj_base_dir):\n            if not os.path.isdir(os.path.join(proj_base_dir,sample_dir)):\n                continue\n            if not query_yes_no(\"Deliver sample {:s}?\".format(sample_dir), default=\"no\"):\n                skip_list.append(sample_dir)\n    \n    created_proj_dir_name = fixProjName(args.project_name)\n    del_path_top = '/proj/' +  args.uppmax_id + \"/INBOX/\" + created_proj_dir_name \n\n    to_copy = get_file_copy_list(proj_base_dir,\n                                 del_path_top,\n                                 fcid,\n                                 args.deliver_all_fcs,\n                                 args.deliver_nophix,\n                                 skip_list)\n    \n    # Prompt user if any of the files are non-compressed\n    for fqfile, _, _ in to_copy:\n        if os.path.splitext(fqfile)[1] == \".gz\":\n            continue\n        print(\"WARNING: The file {:s}, which you are about to deliver, does not seem to be compressed. \" \\\n              \"It is recommended that you compress files prior to delivery.\".format(fqfile))\n        if query_yes_no(\"Do you wish to continue delivering \" \\\n                        \"uncompressed fastq files?\", default=\"yes\"):\n            break\n        clean_exit(1,logfile,args.dry)\n            \n    rsync_files(to_copy,\n                logfile,\n                args.group,\n                args.dry)\n    \n    # Touch the flag for the Uppmax cronjob to fix the INBOX permissions\n    touch_file(os.path.join(\"/sw\",\"uppmax\",\"var\",\"inboxfix\",\"schedule\",args.uppmax_id))\n    \n    clean_exit(0,logfile,args.dry)\n        \ndef clean_exit(exitcode, logfile, dry=False):\n    \"\"\"Close the logfile and exit with the given exit code\n    \"\"\"\n    if not dry and logfile is not None:\n        logfile.close()\n    sys.exit(exitcode)\n\nif __name__ == \"__main__\":\n    main()\n    \n########## Tests ###########\n\nimport unittest\nimport shutil\nimport tempfile\nimport random\nimport uuid\n\nclass TestDataDelivery(unittest.TestCase):\n    \n    def test_fixProjName(self):\n        \"\"\"Fix project name\n        \"\"\"\n        \n        test_pnames = [(\"j.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"j.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.doe_11_01\",\"J.Doe_11_01\"),\n                       (\"J.Doe_11_01\",\"J.Doe_11_01\"),\n                       (\"doe_11_01\",\"Doe_11_01\"),\n                       (\"j.d.doe_11_01\",\"J.D.Doe_11_01\"),]\n        \n        for test_pname, exp_pname in test_pnames:\n            obs_pname = fixProjName(test_pname)\n            self.assertEqual(obs_pname,\n                             exp_pname,\n                             \"Did not get the expected fix ({:s}) for project name {:s} (got {:s})\".format(exp_pname,test_pname,obs_pname))\n        \n    def test_is_fastq(self):\n        \"\"\"Determine if a file name corresponds to a fastq file\n        \"\"\"\n        \n        test_fnames = [(\"foo.fastq\",True),\n                       (\"foo.fastq.gz\",True),\n                       (\"foo_fastq.txt\",True),\n                       (\"foo_fastq.txt.gz\",True),\n                       (\"foo.fastq.bar\",False),\n                       (\"foo.txt\",False),]\n        \n        for test_fname, exp_result in test_fnames:\n            obs_result = is_fastq(test_fname)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected result ({:s}) for file name {:s}\".format(str(exp_result),test_fname))\n    \n    def _create_test_files(self, root):\n        \n        to_copy = []\n        for n in xrange(10):\n            fd, sfile = tempfile.mkstemp(suffix=\".tmp\", prefix=\"rsync_test_\", dir=root)\n            os.close(fd)\n            # Generate destination file hierarchies\n            ddir = root\n            for l in xrange(random.randint(1,5)):\n                ddir = os.path.join(ddir,str(uuid.uuid4()))\n            to_copy.append([sfile,ddir,\"{:s}.tmp\".format(str(uuid.uuid4()))])\n        \n        return to_copy\n    \n    def test_rsync_files(self):\n        \"\"\"Test the rsync functionality\n        \"\"\"\n        root = tempfile.mkdtemp(prefix=\"rsync_test_\")\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,None,False)\n            sys.stdout = old_stdout\n            \n        \n        # Verify the copy process\n        for src, ddir, dname in to_copy:\n            self.assertTrue(os.path.exists(src),\n                            \"The rsync process have removed source file\")\n            self.assertTrue(os.path.exists(ddir) and os.path.isdir(ddir),\n                            \"The expected destination directory was not created\")\n            dfile = os.path.join(ddir,dname)\n            self.assertTrue(os.path.exists(dfile) and os.path.isfile(dfile),\n                            \"The expected destination file was not created\")\n            exp_stat = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP\n            obs_stat = stat.S_IMODE(os.stat(dfile).st_mode)\n            self.assertEqual(obs_stat,\n                             exp_stat,\n                            \"The mode of the created file is not as expected\")\n            \n        shutil.rmtree(root)\n        \n    def test_rsync_set_group(self):\n        \"\"\"Test setting the group membership on rsync'd files\n        \"\"\"\n        \n        root = tempfile.mkdtemp(prefix=\"rsync_test_set_group_\")\n        avail_groups = os.getgroups()\n        exp_group = grp.getgrgid(avail_groups[random.randint(1,len(avail_groups))-1])[0]\n        \n        # Create some files to move\n        to_copy = self._create_test_files(root)\n        \n        # Run rsync\n        with open(os.devnull, 'w') as f:\n            old_stdout = sys.stdout\n            sys.stdout = f\n            rsync_files(to_copy,sys.stdout,exp_group,False)\n            sys.stdout = old_stdout\n            \n        # Verify the copy process set the correct group on created directories\n        for ddir in set([d[1] for d in to_copy]):\n            gid = os.stat(ddir).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on directory. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        # Verify the copy process set the correct group\n        for src, ddir, dname in to_copy:\n            dfile = os.path.join(ddir,dname)\n            gid = os.stat(dfile).st_gid\n            obs_group = grp.getgrgid(gid)[0]\n            self.assertEqual(obs_group,\n                             exp_group,\n                             \"Failed to set group '{}' on file. Group is {}\".format(exp_group,\n                                                                                    obs_group))\n        \n        \n    def test_create_final_name(self):\n        \"\"\"Create the destination file name\n        \"\"\"\n        \n        date = \"111111\"\n        fcid = \"A11A22BCXX\"\n        sample_name = \"P101_150B_index5\"\n        \n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name)),\n                      (\"1_{}_{}_1_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq..gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),\n                      (\"{}_CGATGT_L001_R1_001.fastq\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq\".format(date,fcid,sample_name))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n        \n        # Try without the _index part of file name\n        sample_name_noindex = \"P101_150\"\n        test_names = [(\"1_{}_{}_1_nophix_1_fastq.txt.gz\".format(date,fcid),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_CGATGT_L001_R1_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name_noindex)),\n                      (\"{}_NoIndex_L001_R2_001.fastq.gz\".format(sample_name_noindex),\n                       \"1_{}_{}_{}_2.fastq.gz\".format(date,fcid,sample_name_noindex))]\n        \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name_noindex)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        # Try some illegal file names and assert that they raise exceptions\n        test_names = [\"1_{}_{}_1_nophix_1_fastq.gz\".format(date,fcid),\n                      \"a_{}_{}_1_nophix_1_fastq.txt\".format(date,fcid),\n                      \"{}_CGATRGT_L1_R1_001.fastq.gz\".format(sample_name)]\n        for test_name in test_names:\n            with self.assertRaises(ValueError):\n                create_final_name(test_name,date,fcid,sample_name)\n        \n        # Try a file with undetermined reads\n        sample_name = \"lane1\"\n        test_names = [(\"{}_Undetermined_L001_R1_001.fastq.gz\".format(sample_name),\n                       \"1_{}_{}_{}_1.fastq.gz\".format(date,fcid,sample_name)),]    \n        for test_fname, exp_result in test_names:\n            obs_result = create_final_name(test_fname,date,fcid,sample_name)\n            self.assertEqual(obs_result,\n                             exp_result,\n                             \"Did not get expected final name ({:s}) for file name {:s}\".format(exp_result,test_fname))\n    \n        \n    def test_get_file_copy_list(self):\n        \"\"\"Get list of files to copy and the destinations\n        \"\"\"\n                     \n        so = sys.stdout\n        dn = open(os.devnull,\"w\")\n        \n        # Create a file hierarchy to search for files\n        root = tempfile.mkdtemp(prefix=\"test_casava_data_delivery_\")\n        date = \"111111\"\n        fcs = [\"{}_{}\".format(date,fcid) for fcid in [\"FCA\",\"FCB\"]]\n        \n        # Create some sample files\n        exp_files = []\n        samples = []\n        for n in xrange(2):\n            sample = tempfile.mkdtemp(dir=root)\n            samples.append(os.path.basename(sample))\n            for fcid in fcs:\n                fcdir = os.path.join(sample,fcid)\n                nophixdir = os.path.join(fcdir,\"nophix\")\n                for d in [fcdir,nophixdir]:\n                    os.makedirs(d)\n                    test_names = [\"{:d}_{:s}_1_1_fastq.txt.gz\".format(random.randint(1,8),\n                                                                           fcid),\n                                  \"{}_CGATGT_L001_R1_001.fastq.gz\".format(samples[-1]),\n                                  \"{}_CGATGT_L001_R1_001.fastq..gz\".format(samples[-1]),]\n                    for test_name in test_names:\n                        test_file = os.path.join(d,test_name)\n                        open(test_file,\"w\").close()\n                        exp_files.append([samples[-1],\n                                          fcid,\n                                          os.path.basename(d) == \"nophix\",\n                                          test_file,\n                                          os.path.join(samples[-1],fcid),\n                                          create_final_name(os.path.basename(test_name),date,fcid.split(\"_\")[-1],samples[-1])])\n                    \n        # Get the list of files to copy under various conditions\n        \n        for deliver_all_fcs in [False, True]:\n            for fcid in fcs:\n                for deliver_nophix in [False, True]:\n                    for skip_sample_list in [[],[samples[0]],[samples[1]],samples]:\n                        sys.stdout = dn\n                        obs_to_copy = sorted(get_file_copy_list(root,\"\",fcid,deliver_all_fcs,deliver_nophix,skip_sample_list))\n                        sys.stdout = so\n                        exp_to_copy = sorted([ef[3:6] for ef in exp_files if (deliver_all_fcs or ef[1] == fcid) and \\\n                                              deliver_nophix == ef[2] and \\\n                                              ef[0] not in skip_sample_list])\n                        #import pdb; pdb.set_trace()\n                        self.assertListEqual(obs_to_copy,\n                                             exp_to_copy,\n                                             \"The files to copy result did not match the expected for \" \\\n                                             \"{:s}\".format(\", \".join([\"{:s}: {:s}\".format(k,v) for k, v in \\\n                                                                      dict(zip([\"deliver_all_fcs\",\n                                                                                \"fcid\",\n                                                                                \"deliver_nophix\",\n                                                                                \"skip_samples\"],\n                                                                               [str(deliver_all_fcs),\n                                                                                fcid,\n                                                                                str(deliver_nophix),\n                                                                                \" \".join(skip_sample_list)])).items()])))\n          \n                        \n        \n            \n    def test_get_file_copy_list_with_valid_group(self):\n        \"\"\"Get the list of files to copy and the destinations\n        \"\"\"\n        \n        # Create a file hierarchy to search for files"
  },
  "feature_stats": {
    "indices": [
      1,
      3600,
      7196,
      1592,
      6372,
      3645,
      407,
      1854,
      4772,
      6110,
      6030
    ],
    "f_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_before": [
      0.0,
      0.0,
      0.03438861668109894,
      0.048972342163324356,
      0.010611850768327713,
      0.009067859500646591,
      0.05526633560657501,
      0.13111437857151031,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.03438861668109894,
      0.048972342163324356,
      0.010611850768327713,
      0.009067859500646591,
      0.05526633560657501,
      0.13111437857151031,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 6.500702248136203,
    "train_mean_l2": 4.52228784327209,
    "train_mean_l1": 1.9784144236048062,
    "num_steps": 3000,
    "num_batches": 3000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251126-190647/feature_std_layer_12.html",
    "mean_std": 0.993312418460846,
    "max_std": 26.361066818237305
  }
}