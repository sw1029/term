{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "main.py sae.loss_option=1 sae.loss_module=option1_loss experiment.use_multi_contrast=true",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 4,
    "epochs": 1,
    "max_steps": 1000,
    "concept_samples_per_label": 250,
    "loss_option": 1,
    "loss_module": "option1_loss"
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "steering": {
    "label": "struct",
    "feature_idx": 2,
    "strength": 15.0
  },
  "prompt": "from typing import Optional, Tuple\n\nimport torch\n\n\ndef marginal_pdf(\n    values: torch.Tensor, bins: torch.Tensor, sigma: torch.Tensor, epsilon: float = 1e-10\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculate the marginal probability distribution function of the input tensor based on the number of\n    histogram bins.\n\n    Args:\n        values: shape [BxNx1].\n        bins: shape [NUM_BINS].\n        sigma: shape [1], gaussian smoothing factor.\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n          - torch.Tensor: shape [BxN].\n          - torch.Tensor: shape [BxNxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(values, torch.Tensor):\n        raise TypeError(f\"Input values type is not a torch.Tensor. Got {type(values)}\")\n\n    if not isinstance(bins, torch.Tensor):\n        raise TypeError(f\"Input bins type is not a torch.Tensor. Got {type(bins)}\")\n\n    if not isinstance(sigma, torch.Tensor):\n        raise TypeError(f\"Input sigma type is not a torch.Tensor. Got {type(sigma)}\")\n\n    if not values.dim() == 3:\n        raise ValueError(\"Input values must be a of the shape BxNx1.\" \" Got {}\".format(values.shape))\n\n    if not bins.dim() == 1:\n        raise ValueError(\"Input bins must be a of the shape NUM_BINS\" \" Got {}\".format(bins.shape))\n\n    if not sigma.dim() == 0:\n        raise ValueError(\"Input sigma must be a of the shape 1\" \" Got {}\".format(sigma.shape))\n\n    residuals = values - bins.unsqueeze(0).unsqueeze(0)\n    kernel_values = torch.exp(-0.5 * (residuals / sigma).pow(2))\n\n    pdf = torch.mean(kernel_values, dim=1)\n    normalization = torch.sum(pdf, dim=1).unsqueeze(1) + epsilon\n    pdf = pdf / normalization\n\n    return pdf, kernel_values\n\n\ndef joint_pdf(kernel_values1: torch.Tensor, kernel_values2: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Calculate the joint probability distribution function of the input tensors based on the number of histogram\n    bins.\n\n    Args:\n        kernel_values1: shape [BxNxNUM_BINS].\n        kernel_values2: shape [BxNxNUM_BINS].\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        shape [BxNUM_BINSxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(kernel_values1, torch.Tensor):\n        raise TypeError(f\"Input kernel_values1 type is not a torch.Tensor. Got {type(kernel_values1)}\")\n\n    if not isinstance(kernel_values2, torch.Tensor):\n        raise TypeError(f\"Input kernel_values2 type is not a torch.Tensor. Got {type(kernel_values2)}\")\n\n    if not kernel_values1.dim() == 3:\n        raise ValueError(\"Input kernel_values1 must be a of the shape BxN.\" \" Got {}\".format(kernel_values1.shape))\n\n    if not kernel_values2.dim() == 3:\n        raise ValueError(\"Input kernel_values2 must be a of the shape BxN.\" \" Got {}\".format(kernel_values2.shape))\n\n    if kernel_values1.shape != kernel_values2.shape:\n        raise ValueError(\n            \"Inputs kernel_values1 and kernel_values2 must have the same shape.\"\n            \" Got {} and {}\".format(kernel_values1.shape, kernel_values2.shape)\n        )\n\n    joint_kernel_values = torch.matmul(kernel_values1.transpose(1, 2), kernel_values2)\n    normalization = torch.sum(joint_kernel_values, dim=(1, 2)).view(-1, 1, 1) + epsilon\n    pdf = joint_kernel_values / normalization\n\n    return pdf\n\n\ndef histogram(x: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Estimate the histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x: Input tensor to compute the histogram with shape :math:`(B, D)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins})`.\n\n    Examples:\n        >>> x = torch.rand(1, 10)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram(x, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([1, 128])\n    \"\"\"\n\n    pdf, _ = marginal_pdf(x.unsqueeze(2), bins, bandwidth, epsilon)\n\n    return pdf\n\n\ndef histogram2d(\n    x1: torch.Tensor, x2: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10\n) -> torch.Tensor:\n    \"\"\"Estimate the 2d histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x1: Input tensor to compute the histogram with shape :math:`(B, D1)`.\n        x2: Input tensor to compute the histogram with shape :math:`(B, D2)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability. Default: 1e-10.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins}), N_{bins})`.\n\n    Examples:\n        >>> x1 = torch.rand(2, 32)\n        >>> x2 = torch.rand(2, 32)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram2d(x1, x2, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([2, 128, 128])\n    \"\"\"\n\n    _, kernel_values1 = marginal_pdf(x1.unsqueeze(2), bins, bandwidth, epsilon)\n    _, kernel_values2 = marginal_pdf(x2.unsqueeze(2), bins, bandwidth, epsilon)\n\n    pdf = joint_pdf(kernel_values1, kernel_values2)\n\n    return pdf\n\n\ndef image_histogram2d(\n    image: torch.Tensor,\n    min: float = 0.0,\n    max: float = 255.0,\n    n_bins: int = 256,\n    bandwidth: Optional[float] = None,\n    centers: Optional[torch.Tensor] = None,\n    return_pdf: bool = False,\n    kernel: str = \"triangular\",\n    eps: float = 1e-10,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Estimate the histogram of the input image(s).\n\n    The calculation uses triangular kernel density estimation.\n\n    Args:\n        image: Input tensor to compute the histogram with shape\n          :math:`(H, W)`, :math:`(C, H, W)` or :math:`(B, C, H, W)`.\n        min: Lower end of the interval (inclusive).\n        max: Upper end of the interval (inclusive). Ignored when\n          :attr:`centers` is specified.\n        n_bins: The number of histogram bins. Ignored when\n          :attr:`centers` is specified.\n        bandwidth: Smoothing factor. If not specified or equal to -1,\n          :math:`(bandwidth = (max - min) / n_bins)`.\n        centers: Centers of the bins with shape :math:`(n_bins,)`.\n          If not specified or empty, it is calculated as centers of\n          equal width bins of [min, max] range.\n        return_pdf: If True, also return probability densities for\n          each bin.\n        kernel: kernel to perform kernel density estimation\n          ``(`triangular`, `gaussian`, `uniform`, `epanechnikov`)``.\n\n    Returns:\n        Computed histogram of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`.\n        Computed probability densities of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`, if return_pdf is ``True``. Tensor of zeros with shape\n          of the histogram otherwise.\n    \"\"\"\n    if image is not None and not isinstance(image, torch.Tensor):\n        raise TypeError(f\"Input image type is not a torch.Tensor. Got {type(image)}.\")\n\n    if centers is not None and not isinstance(centers, torch.Tensor):\n        raise TypeError(f\"Bins' centers type is not a torch.Tensor. Got {type(centers)}.\")\n\n    if centers is not None and len(centers.shape) > 0 and centers.dim() != 1:\n        raise ValueError(f\"Bins' centers must be a torch.Tensor of the shape (n_bins,). Got {centers.shape}.\")\n\n    if not isinstance(min, float):\n        raise TypeError(f'Type of lower end of the range is not a float. Got {type(min)}.')\n\n    if not isinstance(max, float):\n        raise TypeError(f\"Type of upper end of the range is not a float. Got {type(min)}.\")\n\n    if not isinstance(n_bins, int):\n        raise TypeError(f\"Type of number of bins is not an int. Got {type(n_bins)}.\")\n\n    if bandwidth is not None and not isinstance(bandwidth, float):\n        raise TypeError(f\"Bandwidth type is not a float. Got {type(bandwidth)}.\")\n\n    if not isinstance(return_pdf, bool):\n        raise TypeError(f\"Return_pdf type is not a bool. Got {type(return_pdf)}.\")\n\n    if bandwidth is None:\n        bandwidth = (max - min) / n_bins\n\n    if centers is None:\n        centers = min + bandwidth * (torch.arange(n_bins, device=image.device, dtype=image.dtype) + 0.5)\n    centers = centers.reshape(-1, 1, 1, 1, 1)\n\n    u = torch.abs(image.unsqueeze(0) - centers) / bandwidth\n\n    if kernel == \"gaussian\":\n        kernel_values = torch.exp(-0.5 * u ** 2)\n    elif kernel in (\"triangular\", \"uniform\", \"epanechnikov\",):\n        # compute the mask and cast to floating point\n        mask = (u <= 1).to(u.dtype)\n        if kernel == \"triangular\":\n            kernel_values = (1. - u) * mask\n        elif kernel == \"uniform\":\n            kernel_values = torch.ones_like(u) * mask\n        else:  # kernel == \"epanechnikov\"\n            kernel_values = (1. - u ** 2) * mask\n    else:\n        raise ValueError(f\"Kernel must be 'triangular', 'gaussian', \" f\"'uniform' or 'epanechnikov'. Got {kernel}.\")\n\n    hist = torch.sum(kernel_values, dim=(-2, -1)).permute(1, 2, 0)\n\n    if return_pdf:\n        normalization = torch.sum(hist, dim=-1, keepdim=True) + eps\n        pdf = hist / normalization\n        if image.dim() == 2:\n            hist = hist.squeeze()\n            pdf = pdf.squeeze()\n        elif image.dim() == 3:\n            hist = hist.squeeze(0)\n            pdf = pdf.squeeze(0)\n        return hist, pdf\n\n    if image.dim() == 2:\n        hist = hist.squeeze()\n    elif image.dim() == 3:\n        hist = hist.squeeze(0)\n\n    return hist, torch.zeros_like(hist)\n",
  "output": {
    "before": "from typing import Optional, Tuple\n\nimport torch\n\n\ndef marginal_pdf(\n    values: torch.Tensor, bins: torch.Tensor, sigma: torch.Tensor, epsilon: float = 1e-10\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculate the marginal probability distribution function of the input tensor based on the number of\n    histogram bins.\n\n    Args:\n        values: shape [BxNx1].\n        bins: shape [NUM_BINS].\n        sigma: shape [1], gaussian smoothing factor.\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n          - torch.Tensor: shape [BxN].\n          - torch.Tensor: shape [BxNxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(values, torch.Tensor):\n        raise TypeError(f\"Input values type is not a torch.Tensor. Got {type(values)}\")\n\n    if not isinstance(bins, torch.Tensor):\n        raise TypeError(f\"Input bins type is not a torch.Tensor. Got {type(bins)}\")\n\n    if not isinstance(sigma, torch.Tensor):\n        raise TypeError(f\"Input sigma type is not a torch.Tensor. Got {type(sigma)}\")\n\n    if not values.dim() == 3:\n        raise ValueError(\"Input values must be a of the shape BxNx1.\" \" Got {}\".format(values.shape))\n\n    if not bins.dim() == 1:\n        raise ValueError(\"Input bins must be a of the shape NUM_BINS\" \" Got {}\".format(bins.shape))\n\n    if not sigma.dim() == 0:\n        raise ValueError(\"Input sigma must be a of the shape 1\" \" Got {}\".format(sigma.shape))\n\n    residuals = values - bins.unsqueeze(0).unsqueeze(0)\n    kernel_values = torch.exp(-0.5 * (residuals / sigma).pow(2))\n\n    pdf = torch.mean(kernel_values, dim=1)\n    normalization = torch.sum(pdf, dim=1).unsqueeze(1) + epsilon\n    pdf = pdf / normalization\n\n    return pdf, kernel_values\n\n\ndef joint_pdf(kernel_values1: torch.Tensor, kernel_values2: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Calculate the joint probability distribution function of the input tensors based on the number of histogram\n    bins.\n\n    Args:\n        kernel_values1: shape [BxNxNUM_BINS].\n        kernel_values2: shape [BxNxNUM_BINS].\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        shape [BxNUM_BINSxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(kernel_values1, torch.Tensor):\n        raise TypeError(f\"Input kernel_values1 type is not a torch.Tensor. Got {type(kernel_values1)}\")\n\n    if not isinstance(kernel_values2, torch.Tensor):\n        raise TypeError(f\"Input kernel_values2 type is not a torch.Tensor. Got {type(kernel_values2)}\")\n\n    if not kernel_values1.dim() == 3:\n        raise ValueError(\"Input kernel_values1 must be a of the shape BxN.\" \" Got {}\".format(kernel_values1.shape))\n\n    if not kernel_values2.dim() == 3:\n        raise ValueError(\"Input kernel_values2 must be a of the shape BxN.\" \" Got {}\".format(kernel_values2.shape))\n\n    if kernel_values1.shape != kernel_values2.shape:\n        raise ValueError(\n            \"Inputs kernel_values1 and kernel_values2 must have the same shape.\"\n            \" Got {} and {}\".format(kernel_values1.shape, kernel_values2.shape)\n        )\n\n    joint_kernel_values = torch.matmul(kernel_values1.transpose(1, 2), kernel_values2)\n    normalization = torch.sum(joint_kernel_values, dim=(1, 2)).view(-1, 1, 1) + epsilon\n    pdf = joint_kernel_values / normalization\n\n    return pdf\n\n\ndef histogram(x: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Estimate the histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x: Input tensor to compute the histogram with shape :math:`(B, D)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins})`.\n\n    Examples:\n        >>> x = torch.rand(1, 10)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram(x, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([1, 128])\n    \"\"\"\n\n    pdf, _ = marginal_pdf(x.unsqueeze(2), bins, bandwidth, epsilon)\n\n    return pdf\n\n\ndef histogram2d(\n    x1: torch.Tensor, x2: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10\n) -> torch.Tensor:\n    \"\"\"Estimate the 2d histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x1: Input tensor to compute the histogram with shape :math:`(B, D1)`.\n        x2: Input tensor to compute the histogram with shape :math:`(B, D2)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability. Default: 1e-10.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins}), N_{bins})`.\n\n    Examples:\n        >>> x1 = torch.rand(2, 32)\n        >>> x2 = torch.rand(2, 32)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram2d(x1, x2, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([2, 128, 128])\n    \"\"\"\n\n    _, kernel_values1 = marginal_pdf(x1.unsqueeze(2), bins, bandwidth, epsilon)\n    _, kernel_values2 = marginal_pdf(x2.unsqueeze(2), bins, bandwidth, epsilon)\n\n    pdf = joint_pdf(kernel_values1, kernel_values2)\n\n    return pdf\n\n\ndef image_histogram2d(\n    image: torch.Tensor,\n    min: float = 0.0,\n    max: float = 255.0,\n    n_bins: int = 256,\n    bandwidth: Optional[float] = None,\n    centers: Optional[torch.Tensor] = None,\n    return_pdf: bool = False,\n    kernel: str = \"triangular\",\n    eps: float = 1e-10,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Estimate the histogram of the input image(s).\n\n    The calculation uses triangular kernel density estimation.\n\n    Args:\n        image: Input tensor to compute the histogram with shape\n          :math:`(H, W)`, :math:`(C, H, W)` or :math:`(B, C, H, W)`.\n        min: Lower end of the interval (inclusive).\n        max: Upper end of the interval (inclusive). Ignored when\n          :attr:`centers` is specified.\n        n_bins: The number of histogram bins. Ignored when\n          :attr:`centers` is specified.\n        bandwidth: Smoothing factor. If not specified or equal to -1,\n          :math:`(bandwidth = (max - min) / n_bins)`.\n        centers: Centers of the bins with shape :math:`(n_bins,)`.\n          If not specified or empty, it is calculated as centers of\n          equal width bins of [min, max] range.\n        return_pdf: If True, also return probability densities for\n          each bin.\n        kernel: kernel to perform kernel density estimation\n          ``(`triangular`, `gaussian`, `uniform`, `epanechnikov`)``.\n\n    Returns:\n        Computed histogram of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`.\n        Computed probability densities of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`, if return_pdf is ``True``. Tensor of zeros with shape\n          of the histogram otherwise.\n    \"\"\"\n    if image is not None and not isinstance(image, torch.Tensor):\n        raise TypeError(f\"Input image type is not a torch.Tensor. Got {type(image)}.\")\n\n    if centers is not None and not isinstance(centers, torch.Tensor):\n        raise TypeError(f\"Bins' centers type is not a torch.Tensor. Got {type(centers)}.\")\n\n    if centers is not None and len(centers.shape) > 0 and centers.dim() != 1:\n        raise ValueError(f\"Bins' centers must be a torch.Tensor of the shape (n_bins,). Got {centers.shape}.\")\n\n    if not isinstance(min, float):\n        raise TypeError(f'Type of lower end of the range is not a float. Got {type(min)}.')\n\n    if not isinstance(max, float):\n        raise TypeError(f\"Type of upper end of the range is not a float. Got {type(min)}.\")\n\n    if not isinstance(n_bins, int):\n        raise TypeError(f\"Type of number of bins is not an int. Got {type(n_bins)}.\")\n\n    if bandwidth is not None and not isinstance(bandwidth, float):\n        raise TypeError(f\"Bandwidth type is not a float. Got {type(bandwidth)}.\")\n\n    if not isinstance(return_pdf, bool):\n        raise TypeError(f\"Return_pdf type is not a bool. Got {type(return_pdf)}.\")\n\n    if bandwidth is None:\n        bandwidth = (max - min) / n_bins\n\n    if centers is None:\n        centers = min + bandwidth * (torch.arange(n_bins, device=image.device, dtype=image.dtype) + 0.5)\n    centers = centers.reshape(-1, 1, 1, 1, 1)\n\n    u = torch.abs(image.unsqueeze(0) - centers) / bandwidth\n\n    if kernel == \"gaussian\":\n        kernel_values = torch.exp(-0.5 * u ** 2)\n    elif kernel in (\"triangular\", \"uniform\", \"epanechnikov\",):\n        # compute the mask and cast to floating point\n        mask = (u <= 1).to(u.dtype)\n        if kernel == \"triangular\":\n            kernel_values = (1. - u) * mask\n        elif kernel == \"uniform\":\n            kernel_values = torch.ones_like(u) * mask\n        else:  # kernel == \"epanechnikov\"\n            kernel_values = (1. - u ** 2) * mask\n    else:\n        raise ValueError(f\"Kernel must be 'triangular', 'gaussian', \" f\"'uniform' or 'epanechnikov'. Got {kernel}.\")\n\n    hist = torch.sum(kernel_values, dim=(-2, -1)).permute(1, 2, 0)\n\n    if return_pdf:\n        normalization = torch.sum(hist, dim=-1, keepdim=True) + eps\n        pdf = hist / normalization\n        if image.dim() == 2:\n            hist = hist.squeeze()\n            pdf = pdf.squeeze()\n        elif image.dim() == 3:\n            hist = hist.squeeze(0)\n            pdf = pdf.squeeze(0)\n        return hist, pdf\n\n    if image.dim() == 2:\n        hist = hist.squeeze()\n    elif image.dim() == 3:\n        hist = hist.squeeze(0)\n\n    return hist, torch.zeros_like(hist)\n```\n\n\n**Explanation:**\n\nThis code defines several functions for working with histograms in PyTorch.  \n\n* **`marginal_pdf`:** Calculates the marginal probability density function (PDF) of a tensor for a given number of bins.\n",
    "after": "from typing import Optional, Tuple\n\nimport torch\n\n\ndef marginal_pdf(\n    values: torch.Tensor, bins: torch.Tensor, sigma: torch.Tensor, epsilon: float = 1e-10\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Calculate the marginal probability distribution function of the input tensor based on the number of\n    histogram bins.\n\n    Args:\n        values: shape [BxNx1].\n        bins: shape [NUM_BINS].\n        sigma: shape [1], gaussian smoothing factor.\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n          - torch.Tensor: shape [BxN].\n          - torch.Tensor: shape [BxNxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(values, torch.Tensor):\n        raise TypeError(f\"Input values type is not a torch.Tensor. Got {type(values)}\")\n\n    if not isinstance(bins, torch.Tensor):\n        raise TypeError(f\"Input bins type is not a torch.Tensor. Got {type(bins)}\")\n\n    if not isinstance(sigma, torch.Tensor):\n        raise TypeError(f\"Input sigma type is not a torch.Tensor. Got {type(sigma)}\")\n\n    if not values.dim() == 3:\n        raise ValueError(\"Input values must be a of the shape BxNx1.\" \" Got {}\".format(values.shape))\n\n    if not bins.dim() == 1:\n        raise ValueError(\"Input bins must be a of the shape NUM_BINS\" \" Got {}\".format(bins.shape))\n\n    if not sigma.dim() == 0:\n        raise ValueError(\"Input sigma must be a of the shape 1\" \" Got {}\".format(sigma.shape))\n\n    residuals = values - bins.unsqueeze(0).unsqueeze(0)\n    kernel_values = torch.exp(-0.5 * (residuals / sigma).pow(2))\n\n    pdf = torch.mean(kernel_values, dim=1)\n    normalization = torch.sum(pdf, dim=1).unsqueeze(1) + epsilon\n    pdf = pdf / normalization\n\n    return pdf, kernel_values\n\n\ndef joint_pdf(kernel_values1: torch.Tensor, kernel_values2: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Calculate the joint probability distribution function of the input tensors based on the number of histogram\n    bins.\n\n    Args:\n        kernel_values1: shape [BxNxNUM_BINS].\n        kernel_values2: shape [BxNxNUM_BINS].\n        epsilon: scalar, for numerical stability.\n\n    Returns:\n        shape [BxNUM_BINSxNUM_BINS].\n    \"\"\"\n\n    if not isinstance(kernel_values1, torch.Tensor):\n        raise TypeError(f\"Input kernel_values1 type is not a torch.Tensor. Got {type(kernel_values1)}\")\n\n    if not isinstance(kernel_values2, torch.Tensor):\n        raise TypeError(f\"Input kernel_values2 type is not a torch.Tensor. Got {type(kernel_values2)}\")\n\n    if not kernel_values1.dim() == 3:\n        raise ValueError(\"Input kernel_values1 must be a of the shape BxN.\" \" Got {}\".format(kernel_values1.shape))\n\n    if not kernel_values2.dim() == 3:\n        raise ValueError(\"Input kernel_values2 must be a of the shape BxN.\" \" Got {}\".format(kernel_values2.shape))\n\n    if kernel_values1.shape != kernel_values2.shape:\n        raise ValueError(\n            \"Inputs kernel_values1 and kernel_values2 must have the same shape.\"\n            \" Got {} and {}\".format(kernel_values1.shape, kernel_values2.shape)\n        )\n\n    joint_kernel_values = torch.matmul(kernel_values1.transpose(1, 2), kernel_values2)\n    normalization = torch.sum(joint_kernel_values, dim=(1, 2)).view(-1, 1, 1) + epsilon\n    pdf = joint_kernel_values / normalization\n\n    return pdf\n\n\ndef histogram(x: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n    \"\"\"Estimate the histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x: Input tensor to compute the histogram with shape :math:`(B, D)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins})`.\n\n    Examples:\n        >>> x = torch.rand(1, 10)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram(x, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([1, 128])\n    \"\"\"\n\n    pdf, _ = marginal_pdf(x.unsqueeze(2), bins, bandwidth, epsilon)\n\n    return pdf\n\n\ndef histogram2d(\n    x1: torch.Tensor, x2: torch.Tensor, bins: torch.Tensor, bandwidth: torch.Tensor, epsilon: float = 1e-10\n) -> torch.Tensor:\n    \"\"\"Estimate the 2d histogram of the input tensor.\n\n    The calculation uses kernel density estimation which requires a bandwidth (smoothing) parameter.\n\n    Args:\n        x1: Input tensor to compute the histogram with shape :math:`(B, D1)`.\n        x2: Input tensor to compute the histogram with shape :math:`(B, D2)`.\n        bins: The number of bins to use the histogram :math:`(N_{bins})`.\n        bandwidth: Gaussian smoothing factor with shape shape [1].\n        epsilon: A scalar, for numerical stability. Default: 1e-10.\n\n    Returns:\n        Computed histogram of shape :math:`(B, N_{bins}), N_{bins})`.\n\n    Examples:\n        >>> x1 = torch.rand(2, 32)\n        >>> x2 = torch.rand(2, 32)\n        >>> bins = torch.torch.linspace(0, 255, 128)\n        >>> hist = histogram2d(x1, x2, bins, bandwidth=torch.tensor(0.9))\n        >>> hist.shape\n        torch.Size([2, 128, 128])\n    \"\"\"\n\n    _, kernel_values1 = marginal_pdf(x1.unsqueeze(2), bins, bandwidth, epsilon)\n    _, kernel_values2 = marginal_pdf(x2.unsqueeze(2), bins, bandwidth, epsilon)\n\n    pdf = joint_pdf(kernel_values1, kernel_values2)\n\n    return pdf\n\n\ndef image_histogram2d(\n    image: torch.Tensor,\n    min: float = 0.0,\n    max: float = 255.0,\n    n_bins: int = 256,\n    bandwidth: Optional[float] = None,\n    centers: Optional[torch.Tensor] = None,\n    return_pdf: bool = False,\n    kernel: str = \"triangular\",\n    eps: float = 1e-10,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Estimate the histogram of the input image(s).\n\n    The calculation uses triangular kernel density estimation.\n\n    Args:\n        image: Input tensor to compute the histogram with shape\n          :math:`(H, W)`, :math:`(C, H, W)` or :math:`(B, C, H, W)`.\n        min: Lower end of the interval (inclusive).\n        max: Upper end of the interval (inclusive). Ignored when\n          :attr:`centers` is specified.\n        n_bins: The number of histogram bins. Ignored when\n          :attr:`centers` is specified.\n        bandwidth: Smoothing factor. If not specified or equal to -1,\n          :math:`(bandwidth = (max - min) / n_bins)`.\n        centers: Centers of the bins with shape :math:`(n_bins,)`.\n          If not specified or empty, it is calculated as centers of\n          equal width bins of [min, max] range.\n        return_pdf: If True, also return probability densities for\n          each bin.\n        kernel: kernel to perform kernel density estimation\n          ``(`triangular`, `gaussian`, `uniform`, `epanechnikov`)``.\n\n    Returns:\n        Computed histogram of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`.\n        Computed probability densities of shape :math:`(bins)`, :math:`(C, bins)`,\n          :math:`(B, C, bins)`, if return_pdf is ``True``. Tensor of zeros with shape\n          of the histogram otherwise.\n    \"\"\"\n    if image is not None and not isinstance(image, torch.Tensor):\n        raise TypeError(f\"Input image type is not a torch.Tensor. Got {type(image)}.\")\n\n    if centers is not None and not isinstance(centers, torch.Tensor):\n        raise TypeError(f\"Bins' centers type is not a torch.Tensor. Got {type(centers)}.\")\n\n    if centers is not None and len(centers.shape) > 0 and centers.dim() != 1:\n        raise ValueError(f\"Bins' centers must be a torch.Tensor of the shape (n_bins,). Got {centers.shape}.\")\n\n    if not isinstance(min, float):\n        raise TypeError(f'Type of lower end of the range is not a float. Got {type(min)}.')\n\n    if not isinstance(max, float):\n        raise TypeError(f\"Type of upper end of the range is not a float. Got {type(min)}.\")\n\n    if not isinstance(n_bins, int):\n        raise TypeError(f\"Type of number of bins is not an int. Got {type(n_bins)}.\")\n\n    if bandwidth is not None and not isinstance(bandwidth, float):\n        raise TypeError(f\"Bandwidth type is not a float. Got {type(bandwidth)}.\")\n\n    if not isinstance(return_pdf, bool):\n        raise TypeError(f\"Return_pdf type is not a bool. Got {type(return_pdf)}.\")\n\n    if bandwidth is None:\n        bandwidth = (max - min) / n_bins\n\n    if centers is None:\n        centers = min + bandwidth * (torch.arange(n_bins, device=image.device, dtype=image.dtype) + 0.5)\n    centers = centers.reshape(-1, 1, 1, 1, 1)\n\n    u = torch.abs(image.unsqueeze(0) - centers) / bandwidth\n\n    if kernel == \"gaussian\":\n        kernel_values = torch.exp(-0.5 * u ** 2)\n    elif kernel in (\"triangular\", \"uniform\", \"epanechnikov\",):\n        # compute the mask and cast to floating point\n        mask = (u <= 1).to(u.dtype)\n        if kernel == \"triangular\":\n            kernel_values = (1. - u) * mask\n        elif kernel == \"uniform\":\n            kernel_values = torch.ones_like(u) * mask\n        else:  # kernel == \"epanechnikov\"\n            kernel_values = (1. - u ** 2) * mask\n    else:\n        raise ValueError(f\"Kernel must be 'triangular', 'gaussian', \" f\"'uniform' or 'epanechnikov'. Got {kernel}.\")\n\n    hist = torch.sum(kernel_values, dim=(-2, -1)).permute(1, 2, 0)\n\n    if return_pdf:\n        normalization = torch.sum(hist, dim=-1, keepdim=True) + eps\n        pdf = hist / normalization\n        if image.dim() == 2:\n            hist = hist.squeeze()\n            pdf = pdf.squeeze()\n        elif image.dim() == 3:\n            hist = hist.squeeze(0)\n            pdf = pdf.squeeze(0)\n        return hist, pdf\n\n    if image.dim() == 2:\n        hist = hist.squeeze()\n    elif image.dim() == 3:\n        hist = hist.squeeze(0)\n\n    return hist, torch.zeros_like(hist)\n```\n\nThis code defines a `histogram2d` function that can be used to estimate the histogram of 2D data. It uses a combination of kernel density estimation and histogram binning to estimate the probability distribution of data.\n\n\n**Key points"
  },
  "feature_stats": {
    "indices": [
      2,
      0,
      1,
      418,
      5597,
      1641,
      5933,
      8191,
      2275,
      3814,
      5780
    ],
    "f_before": [
      0.0,
      0.0,
      43.94951629638672,
      0.0,
      0.0,
      0.465216726064682,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      0.0,
      43.94951629638672,
      0.0,
      0.0,
      0.465216726064682,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_before": [
      7.844775676727295,
      0.024391954764723778,
      0.0,
      0.010694734752178192,
      0.0,
      0.0,
      0.027060523629188538,
      0.0,
      0.07386557012796402,
      0.004375823773443699,
      0.006374821998178959
    ],
    "g_after": [
      7.844775676727295,
      0.024391954764723778,
      0.0,
      0.010694734752178192,
      0.0,
      0.0,
      0.027060523629188538,
      0.0,
      0.07386557012796402,
      0.004375823773443699,
      0.006374821998178959
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 15.652211345553399,
    "train_mean_l2": 11.55342114698887,
    "train_mean_l1": 4.098790381908417,
    "num_steps": 1000,
    "num_batches": 1000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251126-175135/feature_std_layer_12.html",
    "mean_std": 1.074162483215332,
    "max_std": 22.999488830566406
  }
}