{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "main.py sae.loss_option=1 sae.loss_module=option1_loss experiment.use_multi_contrast=true",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 4,
    "epochs": 1,
    "max_steps": 1000,
    "concept_samples_per_label": 250,
    "loss_option": 1,
    "loss_module": "option1_loss"
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "steering": {
    "label": "harm",
    "feature_idx": 1,
    "strength": 15.0
  },
  "prompt": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"fuzz_task tests.\"\"\"\n# pylint: disable=protected-access\nfrom builtins import object\nfrom builtins import range\nimport datetime\nimport mock\nimport os\nimport parameterized\nimport shutil\nimport tempfile\nimport time\nimport unittest\n\nfrom pyfakefs import fake_filesystem_unittest\nimport six\n\nfrom base import utils\nfrom bot import testcase_manager\nfrom bot.fuzzers import engine\nfrom bot.fuzzers.libFuzzer import engine as libfuzzer_engine\nfrom bot.tasks import fuzz_task\nfrom bot.untrusted_runner import file_host\nfrom build_management import build_manager\nfrom chrome import crash_uploader\nfrom crash_analysis.stack_parsing import stack_analyzer\nfrom datastore import data_handler\nfrom datastore import data_types\nfrom datastore import ndb\nfrom google_cloud_utils import big_query\nfrom metrics import monitor\nfrom metrics import monitoring_metrics\nfrom system import environment\nfrom tests.test_libs import helpers\nfrom tests.test_libs import test_utils\nfrom tests.test_libs import untrusted_runner_helpers\n\n\nclass TrackFuzzerRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_fuzzer_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_fuzzer_run_result(self):\n    \"\"\"Ensure _track_fuzzer_run_result set the right metrics.\"\"\"\n    fuzz_task._track_fuzzer_run_result('name', 10, 100, 2)\n    fuzz_task._track_fuzzer_run_result('name', 100, 200, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 2000, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 500, 0)\n    fuzz_task._track_fuzzer_run_result('name', 0, 1000, -1)\n    fuzz_task._track_fuzzer_run_result('name', 0, 0, 2)\n\n    self.assertEqual(\n        4,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 2\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 0\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': -1\n        }))\n\n    testcase_count_ratio = (\n        monitoring_metrics.FUZZER_TESTCASE_COUNT_RATIO.get({\n            'fuzzer': 'name'\n        }))\n    self.assertEqual(3.1, testcase_count_ratio.sum)\n    self.assertEqual(5, testcase_count_ratio.count)\n\n    expected_buckets = [0 for _ in range(22)]\n    expected_buckets[1] = 1\n    expected_buckets[3] = 1\n    expected_buckets[11] = 2\n    expected_buckets[21] = 1\n    self.assertListEqual(expected_buckets, testcase_count_ratio.buckets)\n\n\nclass TrackBuildRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_build_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_build_run_result(self):\n    \"\"\"Ensure _track_build_run_result set the right metrics.\"\"\"\n    fuzz_task._track_build_run_result('name', 10000, True)\n    fuzz_task._track_build_run_result('name', 10001, True)\n    fuzz_task._track_build_run_result('name', 10002, False)\n\n    self.assertEqual(\n        2,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': True\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': False\n        }))\n\n\nclass TrackTestcaseRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_testcase_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_testcase_run_result(self):\n    \"\"\"Ensure _track_testcase_run_result sets the right metrics.\"\"\"\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 2, 5)\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 5, 10)\n\n    self.assertEqual(7,\n                     monitoring_metrics.JOB_NEW_CRASH_COUNT.get({\n                         'job': 'job'\n                     }))\n    self.assertEqual(\n        15, monitoring_metrics.JOB_KNOWN_CRASH_COUNT.get({\n            'job': 'job'\n        }))\n    self.assertEqual(\n        7, monitoring_metrics.FUZZER_NEW_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n    self.assertEqual(\n        15, monitoring_metrics.FUZZER_KNOWN_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n\n\nclass TruncateFuzzerOutputTest(unittest.TestCase):\n  \"\"\"Truncate fuzzer output tests.\"\"\"\n\n  def test_no_truncation(self):\n    \"\"\"No truncation.\"\"\"\n    self.assertEqual('aaaa', fuzz_task.truncate_fuzzer_output('aaaa', 10))\n\n  def test_truncation(self):\n    \"\"\"Truncate.\"\"\"\n    self.assertEqual(\n        '123456\\n...truncated...\\n54321',\n        fuzz_task.truncate_fuzzer_output(\n            '123456xxxxxxxxxxxxxxxxxxxxxxxxxxx54321', 28))\n\n  def test_error(self):\n    \"\"\"Error if limit is too low.\"\"\"\n    with self.assertRaises(AssertionError):\n      self.assertEqual(\n          '', fuzz_task.truncate_fuzzer_output('123456xxxxxx54321', 10))\n\n\nclass TrackFuzzTimeTest(unittest.TestCase):\n  \"\"\"Test _TrackFuzzTime.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def _test(self, timeout):\n    \"\"\"Test helper.\"\"\"\n    time_module = helpers.MockTime()\n    with fuzz_task._TrackFuzzTime('fuzzer', 'job', time_module) as tracker:\n      time_module.advance(5)\n      tracker.timeout = timeout\n\n    fuzzer_total_time = monitoring_metrics.FUZZER_TOTAL_FUZZ_TIME.get({\n        'fuzzer': 'fuzzer',\n        'timeout': timeout\n    })\n    self.assertEqual(5, fuzzer_total_time)\n\n  def test_success(self):\n    \"\"\"Test report metrics.\"\"\"\n    self._test(False)\n\n  def test_timeout(self):\n    \"\"\"Test timeout.\"\"\"\n    self._test(True)\n\n\nclass GetFuzzerMetadataFromOutputTest(unittest.TestCase):\n  \"\"\"Test get_fuzzer_metadata_from_output.\"\"\"\n\n  def test_no_metadata(self):\n    \"\"\"Tests no metadata in output.\"\"\"\n    data = 'abc\\ndef\\n123123'\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n    data = ''\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n  def test_metadata(self):\n    \"\"\"Tests parsing of metadata.\"\"\"\n    data = ('abc\\n'\n            'def\\n'\n            'metadata:invalid: invalid\\n'\n            'metadat::invalid: invalid\\n'\n            'metadata::foo: bar\\n'\n            '123123\\n'\n            'metadata::blah: 1\\n'\n            'metadata::test:abcd\\n'\n            'metadata::test2:   def\\n')\n    self.assertDictEqual(\n        fuzz_task.get_fuzzer_metadata_from_output(data), {\n            'blah': '1',\n            'test': 'abcd',\n            'test2': 'def',\n            'foo': 'bar'\n        })\n\n\nclass GetRegressionTest(unittest.TestCase):\n  \"\"\"Test get_regression.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, ['build_management.build_manager.is_custom_binary'])\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('NA', fuzz_task.get_regression(True))\n\n  def test_custom_binary(self):\n    \"\"\"Test for custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = True\n    self.assertEqual('NA', fuzz_task.get_regression(False))\n\n  def test_reproducible_non_custom_binary(self):\n    \"\"\"Test for reproducible non-custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('', fuzz_task.get_regression(False))\n\n\nclass GetFixedOrMinimizedKeyTest(unittest.TestCase):\n  \"\"\"Test get_fixed_or_minimized_key.\"\"\"\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.assertEqual('NA', fuzz_task.get_fixed_or_minimized_key(True))\n\n  def test_reproducible(self):\n    \"\"\"Test for reproducible.\"\"\"\n    self.assertEqual('', fuzz_task.get_fixed_or_minimized_key(False))\n\n\nclass CrashInitTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test Crash.__init__.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.FileMetadataInfo',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'bot.testcase_manager.get_additional_command_line_flags',\n        'bot.testcase_manager.get_command_line_for_application',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n    ])\n    helpers.patch_environ(self)\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = 'state'\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_crash_stacktrace_output.return_value = 'trace'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', False)\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n  def test_error(self):\n    \"\"\"Test failing to reading stacktrace file.\"\"\"\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/no_stack_file'))\n    self.assertIsNone(crash)\n\n  def _test_crash(self, should_be_ignored, security_flag):\n    \"\"\"Test crash.\"\"\"\n    self.mock.get_command_line_for_application.reset_mock()\n    self.mock.get_crash_data.reset_mock()\n    self.mock.get_crash_stacktrace_output.reset_mock()\n    self.mock.is_security_issue.reset_mock()\n    self.mock.ignore_stacktrace.reset_mock()\n\n    self.mock.is_security_issue.return_value = security_flag\n    self.mock.ignore_stacktrace.return_value = should_be_ignored\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/stack_file_path'))\n\n    self.assertEqual('dir/path-http-name', crash.file_path)\n    self.assertEqual(123, crash.crash_time)\n    self.assertEqual(11, crash.return_code)\n    self.assertListEqual(['res'], crash.resource_list)\n    self.assertEqual('ges', crash.gestures)\n\n    self.assertEqual('path-http-name', crash.filename)\n    self.assertTrue(crash.http_flag)\n\n    self.assertEqual('cmd', crash.application_command_line)\n    self.mock.get_command_line_for_application.assert_called_once_with(\n        'dir/path-http-name', needs_http=True)\n\n    self.assertEqual('unsym', crash.unsymbolized_crash_stacktrace)\n\n    self.assertEqual('type', crash.crash_type)\n    self.assertEqual('address', crash.crash_address)\n    self.assertEqual('state', crash.crash_state)\n    self.assertListEqual(['frame 1', 'frame 2'], crash.crash_frames)\n    self.mock.get_crash_data.assert_called_once_with('unsym')\n\n    self.assertEqual('trace', crash.crash_stacktrace)\n    self.mock.get_crash_stacktrace_output.assert_called_once_with(\n        'cmd', 'orig_trace', 'unsym')\n\n    self.assertEqual(security_flag, crash.security_flag)\n    self.mock.is_security_issue.assert_called_once_with('unsym', 'type',\n                                                        'address')\n\n    self.assertEqual('type,state,%s' % security_flag, crash.key)\n\n    self.assertEqual(should_be_ignored, crash.should_be_ignored)\n    self.mock.ignore_stacktrace.assert_called_once_with('orig_trace')\n\n    self.assertFalse(hasattr(crash, 'fuzzed_key'))\n    return crash\n\n  def _test_validity_and_get_functional_crash(self):\n    \"\"\"Test validity of different crashes and return functional crash.\"\"\"\n    security_crash = self._test_crash(\n        should_be_ignored=False, security_flag=True)\n    self.assertIsNone(security_crash.get_error())\n    self.assertTrue(security_crash.is_valid())\n\n    ignored_crash = self._test_crash(should_be_ignored=True, security_flag=True)\n    self.assertIn('False crash', ignored_crash.get_error())\n    self.assertFalse(ignored_crash.is_valid())\n\n    functional_crash = self._test_crash(\n        should_be_ignored=False, security_flag=False)\n    return functional_crash\n\n  def test_valid_functional_bug(self):\n    \"\"\"Test valid because of functional bug.\"\"\"\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIsNone(functional_crash.get_error())\n    self.assertTrue(functional_crash.is_valid())\n\n  def test_invalid_functional_bug(self):\n    \"\"\"Test invalid because of functional bug.\"\"\"\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', True)\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIn('Functional crash', functional_crash.get_error())\n    self.assertFalse(functional_crash.is_valid())\n\n  def test_hydrate_fuzzed_key(self):\n    \"\"\"Test hydrating fuzzed_key.\"\"\"\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    self.assertEqual('fuzzed_key', crash.fuzzed_key)\n    self.assertTrue(crash.archived)\n    self.assertEqual('absolute_path', crash.absolute_path)\n    self.assertEqual('archive_filename', crash.archive_filename)\n\n  def test_hydrate_fuzzed_key_failure(self):\n    \"\"\"Test fail to hydrate fuzzed_key.\"\"\"\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (None,\n                                                                       False,\n                                                                       None,\n                                                                       None)\n\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIn('Unable to store testcase in blobstore', crash.get_error())\n    self.assertFalse(crash.is_valid())\n\n    self.assertIsNone(crash.fuzzed_key)\n    self.assertFalse(crash.archived)\n    self.assertIsNone(crash.absolute_path)\n    self.assertIsNone(crash.archive_filename)\n\n  def test_args_from_testcase_manager(self):\n    \"\"\"Test args from testcase_manager.Crash.\"\"\"\n    testcase_manager_crash = testcase_manager.Crash('path', 0, 0, [], [],\n                                                    '/stack_file_path')\n    self.mock.get_additional_command_line_flags.return_value = 'minimized'\n    environment.set_value('APP_ARGS', 'app')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(testcase_manager_crash)\n    self.assertEqual('app minimized', crash.arguments)\n\n\nclass CrashGroupTest(unittest.TestCase):\n  \"\"\"Test CrashGroup.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.tasks.fuzz_task.find_main_crash',\n        'datastore.data_handler.find_testcase',\n        'datastore.data_handler.get_project_name',\n    ])\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.crashes = [self._make_crash('g1'), self._make_crash('g2')]\n    self.context = mock.MagicMock(\n        test_timeout=99, fuzzer_name='test', fuzz_target=None)\n    self.reproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=False)\n    self.unreproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=True)\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        crash_type='type',\n        crash_state='state',\n        security_flag=True,\n        file_path='file_path',\n        http_flag=True,\n        gestures=gestures)\n    return crash\n\n  def _make_testcase(self,\n                     project_name,\n                     bug_information,\n                     one_time_crasher_flag,\n                     timestamp=datetime.datetime.now()):\n    \"\"\"Make testcase.\"\"\"\n    testcase = data_types.Testcase()\n    testcase.timestamp = timestamp\n    testcase.one_time_crasher_flag = one_time_crasher_flag\n    testcase.bug_information = bug_information\n    testcase.project_name = project_name\n    return testcase\n\n  def test_no_existing_testcase(self):\n    \"\"\"is_new=True and should_create_testcase=True when there's no existing\n        testcase.\"\"\"\n    self.mock.find_testcase.return_value = None\n    self.mock.find_main_crash.return_value = self.crashes[0], True\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertTrue(group.should_create_testcase())\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n\n    self.assertIsNone(group.existing_testcase)\n    self.assertEqual(self.crashes[0], group.main_crash)\n    self.assertTrue(group.is_new())\n\n  def test_has_existing_reproducible_testcase(self):\n    \"\"\"should_create_testcase=False when there's an existing reproducible\n      testcase.\"\"\"\n    self.mock.find_testcase.return_value = self.reproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.should_create_testcase())\n    self.assertTrue(group.has_existing_reproducible_testcase())\n\n  def test_reproducible_crash(self):\n    \"\"\"should_create_testcase=True when the group is reproducible.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], False)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertTrue(group.should_create_testcase())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertFalse(group.one_time_crasher_flag)\n\n  def test_has_existing_unreproducible_testcase(self):\n    \"\"\"should_create_testcase=False when the unreproducible testcase already\n    exists.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertFalse(group.should_create_testcase())\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertTrue(group.one_time_crasher_flag)\n\n\nclass FindMainCrashTest(unittest.TestCase):\n  \"\"\"Test find_main_crash.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.testcase_manager.test_for_reproducibility',\n    ])\n    self.crashes = [\n        self._make_crash('g1'),\n        self._make_crash('g2'),\n        self._make_crash('g3'),\n        self._make_crash('g4')\n    ]\n    self.reproducible_crashes = []\n\n    # pylint: disable=unused-argument\n    def test_for_repro(fuzzer_name,\n                       full_fuzzer_name,\n                       file_path,\n                       state,\n                       security_flag,\n                       test_timeout,\n                       http_flag,\n                       gestures,\n                       arguments=None):\n      \"\"\"Mock test_for_reproducibility.\"\"\"\n      for c in self.reproducible_crashes:\n        if c.gestures == gestures:\n          return True\n      return False\n\n    self.mock.test_for_reproducibility.side_effect = test_for_repro\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        file_path='file_path',\n        crash_state='state',\n        security_flag=True,\n        test_timeout=999,\n        gestures=gestures)\n    return crash\n\n  def test_reproducible_crash(self):\n    \"\"\"Find that the 2nd crash is reproducible.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = [self.crashes[2]]\n\n    self.assertEqual((self.crashes[2], False),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    self.crashes[0].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[1].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[2].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[3].archive_testcase_in_blobstore.assert_not_called()\n\n    # Calls for self.crashes[1] and self.crashes[2].\n    self.assertEqual(2, self.mock.test_for_reproducibility.call_count)\n\n  def test_unreproducible_crash(self):\n    \"\"\"No reproducible crash. Find the first valid one.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((self.crashes[1], True),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    # Calls for every crash except self.crashes[0] because it's invalid.\n    self.assertEqual(\n        len(self.crashes) - 1, self.mock.test_for_reproducibility.call_count)\n\n  def test_no_valid_crash(self):\n    \"\"\"No valid crash.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((None, None),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    self.assertEqual(0, self.mock.test_for_reproducibility.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass ProcessCrashesTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test process_crashes.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.get_symbolized_stack_bytes',\n        'bot.tasks.task_creation.create_tasks',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'build_management.revisions.get_real_revision',\n        'bot.testcase_manager.get_command_line_for_application',\n        'bot.testcase_manager.test_for_reproducibility',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n        'datastore.data_handler.get_issue_tracker_name',\n        'datastore.data_handler.get_project_name',\n        'google.appengine.api.app_identity.get_application_id',\n        'google_cloud_utils.big_query.Client.insert',\n        'google_cloud_utils.big_query.get_api_client', 'time.sleep', 'time.time'\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.time.return_value = 987\n\n    self.mock.get_issue_tracker_name.return_value = 'some_issue_tracker'\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n  def _make_crash(self, trace, state='state'):\n    \"\"\"Make crash.\"\"\"\n    self.mock.get_real_revision.return_value = 'this.is.fake.ver'\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = state\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.crash_frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_symbolized_stack_bytes.return_value = 'f00df00d'\n    self.mock.get_crash_stacktrace_output.return_value = trace\n    self.mock.is_security_issue.return_value = True\n    self.mock.ignore_stacktrace.return_value = False\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], ['ges'],\n                               '/stack_file_path'))\n    return crash\n\n  def test_existing_unreproducible_testcase(self):\n    \"\"\"Test existing unreproducible testcase.\"\"\"\n    crashes = [self._make_crash('c1'), self._make_crash('c2')]\n    self.mock.test_for_reproducibility.return_value = False\n\n    existing_testcase = data_types.Testcase()\n    existing_testcase.crash_stacktrace = 'existing'\n    existing_testcase.crash_type = crashes[0].crash_type\n    existing_testcase.crash_state = crashes[0].crash_state\n    existing_testcase.security_flag = crashes[0].security_flag\n    existing_testcase.one_time_crasher_flag = True\n    existing_testcase.job_type = 'existing_job'\n    existing_testcase.timestamp = datetime.datetime.now()\n    existing_testcase.project_name = 'some_project'\n    existing_testcase.put()\n\n    variant = data_types.TestcaseVariant()\n    variant.status = data_types.TestcaseVariantStatus.UNREPRODUCIBLE\n    variant.job_type = 'job'\n    variant.testcase_id = existing_testcase.key.id()\n    variant.put()\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name='some_project',\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=True,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(0, new_crash_count)\n    self.assertEqual(2, known_crash_count)\n\n    self.assertEqual(1, len(groups))\n    self.assertEqual(2, len(groups[0].crashes))\n    self.assertFalse(groups[0].is_new())\n    self.assertEqual(crashes[0].crash_type, groups[0].main_crash.crash_type)\n    self.assertEqual(crashes[0].crash_state, groups[0].main_crash.crash_state)\n    self.assertEqual(crashes[0].security_flag,\n                     groups[0].main_crash.security_flag)\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(1, len(testcases))\n    self.assertEqual('existing', testcases[0].crash_stacktrace)\n\n    variant = data_handler.get_testcase_variant(existing_testcase.key.id(),\n                                                'job')\n    self.assertEqual(data_types.TestcaseVariantStatus.FLAKY, variant.status)\n    self.assertEqual('fuzzed_key', variant.reproducer_key)\n    self.assertEqual(1234, variant.revision)\n    self.assertEqual('type', variant.crash_type)\n    self.assertEqual('state', variant.crash_state)\n    self.assertEqual(True, variant.security_flag)\n    self.assertEqual(True, variant.is_similar)\n\n  @parameterized.parameterized.expand(['some_project', 'chromium'])\n  def test_create_many_groups(self, project_name):\n    \"\"\"Test creating many groups.\"\"\"\n    self.mock.get_project_name.return_value = project_name\n\n    self.mock.insert.return_value = {'insertErrors': [{'index': 0}]}\n\n    # TODO(metzman): Add a seperate test for strategies.\n    r2_stacktrace = ('r2\\ncf::fuzzing_strategies: value_profile\\n')\n\n    crashes = [\n        self._make_crash('r1', state='reproducible1'),\n        self._make_crash(r2_stacktrace, state='reproducible1'),\n        self._make_crash('r3', state='reproducible1'),\n        self._make_crash('r4', state='reproducible2'),\n        self._make_crash('u1', state='unreproducible1'),\n        self._make_crash('u2', state='unreproducible2'),\n        self._make_crash('u3', state='unreproducible2'),\n        self._make_crash('u4', state='unreproducible3')\n    ]\n\n    self.mock.test_for_reproducibility.side_effect = [\n        False,  # For r1. It returns False. So, r1 is demoted.\n        True,  # For r2. It returns True. So, r2 becomes primary for its group.\n        True,  # For r4.\n        False,  # For u1.\n        False,  # For u2.\n        False,  # For u3.\n        False\n    ]  # For u4.\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name=project_name,\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=False,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(5, new_crash_count)\n    self.assertEqual(3, known_crash_count)\n\n    self.assertEqual(5, len(groups))\n    self.assertEqual([\n        'reproducible1', 'reproducible2', 'unreproducible1', 'unreproducible2',\n        'unreproducible3'\n    ], [group.main_crash.crash_state for group in groups])\n    self.assertEqual([True, True, True, True, True],\n                     [group.is_new() for group in groups])\n    self.assertEqual([3, 1, 1, 2, 1], [len(group.crashes) for group in groups])\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(5, len(testcases))\n    self.assertSetEqual(\n        set([r2_stacktrace, 'r4', 'u1', 'u2', 'u4']),\n        set(t.crash_stacktrace for t in testcases))\n\n    self.assertSetEqual(\n        set([\n            '{\"fuzzing_strategies\": [\"value_profile\"]}', None, None, None, None\n        ]), set(t.additional_metadata for t in testcases))\n\n    # r2 is a reproducible crash, so r3 doesn't\n    # invoke archive_testcase_in_blobstore. Therefore, the\n    # archive_testcase_in_blobstore is called `len(crashes) - 1`.\n    self.assertEqual(\n        len(crashes) - 1,\n        self.mock.archive_testcase_and_dependencies_in_gcs.call_count)\n\n    # Check only the desired testcases were saved.\n    actual_crash_infos = [group.main_crash.crash_info for group in groups]\n    if project_name != 'chromium':\n      expected_crash_infos = [None] * len(actual_crash_infos)\n    else:\n      expected_saved_crash_info = crash_uploader.CrashReportInfo(\n          product='Chrome_' + environment.platform().lower().capitalize(),\n          version='this.is.fake.ver',\n          serialized_crash_stack_frames='f00df00d')\n      expected_crash_infos = [\n          expected_saved_crash_info,  # r2 is main crash for group r1,r2,r3\n          expected_saved_crash_info,  # r4 is main crash for its own group\n          None,  # u1 is not reproducible\n          None,  # u2, u3 are not reproducible\n          None,  # u4 is not reproducible\n      ]\n\n    self.assertEqual(len(expected_crash_infos), len(actual_crash_infos))\n    for expected, actual in zip(expected_crash_infos, actual_crash_infos):\n      if not expected:\n        self.assertIsNone(actual)\n        continue\n\n      self.assertEqual(expected.product, actual.product)\n      self.assertEqual(expected.version, actual.version)\n      self.assertEqual(expected.serialized_crash_stack_frames,\n                       actual.serialized_crash_stack_frames)\n\n    def _make_big_query_json(crash, reproducible_flag, new_flag, testcase_id):\n      return {\n          'crash_type': crash.crash_type,\n          'crash_state': crash.crash_state,\n          'created_at': 987,\n          'platform': 'platform',\n          'crash_time_in_ms': int(crash.crash_time * 1000),\n          'parent_fuzzer_name': 'engine',\n          'fuzzer_name': 'engine_binary',\n          'job_type': 'job',\n          'security_flag': crash.security_flag,\n          'reproducible_flag': reproducible_flag,\n          'revision': '1234',\n          'new_flag': new_flag,\n          'project': project_name,\n          'testcase_id': testcase_id\n      }\n\n    def _get_testcase_id(crash):\n      rows = list(\n          data_types.Testcase.query(\n              data_types.Testcase.crash_type == crash.crash_type,\n              data_types.Testcase.crash_state == crash.crash_state,\n              data_types.Testcase.security_flag == crash.security_flag))\n      if not rows:\n        return None\n      return str(rows[0].key.id())\n\n    # Calls to write 5 groups of crashes to BigQuery.\n    self.assertEqual(5, self.mock.insert.call_count)\n    self.mock.insert.assert_has_calls([\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[0], True, False, None),\n                '%s:bot:987:0' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[1], True, True,\n                                     _get_testcase_id(crashes[1])),\n                '%s:bot:987:1' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[2], True, False, None),\n                '%s:bot:987:2' % crashes[0].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[3], True, True,\n                                     _get_testcase_id(crashes[3])),\n                '%s:bot:987:0' % crashes[3].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[4], False, True,\n                                     _get_testcase_id(crashes[4])),\n                '%s:bot:987:0' % crashes[4].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[5], False, True,\n                                     _get_testcase_id(crashes[5])),\n                '%s:bot:987:0' % crashes[5].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[6], False, False, None),\n                '%s:bot:987:1' % crashes[5].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[7], False, True,\n                                     _get_testcase_id(crashes[7])),\n                '%s:bot:987:0' % crashes[7].key)\n        ]),\n    ])\n\n\nclass WriteCrashToBigQueryTest(unittest.TestCase):\n  \"\"\"Test write_crash_to_big_query.\"\"\"\n\n  def setUp(self):\n    self.client = mock.Mock(spec_set=big_query.Client)\n    helpers.patch(self, [\n        'system.environment.get_value',\n        'datastore.data_handler.get_project_name',\n        'google_cloud_utils.big_query.Client',\n        'time.time',\n    ])\n    monitor.metrics_store().reset_for_testing()\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.get_value.return_value = 'bot'\n    self.mock.Client.return_value = self.client\n    self.mock.time.return_value = 99\n    self.crashes = [\n        self._make_crash('c1'),\n        self._make_crash('c2'),\n        self._make_crash('c3')\n    ]\n\n    newly_created_testcase = mock.MagicMock()\n    newly_created_testcase.key.id.return_value = 't'\n    self.group = mock.MagicMock(\n        crashes=self.crashes,\n        main_crash=self.crashes[0],\n        one_time_crasher_flag=False,\n        newly_created_testcase=newly_created_testcase)\n    self.group.is_new.return_value = True\n\n  def _create_context(self, job_type, platform_id):\n    return fuzz_task.Context(\n        project_name='some_project',\n        bot_name='bot',\n        job_type=job_type,\n        fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n        redzone=32,\n        disable_ubsan=False,\n        platform_id=platform_id,\n        crash_revision=1234,\n        fuzzer_name='engine',\n        window_argument='windows_args',\n        fuzzer_metadata={},\n        testcases_metadata={},\n        timeout_multiplier=1.0,\n        test_timeout=5,\n        thread_wait_timeout=6,\n        data_directory='data')\n\n  def _make_crash(self, state):\n    crash = mock.Mock(\n        crash_type='type',\n        crash_state=state,\n        crash_time=111,\n        security_flag=True,\n        key='key')\n    return crash\n\n  def _json(self, job, platform, state, new_flag, testcase_id):\n    return {\n        'crash_type': 'type',\n        'crash_state': state,\n        'created_at': 99,\n        'platform': platform,\n        'crash_time_in_ms': 111000,\n        'parent_fuzzer_name': 'engine',\n        'fuzzer_name': 'engine_binary',\n        'job_type': job,\n        'security_flag': True,\n        'reproducible_flag': True,\n        'revision': '1234',\n        'new_flag': new_flag,\n        'project': 'some_project',\n        'testcase_id': testcase_id\n    }\n\n  def test_all_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(3, success_count)\n    self.assertEqual(0, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_chromeos_platform(self):\n    \"\"\"Test ChromeOS platform is written in stats.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job_chromeos', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c1', True, 't'),\n            'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c2', False, None),\n            'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c3', False, None),\n            'key:bot:99:2')\n    ])\n\n  def test_exception(self):\n    \"\"\"Test writing raising an exception.\"\"\"\n    self.client.insert.side_effect = Exception('error')\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(0, success_count)\n    self.assertEqual(3, failure_count)\n\n\nclass ConvertGroupsToCrashesTest(object):\n  \"\"\"Test convert_groups_to_crashes.\"\"\"\n\n  def test_convert(self):\n    \"\"\"Test converting.\"\"\"\n    groups = [\n        mock.Mock(\n            crashes=[mock.Mock(), mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t1', crash_state='s1', security_flag=True)),\n        mock.Mock(\n            crashes=[mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t2', crash_state='s2', security_flag=False)),\n    ]\n    groups[0].is_new.return_value = False\n    groups[1].is_new.return_value = True\n\n    self.assertEqual([\n        {\n            'is_new': False,\n            'count': 2,\n            'crash_type': 't1',\n            'crash_state': 's1',\n            'security_flag': True\n        },\n        {\n            'is_new': True,\n            'count': 1,\n            'crash_type': 't2',\n            'crash_state': 's2',\n            'security_flag': False\n        },\n    ], fuzz_task.convert_groups_to_crashes(groups))\n\n\nclass TestCorpusSync(fake_filesystem_unittest.TestCase):\n  \"\"\"Test corpus sync.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'fuzzing.corpus_manager.FuzzTargetCorpus.rsync_to_disk',\n        'fuzzing.corpus_manager.FuzzTargetCorpus.upload_files',\n        'google_cloud_utils.storage.last_updated',\n    ])\n\n    helpers.patch_environ(self)\n\n    os.environ['FAIL_RETRIES'] = '1'\n    os.environ['CORPUS_BUCKET'] = 'bucket'\n\n    self.mock.rsync_to_disk.return_value = True\n    test_utils.set_up_pyfakefs(self)\n    self.fs.create_dir('/dir')\n    self.fs.create_dir('/dir1')\n\n  def _write_corpus_files(self, *args, **kwargs):  # pylint: disable=unused-argument\n    self.fs.create_file('/dir/a')\n    self.fs.create_file('/dir/b')\n    return True\n\n  def test_sync(self):\n    \"\"\"Test corpus sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    self.mock.rsync_to_disk.side_effect = self._write_corpus_files\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertTrue(os.path.exists('/dir1/.child_sync'))\n    self.assertEqual(('/dir',), self.mock.rsync_to_disk.call_args[0][1:])\n    self.fs.create_file('/dir/c')\n    self.assertListEqual(['/dir/c'], corpus.get_new_files())\n\n    corpus.upload_files(corpus.get_new_files())\n    self.assertEqual((['/dir/c'],), self.mock.upload_files.call_args[0][1:])\n\n    self.assertListEqual([], corpus.get_new_files())\n\n  def test_no_sync(self):\n    \"\"\"Test no corpus sync when bundle is not updated since last sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = (\n        datetime.datetime.utcnow() - datetime.timedelta(days=1))\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(0, self.mock.rsync_to_disk.call_count)\n\n  def test_sync_with_failed_last_update(self):\n    \"\"\"Test corpus sync when failed to get last update info from gcs.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = None\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(1, self.mock.rsync_to_disk.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass RecordFuzzTargetTest(unittest.TestCase):\n  \"\"\"Tests for record_fuzz_target.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'base.utils.is_oss_fuzz',\n        'base.utils.utcnow',\n    ])\n\n    self.mock.is_oss_fuzz.return_value = False\n    self.mock.utcnow.return_value = datetime.datetime(2018, 1, 1)\n\n  def test_record_fuzz_target(self):\n    \"\"\"Test that record_fuzz_target works.\"\"\"\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_existing(self):\n    \"\"\"Test that record_fuzz_target works when updating an existing entity.\"\"\"\n    data_types.FuzzTarget(\n        binary='child', engine='libFuzzer', project='test-project').put()\n    data_types.FuzzTargetJob(\n        fuzz_target_name='libFuzzer_child',\n        job='job',\n        engine='libFuzzer',\n        last_run=datetime.datetime(2017, 12, 31, 0, 0)).put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_no_binary_name(self):\n    \"\"\"Test recording fuzz target with no binary.\"\"\"\n    # Passing None to binary_name is an error. We shouldn't create any\n    # FuzzTargets as a result.\n    fuzz_task.record_fuzz_target('libFuzzer', None, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertIsNone(fuzz_target)\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertIsNone(job_mapping)\n\n  @parameterized.parameterized.expand(['child', 'proj_child'])\n  def test_record_fuzz_target_ossfuzz(self, binary_name):\n    \"\"\"Test that record_fuzz_target works with OSS-Fuzz projects.\"\"\"\n    self.mock.is_oss_fuzz.return_value = True\n    data_types.Job(name='job', environment_string='PROJECT_NAME = proj\\n').put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', binary_name, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_proj_child').get()\n    self.assertDictEqual({\n        'binary': binary_name,\n        'engine': 'libFuzzer',\n        'project': 'proj',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob,\n                          'libFuzzer_proj_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_proj_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_proj_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('proj_child', fuzz_target.project_qualified_name())\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass DoEngineFuzzingTest(fake_filesystem_unittest.TestCase):\n  \"\"\"do_engine_fuzzing tests.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'bot.fuzzers.engine_common.current_timestamp',\n        'bot.tasks.fuzz_task.GcsCorpus.sync_from_gcs',\n        'bot.tasks.fuzz_task.GcsCorpus.upload_files',\n        'build_management.revisions.get_component_list',\n        'bot.testcase_manager.upload_log',\n        'bot.testcase_manager.upload_testcase',\n        'metrics.fuzzer_stats.upload_stats',\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    os.environ['JOB_NAME'] = 'libfuzzer_asan_test'\n    os.environ['FUZZ_INPUTS'] = '/fuzz-inputs'\n    os.environ['FUZZ_INPUTS_DISK'] = '/fuzz-inputs-disk'\n    os.environ['BUILD_DIR'] = '/build_dir'\n    os.environ['MAX_TESTCASES'] = '2'\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label,auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component,auto_component1'\n\n    self.fs.create_file('/build_dir/test_target')\n    self.fs.create_file(\n        '/build_dir/test_target.labels', contents='label1\\nlabel2')\n    self.fs.create_file(\n        '/build_dir/test_target.owners', contents='owner1@email.com')\n    self.fs.create_file(\n        '/build_dir/test_target.components', contents='component1\\ncomponent2')\n    self.fs.create_file('/input')\n\n    self.mock.sync_from_gcs.return_value = True\n    self.mock.upload_files.return_value = True\n    self.mock.get_component_list.return_value = [{\n        'component': 'component',\n        'link_text': 'rev',\n    }]\n    self.mock.current_timestamp.return_value = 0.0\n\n  def test_basic(self):\n    \"\"\"Test basic fuzzing session.\"\"\"\n    session = fuzz_task.FuzzingSession('libFuzzer', 'libfuzzer_asan_test', 60)\n    session.testcase_directory = os.environ['FUZZ_INPUTS']\n    session.data_directory = '/data_dir'\n\n    os.environ['FUZZ_TARGET'] = 'test_target'\n    os.environ['APP_REVISION'] = '1'\n\n    expected_crashes = [engine.Crash('/input', 'stack', ['args'], 1.0)]\n\n    engine_impl = mock.Mock()\n    engine_impl.name = 'libFuzzer'\n    engine_impl.prepare.return_value = engine.FuzzOptions(\n        '/corpus', ['arg'], {\n            'strategy_1': 1,\n            'strategy_2': 50,\n        })\n    engine_impl.fuzz.side_effect = lambda *_: engine.FuzzResult(\n        'logs', ['cmd'], expected_crashes, {'stat': 1}, 42.0)\n\n    crashes, fuzzer_metadata = session.do_engine_fuzzing(engine_impl)\n    self.assertDictEqual({\n        'fuzzer_binary_name':\n            'test_target',\n        'issue_components':\n            'component1,component2,auto_component,auto_component1',\n        'issue_labels':\n            'label1,label2,auto_label,auto_label1',\n        'issue_owners':\n            'owner1@email.com',\n    }, fuzzer_metadata)\n\n    log_time = datetime.datetime(1970, 1, 1, 0, 0)\n    log_call = mock.call(\n        'Component revisions (build r1):\\n'\n        'component: rev\\n\\n'\n        'Return code: 1\\n\\n'\n        'Command: cmd\\nBot: None\\nTime ran: 42.0\\n\\n'\n        'logs\\n'\n        'cf::fuzzing_strategies: strategy_1:1,strategy_2:50', log_time)\n    self.mock.upload_log.assert_has_calls([log_call, log_call])\n    self.mock.upload_testcase.assert_has_calls([\n        mock.call('/input', log_time),\n        mock.call('/input', log_time),\n    ])\n\n    self.assertEqual(2, len(crashes))\n    for i in range(2):\n      self.assertEqual('/input', crashes[i].file_path)\n      self.assertEqual(1, crashes[i].return_code)\n      self.assertEqual('stack', crashes[i].unsymbolized_crash_stacktrace)\n      self.assertEqual(1.0, crashes[i].crash_time)\n      self.assertEqual('args', crashes[i].arguments)\n\n    for i in range(2):\n      upload_args = self.mock.upload_stats.call_args_list[i][0][0]\n      testcase_run = upload_args[0]\n      self.assertDictEqual({\n          'build_revision': 1,\n          'command': ['cmd'],\n          'fuzzer': u'libFuzzer_test_target',\n          'job': 'libfuzzer_asan_test',\n          'kind': 'TestcaseRun',\n          'stat': 1,\n          'strategy_strategy_1': 1,\n          'strategy_strategy_2': 50,\n          'timestamp': 0.0,\n      }, testcase_run.data)\n\n\nclass UntrustedRunEngineFuzzerTest(\n    untrusted_runner_helpers.UntrustedRunnerIntegrationTest):\n  \"\"\"Engine fuzzing tests for untrusted.\"\"\"\n\n  def setUp(self):\n    \"\"\"Set up.\"\"\"\n    super(UntrustedRunEngineFuzzerTest, self).setUp()\n    environment.set_value('JOB_NAME', 'libfuzzer_asan_job')\n\n    job = data_types.Job(\n        name='libfuzzer_asan_job',\n        environment_string=(\n            'RELEASE_BUILD_BUCKET_PATH = '\n            'gs://clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-([0-9]+).zip\\n'\n            'REVISION_VARS_URL = https://commondatastorage.googleapis.com/'\n            'clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-%s.srcmap.json\\n'))\n    job.put()\n\n    self.temp_dir = tempfile.mkdtemp(dir=environment.get_value('FUZZ_INPUTS'))\n    environment.set_value('USE_MINIJAIL', False)\n\n  def tearDown(self):\n    super(UntrustedRunEngineFuzzerTest, self).tearDown()\n    shutil.rmtree(self.temp_dir, ignore_errors=True)\n\n  def test_run_engine_fuzzer(self):\n    \"\"\"Test running engine fuzzer.\"\"\"\n    self._setup_env(job_type='libfuzzer_asan_job')\n    environment.set_value('FUZZ_TEST_TIMEOUT', 3600)\n\n    build_manager.setup_build()\n    corpus_directory = os.path.join(self.temp_dir, 'corpus')\n    testcase_directory = os.path.join(self.temp_dir, 'artifacts')\n    os.makedirs(file_host.rebase_to_worker_root(corpus_directory))\n    os.makedirs(file_host.rebase_to_worker_root(testcase_directory))\n\n    result, fuzzer_metadata = fuzz_task.run_engine_fuzzer(\n        libfuzzer_engine.LibFuzzerEngine(), 'test_fuzzer', corpus_directory,\n        testcase_directory)\n    self.assertIn(\n        'ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000',\n        result.logs)\n    self.assertEqual(1, len(result.crashes))\n    self.assertTrue(result.crashes[0].input_path.startswith(\n        os.environ['ROOT_DIR']))\n    self.assertTrue(os.path.exists(result.crashes[0].input_path))\n    self.assertIsInstance(result.stats.get('number_of_executed_units'), int)\n    self.assertIsInstance(result.stats.get('oom_count'), int)\n    self.assertIsInstance(\n        result.stats.get('strategy_selection_method'), six.string_types)\n\n    self.assertDictEqual({'fuzzer_binary_name': 'test_fuzzer'}, fuzzer_metadata)\n\n\nclass AddIssueMetadataFromEnvironmentTest(unittest.TestCase):\n  \"\"\"Tests for _add_issue_metadata_from_environment.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n\n  def test_add_no_existing(self):\n    \"\"\"Test adding issue metadata when there are none existing.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components': 'auto_component,auto_component1',\n        'issue_labels': 'auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_append(self):\n    \"\"\"Test adding issue metadata when there are already existing metadata.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {\n        'issue_components': 'existing_component',\n        'issue_labels': 'existing_label'\n    }\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components':\n            'existing_component,auto_component,auto_component1',\n        'issue_labels':\n            'existing_label,auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_numeric(self):\n    \"\"\"Tests adding a numeric label.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = '123'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_labels': '123',\n    }, metadata)\n",
  "output": {
    "before": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"fuzz_task tests.\"\"\"\n# pylint: disable=protected-access\nfrom builtins import object\nfrom builtins import range\nimport datetime\nimport mock\nimport os\nimport parameterized\nimport shutil\nimport tempfile\nimport time\nimport unittest\n\nfrom pyfakefs import fake_filesystem_unittest\nimport six\n\nfrom base import utils\nfrom bot import testcase_manager\nfrom bot.fuzzers import engine\nfrom bot.fuzzers.libFuzzer import engine as libfuzzer_engine\nfrom bot.tasks import fuzz_task\nfrom bot.untrusted_runner import file_host\nfrom build_management import build_manager\nfrom chrome import crash_uploader\nfrom crash_analysis.stack_parsing import stack_analyzer\nfrom datastore import data_handler\nfrom datastore import data_types\nfrom datastore import ndb\nfrom google_cloud_utils import big_query\nfrom metrics import monitor\nfrom metrics import monitoring_metrics\nfrom system import environment\nfrom tests.test_libs import helpers\nfrom tests.test_libs import test_utils\nfrom tests.test_libs import untrusted_runner_helpers\n\n\nclass TrackFuzzerRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_fuzzer_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_fuzzer_run_result(self):\n    \"\"\"Ensure _track_fuzzer_run_result set the right metrics.\"\"\"\n    fuzz_task._track_fuzzer_run_result('name', 10, 100, 2)\n    fuzz_task._track_fuzzer_run_result('name', 100, 200, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 2000, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 500, 0)\n    fuzz_task._track_fuzzer_run_result('name', 0, 1000, -1)\n    fuzz_task._track_fuzzer_run_result('name', 0, 0, 2)\n\n    self.assertEqual(\n        4,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 2\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 0\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': -1\n        }))\n\n    testcase_count_ratio = (\n        monitoring_metrics.FUZZER_TESTCASE_COUNT_RATIO.get({\n            'fuzzer': 'name'\n        }))\n    self.assertEqual(3.1, testcase_count_ratio.sum)\n    self.assertEqual(5, testcase_count_ratio.count)\n\n    expected_buckets = [0 for _ in range(22)]\n    expected_buckets[1] = 1\n    expected_buckets[3] = 1\n    expected_buckets[11] = 2\n    expected_buckets[21] = 1\n    self.assertListEqual(expected_buckets, testcase_count_ratio.buckets)\n\n\nclass TrackBuildRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_build_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_build_run_result(self):\n    \"\"\"Ensure _track_build_run_result set the right metrics.\"\"\"\n    fuzz_task._track_build_run_result('name', 10000, True)\n    fuzz_task._track_build_run_result('name', 10001, True)\n    fuzz_task._track_build_run_result('name', 10002, False)\n\n    self.assertEqual(\n        2,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': True\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': False\n        }))\n\n\nclass TrackTestcaseRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_testcase_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_testcase_run_result(self):\n    \"\"\"Ensure _track_testcase_run_result sets the right metrics.\"\"\"\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 2, 5)\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 5, 10)\n\n    self.assertEqual(7,\n                     monitoring_metrics.JOB_NEW_CRASH_COUNT.get({\n                         'job': 'job'\n                     }))\n    self.assertEqual(\n        15, monitoring_metrics.JOB_KNOWN_CRASH_COUNT.get({\n            'job': 'job'\n        }))\n    self.assertEqual(\n        7, monitoring_metrics.FUZZER_NEW_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n    self.assertEqual(\n        15, monitoring_metrics.FUZZER_KNOWN_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n\n\nclass TruncateFuzzerOutputTest(unittest.TestCase):\n  \"\"\"Truncate fuzzer output tests.\"\"\"\n\n  def test_no_truncation(self):\n    \"\"\"No truncation.\"\"\"\n    self.assertEqual('aaaa', fuzz_task.truncate_fuzzer_output('aaaa', 10))\n\n  def test_truncation(self):\n    \"\"\"Truncate.\"\"\"\n    self.assertEqual(\n        '123456\\n...truncated...\\n54321',\n        fuzz_task.truncate_fuzzer_output(\n            '123456xxxxxxxxxxxxxxxxxxxxxxxxxxx54321', 28))\n\n  def test_error(self):\n    \"\"\"Error if limit is too low.\"\"\"\n    with self.assertRaises(AssertionError):\n      self.assertEqual(\n          '', fuzz_task.truncate_fuzzer_output('123456xxxxxx54321', 10))\n\n\nclass TrackFuzzTimeTest(unittest.TestCase):\n  \"\"\"Test _TrackFuzzTime.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def _test(self, timeout):\n    \"\"\"Test helper.\"\"\"\n    time_module = helpers.MockTime()\n    with fuzz_task._TrackFuzzTime('fuzzer', 'job', time_module) as tracker:\n      time_module.advance(5)\n      tracker.timeout = timeout\n\n    fuzzer_total_time = monitoring_metrics.FUZZER_TOTAL_FUZZ_TIME.get({\n        'fuzzer': 'fuzzer',\n        'timeout': timeout\n    })\n    self.assertEqual(5, fuzzer_total_time)\n\n  def test_success(self):\n    \"\"\"Test report metrics.\"\"\"\n    self._test(False)\n\n  def test_timeout(self):\n    \"\"\"Test timeout.\"\"\"\n    self._test(True)\n\n\nclass GetFuzzerMetadataFromOutputTest(unittest.TestCase):\n  \"\"\"Test get_fuzzer_metadata_from_output.\"\"\"\n\n  def test_no_metadata(self):\n    \"\"\"Tests no metadata in output.\"\"\"\n    data = 'abc\\ndef\\n123123'\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n    data = ''\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n  def test_metadata(self):\n    \"\"\"Tests parsing of metadata.\"\"\"\n    data = ('abc\\n'\n            'def\\n'\n            'metadata:invalid: invalid\\n'\n            'metadat::invalid: invalid\\n'\n            'metadata::foo: bar\\n'\n            '123123\\n'\n            'metadata::blah: 1\\n'\n            'metadata::test:abcd\\n'\n            'metadata::test2:   def\\n')\n    self.assertDictEqual(\n        fuzz_task.get_fuzzer_metadata_from_output(data), {\n            'blah': '1',\n            'test': 'abcd',\n            'test2': 'def',\n            'foo': 'bar'\n        })\n\n\nclass GetRegressionTest(unittest.TestCase):\n  \"\"\"Test get_regression.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, ['build_management.build_manager.is_custom_binary'])\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('NA', fuzz_task.get_regression(True))\n\n  def test_custom_binary(self):\n    \"\"\"Test for custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = True\n    self.assertEqual('NA', fuzz_task.get_regression(False))\n\n  def test_reproducible_non_custom_binary(self):\n    \"\"\"Test for reproducible non-custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('', fuzz_task.get_regression(False))\n\n\nclass GetFixedOrMinimizedKeyTest(unittest.TestCase):\n  \"\"\"Test get_fixed_or_minimized_key.\"\"\"\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.assertEqual('NA', fuzz_task.get_fixed_or_minimized_key(True))\n\n  def test_reproducible(self):\n    \"\"\"Test for reproducible.\"\"\"\n    self.assertEqual('', fuzz_task.get_fixed_or_minimized_key(False))\n\n\nclass CrashInitTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test Crash.__init__.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.FileMetadataInfo',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'bot.testcase_manager.get_additional_command_line_flags',\n        'bot.testcase_manager.get_command_line_for_application',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n    ])\n    helpers.patch_environ(self)\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = 'state'\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_crash_stacktrace_output.return_value = 'trace'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', False)\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n  def test_error(self):\n    \"\"\"Test failing to reading stacktrace file.\"\"\"\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/no_stack_file'))\n    self.assertIsNone(crash)\n\n  def _test_crash(self, should_be_ignored, security_flag):\n    \"\"\"Test crash.\"\"\"\n    self.mock.get_command_line_for_application.reset_mock()\n    self.mock.get_crash_data.reset_mock()\n    self.mock.get_crash_stacktrace_output.reset_mock()\n    self.mock.is_security_issue.reset_mock()\n    self.mock.ignore_stacktrace.reset_mock()\n\n    self.mock.is_security_issue.return_value = security_flag\n    self.mock.ignore_stacktrace.return_value = should_be_ignored\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/stack_file_path'))\n\n    self.assertEqual('dir/path-http-name', crash.file_path)\n    self.assertEqual(123, crash.crash_time)\n    self.assertEqual(11, crash.return_code)\n    self.assertListEqual(['res'], crash.resource_list)\n    self.assertEqual('ges', crash.gestures)\n\n    self.assertEqual('path-http-name', crash.filename)\n    self.assertTrue(crash.http_flag)\n\n    self.assertEqual('cmd', crash.application_command_line)\n    self.mock.get_command_line_for_application.assert_called_once_with(\n        'dir/path-http-name', needs_http=True)\n\n    self.assertEqual('unsym', crash.unsymbolized_crash_stacktrace)\n\n    self.assertEqual('type', crash.crash_type)\n    self.assertEqual('address', crash.crash_address)\n    self.assertEqual('state', crash.crash_state)\n    self.assertListEqual(['frame 1', 'frame 2'], crash.crash_frames)\n    self.mock.get_crash_data.assert_called_once_with('unsym')\n\n    self.assertEqual('trace', crash.crash_stacktrace)\n    self.mock.get_crash_stacktrace_output.assert_called_once_with(\n        'cmd', 'orig_trace', 'unsym')\n\n    self.assertEqual(security_flag, crash.security_flag)\n    self.mock.is_security_issue.assert_called_once_with('unsym', 'type',\n                                                        'address')\n\n    self.assertEqual('type,state,%s' % security_flag, crash.key)\n\n    self.assertEqual(should_be_ignored, crash.should_be_ignored)\n    self.mock.ignore_stacktrace.assert_called_once_with('orig_trace')\n\n    self.assertFalse(hasattr(crash, 'fuzzed_key'))\n    return crash\n\n  def _test_validity_and_get_functional_crash(self):\n    \"\"\"Test validity of different crashes and return functional crash.\"\"\"\n    security_crash = self._test_crash(\n        should_be_ignored=False, security_flag=True)\n    self.assertIsNone(security_crash.get_error())\n    self.assertTrue(security_crash.is_valid())\n\n    ignored_crash = self._test_crash(should_be_ignored=True, security_flag=True)\n    self.assertIn('False crash', ignored_crash.get_error())\n    self.assertFalse(ignored_crash.is_valid())\n\n    functional_crash = self._test_crash(\n        should_be_ignored=False, security_flag=False)\n    return functional_crash\n\n  def test_valid_functional_bug(self):\n    \"\"\"Test valid because of functional bug.\"\"\"\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIsNone(functional_crash.get_error())\n    self.assertTrue(functional_crash.is_valid())\n\n  def test_invalid_functional_bug(self):\n    \"\"\"Test invalid because of functional bug.\"\"\"\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', True)\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIn('Functional crash', functional_crash.get_error())\n    self.assertFalse(functional_crash.is_valid())\n\n  def test_hydrate_fuzzed_key(self):\n    \"\"\"Test hydrating fuzzed_key.\"\"\"\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    self.assertEqual('fuzzed_key', crash.fuzzed_key)\n    self.assertTrue(crash.archived)\n    self.assertEqual('absolute_path', crash.absolute_path)\n    self.assertEqual('archive_filename', crash.archive_filename)\n\n  def test_hydrate_fuzzed_key_failure(self):\n    \"\"\"Test fail to hydrate fuzzed_key.\"\"\"\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (None,\n                                                                       False,\n                                                                       None,\n                                                                       None)\n\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIn('Unable to store testcase in blobstore', crash.get_error())\n    self.assertFalse(crash.is_valid())\n\n    self.assertIsNone(crash.fuzzed_key)\n    self.assertFalse(crash.archived)\n    self.assertIsNone(crash.absolute_path)\n    self.assertIsNone(crash.archive_filename)\n\n  def test_args_from_testcase_manager(self):\n    \"\"\"Test args from testcase_manager.Crash.\"\"\"\n    testcase_manager_crash = testcase_manager.Crash('path', 0, 0, [], [],\n                                                    '/stack_file_path')\n    self.mock.get_additional_command_line_flags.return_value = 'minimized'\n    environment.set_value('APP_ARGS', 'app')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(testcase_manager_crash)\n    self.assertEqual('app minimized', crash.arguments)\n\n\nclass CrashGroupTest(unittest.TestCase):\n  \"\"\"Test CrashGroup.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.tasks.fuzz_task.find_main_crash',\n        'datastore.data_handler.find_testcase',\n        'datastore.data_handler.get_project_name',\n    ])\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.crashes = [self._make_crash('g1'), self._make_crash('g2')]\n    self.context = mock.MagicMock(\n        test_timeout=99, fuzzer_name='test', fuzz_target=None)\n    self.reproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=False)\n    self.unreproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=True)\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        crash_type='type',\n        crash_state='state',\n        security_flag=True,\n        file_path='file_path',\n        http_flag=True,\n        gestures=gestures)\n    return crash\n\n  def _make_testcase(self,\n                     project_name,\n                     bug_information,\n                     one_time_crasher_flag,\n                     timestamp=datetime.datetime.now()):\n    \"\"\"Make testcase.\"\"\"\n    testcase = data_types.Testcase()\n    testcase.timestamp = timestamp\n    testcase.one_time_crasher_flag = one_time_crasher_flag\n    testcase.bug_information = bug_information\n    testcase.project_name = project_name\n    return testcase\n\n  def test_no_existing_testcase(self):\n    \"\"\"is_new=True and should_create_testcase=True when there's no existing\n        testcase.\"\"\"\n    self.mock.find_testcase.return_value = None\n    self.mock.find_main_crash.return_value = self.crashes[0], True\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertTrue(group.should_create_testcase())\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n\n    self.assertIsNone(group.existing_testcase)\n    self.assertEqual(self.crashes[0], group.main_crash)\n    self.assertTrue(group.is_new())\n\n  def test_has_existing_reproducible_testcase(self):\n    \"\"\"should_create_testcase=False when there's an existing reproducible\n      testcase.\"\"\"\n    self.mock.find_testcase.return_value = self.reproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.should_create_testcase())\n    self.assertTrue(group.has_existing_reproducible_testcase())\n\n  def test_reproducible_crash(self):\n    \"\"\"should_create_testcase=True when the group is reproducible.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], False)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertTrue(group.should_create_testcase())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertFalse(group.one_time_crasher_flag)\n\n  def test_has_existing_unreproducible_testcase(self):\n    \"\"\"should_create_testcase=False when the unreproducible testcase already\n    exists.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertFalse(group.should_create_testcase())\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertTrue(group.one_time_crasher_flag)\n\n\nclass FindMainCrashTest(unittest.TestCase):\n  \"\"\"Test find_main_crash.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.testcase_manager.test_for_reproducibility',\n    ])\n    self.crashes = [\n        self._make_crash('g1'),\n        self._make_crash('g2'),\n        self._make_crash('g3'),\n        self._make_crash('g4')\n    ]\n    self.reproducible_crashes = []\n\n    # pylint: disable=unused-argument\n    def test_for_repro(fuzzer_name,\n                       full_fuzzer_name,\n                       file_path,\n                       state,\n                       security_flag,\n                       test_timeout,\n                       http_flag,\n                       gestures,\n                       arguments=None):\n      \"\"\"Mock test_for_reproducibility.\"\"\"\n      for c in self.reproducible_crashes:\n        if c.gestures == gestures:\n          return True\n      return False\n\n    self.mock.test_for_reproducibility.side_effect = test_for_repro\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        file_path='file_path',\n        crash_state='state',\n        security_flag=True,\n        test_timeout=999,\n        gestures=gestures)\n    return crash\n\n  def test_reproducible_crash(self):\n    \"\"\"Find that the 2nd crash is reproducible.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = [self.crashes[2]]\n\n    self.assertEqual((self.crashes[2], False),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    self.crashes[0].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[1].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[2].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[3].archive_testcase_in_blobstore.assert_not_called()\n\n    # Calls for self.crashes[1] and self.crashes[2].\n    self.assertEqual(2, self.mock.test_for_reproducibility.call_count)\n\n  def test_unreproducible_crash(self):\n    \"\"\"No reproducible crash. Find the first valid one.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((self.crashes[1], True),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    # Calls for every crash except self.crashes[0] because it's invalid.\n    self.assertEqual(\n        len(self.crashes) - 1, self.mock.test_for_reproducibility.call_count)\n\n  def test_no_valid_crash(self):\n    \"\"\"No valid crash.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((None, None),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    self.assertEqual(0, self.mock.test_for_reproducibility.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass ProcessCrashesTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test process_crashes.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.get_symbolized_stack_bytes',\n        'bot.tasks.task_creation.create_tasks',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'build_management.revisions.get_real_revision',\n        'bot.testcase_manager.get_command_line_for_application',\n        'bot.testcase_manager.test_for_reproducibility',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n        'datastore.data_handler.get_issue_tracker_name',\n        'datastore.data_handler.get_project_name',\n        'google.appengine.api.app_identity.get_application_id',\n        'google_cloud_utils.big_query.Client.insert',\n        'google_cloud_utils.big_query.get_api_client', 'time.sleep', 'time.time'\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.time.return_value = 987\n\n    self.mock.get_issue_tracker_name.return_value = 'some_issue_tracker'\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n  def _make_crash(self, trace, state='state'):\n    \"\"\"Make crash.\"\"\"\n    self.mock.get_real_revision.return_value = 'this.is.fake.ver'\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = state\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.crash_frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_symbolized_stack_bytes.return_value = 'f00df00d'\n    self.mock.get_crash_stacktrace_output.return_value = trace\n    self.mock.is_security_issue.return_value = True\n    self.mock.ignore_stacktrace.return_value = False\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], ['ges'],\n                               '/stack_file_path'))\n    return crash\n\n  def test_existing_unreproducible_testcase(self):\n    \"\"\"Test existing unreproducible testcase.\"\"\"\n    crashes = [self._make_crash('c1'), self._make_crash('c2')]\n    self.mock.test_for_reproducibility.return_value = False\n\n    existing_testcase = data_types.Testcase()\n    existing_testcase.crash_stacktrace = 'existing'\n    existing_testcase.crash_type = crashes[0].crash_type\n    existing_testcase.crash_state = crashes[0].crash_state\n    existing_testcase.security_flag = crashes[0].security_flag\n    existing_testcase.one_time_crasher_flag = True\n    existing_testcase.job_type = 'existing_job'\n    existing_testcase.timestamp = datetime.datetime.now()\n    existing_testcase.project_name = 'some_project'\n    existing_testcase.put()\n\n    variant = data_types.TestcaseVariant()\n    variant.status = data_types.TestcaseVariantStatus.UNREPRODUCIBLE\n    variant.job_type = 'job'\n    variant.testcase_id = existing_testcase.key.id()\n    variant.put()\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name='some_project',\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=True,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(0, new_crash_count)\n    self.assertEqual(2, known_crash_count)\n\n    self.assertEqual(1, len(groups))\n    self.assertEqual(2, len(groups[0].crashes))\n    self.assertFalse(groups[0].is_new())\n    self.assertEqual(crashes[0].crash_type, groups[0].main_crash.crash_type)\n    self.assertEqual(crashes[0].crash_state, groups[0].main_crash.crash_state)\n    self.assertEqual(crashes[0].security_flag,\n                     groups[0].main_crash.security_flag)\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(1, len(testcases))\n    self.assertEqual('existing', testcases[0].crash_stacktrace)\n\n    variant = data_handler.get_testcase_variant(existing_testcase.key.id(),\n                                                'job')\n    self.assertEqual(data_types.TestcaseVariantStatus.FLAKY, variant.status)\n    self.assertEqual('fuzzed_key', variant.reproducer_key)\n    self.assertEqual(1234, variant.revision)\n    self.assertEqual('type', variant.crash_type)\n    self.assertEqual('state', variant.crash_state)\n    self.assertEqual(True, variant.security_flag)\n    self.assertEqual(True, variant.is_similar)\n\n  @parameterized.parameterized.expand(['some_project', 'chromium'])\n  def test_create_many_groups(self, project_name):\n    \"\"\"Test creating many groups.\"\"\"\n    self.mock.get_project_name.return_value = project_name\n\n    self.mock.insert.return_value = {'insertErrors': [{'index': 0}]}\n\n    # TODO(metzman): Add a seperate test for strategies.\n    r2_stacktrace = ('r2\\ncf::fuzzing_strategies: value_profile\\n')\n\n    crashes = [\n        self._make_crash('r1', state='reproducible1'),\n        self._make_crash(r2_stacktrace, state='reproducible1'),\n        self._make_crash('r3', state='reproducible1'),\n        self._make_crash('r4', state='reproducible2'),\n        self._make_crash('u1', state='unreproducible1'),\n        self._make_crash('u2', state='unreproducible2'),\n        self._make_crash('u3', state='unreproducible2'),\n        self._make_crash('u4', state='unreproducible3')\n    ]\n\n    self.mock.test_for_reproducibility.side_effect = [\n        False,  # For r1. It returns False. So, r1 is demoted.\n        True,  # For r2. It returns True. So, r2 becomes primary for its group.\n        True,  # For r4.\n        False,  # For u1.\n        False,  # For u2.\n        False,  # For u3.\n        False\n    ]  # For u4.\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name=project_name,\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=False,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(5, new_crash_count)\n    self.assertEqual(3, known_crash_count)\n\n    self.assertEqual(5, len(groups))\n    self.assertEqual([\n        'reproducible1', 'reproducible2', 'unreproducible1', 'unreproducible2',\n        'unreproducible3'\n    ], [group.main_crash.crash_state for group in groups])\n    self.assertEqual([True, True, True, True, True],\n                     [group.is_new() for group in groups])\n    self.assertEqual([3, 1, 1, 2, 1], [len(group.crashes) for group in groups])\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(5, len(testcases))\n    self.assertSetEqual(\n        set([r2_stacktrace, 'r4', 'u1', 'u2', 'u4']),\n        set(t.crash_stacktrace for t in testcases))\n\n    self.assertSetEqual(\n        set([\n            '{\"fuzzing_strategies\": [\"value_profile\"]}', None, None, None, None\n        ]), set(t.additional_metadata for t in testcases))\n\n    # r2 is a reproducible crash, so r3 doesn't\n    # invoke archive_testcase_in_blobstore. Therefore, the\n    # archive_testcase_in_blobstore is called `len(crashes) - 1`.\n    self.assertEqual(\n        len(crashes) - 1,\n        self.mock.archive_testcase_and_dependencies_in_gcs.call_count)\n\n    # Check only the desired testcases were saved.\n    actual_crash_infos = [group.main_crash.crash_info for group in groups]\n    if project_name != 'chromium':\n      expected_crash_infos = [None] * len(actual_crash_infos)\n    else:\n      expected_saved_crash_info = crash_uploader.CrashReportInfo(\n          product='Chrome_' + environment.platform().lower().capitalize(),\n          version='this.is.fake.ver',\n          serialized_crash_stack_frames='f00df00d')\n      expected_crash_infos = [\n          expected_saved_crash_info,  # r2 is main crash for group r1,r2,r3\n          expected_saved_crash_info,  # r4 is main crash for its own group\n          None,  # u1 is not reproducible\n          None,  # u2, u3 are not reproducible\n          None,  # u4 is not reproducible\n      ]\n\n    self.assertEqual(len(expected_crash_infos), len(actual_crash_infos))\n    for expected, actual in zip(expected_crash_infos, actual_crash_infos):\n      if not expected:\n        self.assertIsNone(actual)\n        continue\n\n      self.assertEqual(expected.product, actual.product)\n      self.assertEqual(expected.version, actual.version)\n      self.assertEqual(expected.serialized_crash_stack_frames,\n                       actual.serialized_crash_stack_frames)\n\n    def _make_big_query_json(crash, reproducible_flag, new_flag, testcase_id):\n      return {\n          'crash_type': crash.crash_type,\n          'crash_state': crash.crash_state,\n          'created_at': 987,\n          'platform': 'platform',\n          'crash_time_in_ms': int(crash.crash_time * 1000),\n          'parent_fuzzer_name': 'engine',\n          'fuzzer_name': 'engine_binary',\n          'job_type': 'job',\n          'security_flag': crash.security_flag,\n          'reproducible_flag': reproducible_flag,\n          'revision': '1234',\n          'new_flag': new_flag,\n          'project': project_name,\n          'testcase_id': testcase_id\n      }\n\n    def _get_testcase_id(crash):\n      rows = list(\n          data_types.Testcase.query(\n              data_types.Testcase.crash_type == crash.crash_type,\n              data_types.Testcase.crash_state == crash.crash_state,\n              data_types.Testcase.security_flag == crash.security_flag))\n      if not rows:\n        return None\n      return str(rows[0].key.id())\n\n    # Calls to write 5 groups of crashes to BigQuery.\n    self.assertEqual(5, self.mock.insert.call_count)\n    self.mock.insert.assert_has_calls([\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[0], True, False, None),\n                '%s:bot:987:0' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[1], True, True,\n                                     _get_testcase_id(crashes[1])),\n                '%s:bot:987:1' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[2], True, False, None),\n                '%s:bot:987:2' % crashes[0].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[3], True, True,\n                                     _get_testcase_id(crashes[3])),\n                '%s:bot:987:0' % crashes[3].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[4], False, True,\n                                     _get_testcase_id(crashes[4])),\n                '%s:bot:987:0' % crashes[4].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[5], False, True,\n                                     _get_testcase_id(crashes[5])),\n                '%s:bot:987:0' % crashes[5].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[6], False, False, None),\n                '%s:bot:987:1' % crashes[5].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[7], False, True,\n                                     _get_testcase_id(crashes[7])),\n                '%s:bot:987:0' % crashes[7].key)\n        ]),\n    ])\n\n\nclass WriteCrashToBigQueryTest(unittest.TestCase):\n  \"\"\"Test write_crash_to_big_query.\"\"\"\n\n  def setUp(self):\n    self.client = mock.Mock(spec_set=big_query.Client)\n    helpers.patch(self, [\n        'system.environment.get_value',\n        'datastore.data_handler.get_project_name',\n        'google_cloud_utils.big_query.Client',\n        'time.time',\n    ])\n    monitor.metrics_store().reset_for_testing()\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.get_value.return_value = 'bot'\n    self.mock.Client.return_value = self.client\n    self.mock.time.return_value = 99\n    self.crashes = [\n        self._make_crash('c1'),\n        self._make_crash('c2'),\n        self._make_crash('c3')\n    ]\n\n    newly_created_testcase = mock.MagicMock()\n    newly_created_testcase.key.id.return_value = 't'\n    self.group = mock.MagicMock(\n        crashes=self.crashes,\n        main_crash=self.crashes[0],\n        one_time_crasher_flag=False,\n        newly_created_testcase=newly_created_testcase)\n    self.group.is_new.return_value = True\n\n  def _create_context(self, job_type, platform_id):\n    return fuzz_task.Context(\n        project_name='some_project',\n        bot_name='bot',\n        job_type=job_type,\n        fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n        redzone=32,\n        disable_ubsan=False,\n        platform_id=platform_id,\n        crash_revision=1234,\n        fuzzer_name='engine',\n        window_argument='windows_args',\n        fuzzer_metadata={},\n        testcases_metadata={},\n        timeout_multiplier=1.0,\n        test_timeout=5,\n        thread_wait_timeout=6,\n        data_directory='data')\n\n  def _make_crash(self, state):\n    crash = mock.Mock(\n        crash_type='type',\n        crash_state=state,\n        crash_time=111,\n        security_flag=True,\n        key='key')\n    return crash\n\n  def _json(self, job, platform, state, new_flag, testcase_id):\n    return {\n        'crash_type': 'type',\n        'crash_state': state,\n        'created_at': 99,\n        'platform': platform,\n        'crash_time_in_ms': 111000,\n        'parent_fuzzer_name': 'engine',\n        'fuzzer_name': 'engine_binary',\n        'job_type': job,\n        'security_flag': True,\n        'reproducible_flag': True,\n        'revision': '1234',\n        'new_flag': new_flag,\n        'project': 'some_project',\n        'testcase_id': testcase_id\n    }\n\n  def test_all_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(3, success_count)\n    self.assertEqual(0, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_chromeos_platform(self):\n    \"\"\"Test ChromeOS platform is written in stats.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job_chromeos', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c1', True, 't'),\n            'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c2', False, None),\n            'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c3', False, None),\n            'key:bot:99:2')\n    ])\n\n  def test_exception(self):\n    \"\"\"Test writing raising an exception.\"\"\"\n    self.client.insert.side_effect = Exception('error')\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(0, success_count)\n    self.assertEqual(3, failure_count)\n\n\nclass ConvertGroupsToCrashesTest(object):\n  \"\"\"Test convert_groups_to_crashes.\"\"\"\n\n  def test_convert(self):\n    \"\"\"Test converting.\"\"\"\n    groups = [\n        mock.Mock(\n            crashes=[mock.Mock(), mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t1', crash_state='s1', security_flag=True)),\n        mock.Mock(\n            crashes=[mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t2', crash_state='s2', security_flag=False)),\n    ]\n    groups[0].is_new.return_value = False\n    groups[1].is_new.return_value = True\n\n    self.assertEqual([\n        {\n            'is_new': False,\n            'count': 2,\n            'crash_type': 't1',\n            'crash_state': 's1',\n            'security_flag': True\n        },\n        {\n            'is_new': True,\n            'count': 1,\n            'crash_type': 't2',\n            'crash_state': 's2',\n            'security_flag': False\n        },\n    ], fuzz_task.convert_groups_to_crashes(groups))\n\n\nclass TestCorpusSync(fake_filesystem_unittest.TestCase):\n  \"\"\"Test corpus sync.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'fuzzing.corpus_manager.FuzzTargetCorpus.rsync_to_disk',\n        'fuzzing.corpus_manager.FuzzTargetCorpus.upload_files',\n        'google_cloud_utils.storage.last_updated',\n    ])\n\n    helpers.patch_environ(self)\n\n    os.environ['FAIL_RETRIES'] = '1'\n    os.environ['CORPUS_BUCKET'] = 'bucket'\n\n    self.mock.rsync_to_disk.return_value = True\n    test_utils.set_up_pyfakefs(self)\n    self.fs.create_dir('/dir')\n    self.fs.create_dir('/dir1')\n\n  def _write_corpus_files(self, *args, **kwargs):  # pylint: disable=unused-argument\n    self.fs.create_file('/dir/a')\n    self.fs.create_file('/dir/b')\n    return True\n\n  def test_sync(self):\n    \"\"\"Test corpus sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    self.mock.rsync_to_disk.side_effect = self._write_corpus_files\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertTrue(os.path.exists('/dir1/.child_sync'))\n    self.assertEqual(('/dir',), self.mock.rsync_to_disk.call_args[0][1:])\n    self.fs.create_file('/dir/c')\n    self.assertListEqual(['/dir/c'], corpus.get_new_files())\n\n    corpus.upload_files(corpus.get_new_files())\n    self.assertEqual((['/dir/c'],), self.mock.upload_files.call_args[0][1:])\n\n    self.assertListEqual([], corpus.get_new_files())\n\n  def test_no_sync(self):\n    \"\"\"Test no corpus sync when bundle is not updated since last sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = (\n        datetime.datetime.utcnow() - datetime.timedelta(days=1))\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(0, self.mock.rsync_to_disk.call_count)\n\n  def test_sync_with_failed_last_update(self):\n    \"\"\"Test corpus sync when failed to get last update info from gcs.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = None\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(1, self.mock.rsync_to_disk.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass RecordFuzzTargetTest(unittest.TestCase):\n  \"\"\"Tests for record_fuzz_target.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'base.utils.is_oss_fuzz',\n        'base.utils.utcnow',\n    ])\n\n    self.mock.is_oss_fuzz.return_value = False\n    self.mock.utcnow.return_value = datetime.datetime(2018, 1, 1)\n\n  def test_record_fuzz_target(self):\n    \"\"\"Test that record_fuzz_target works.\"\"\"\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_existing(self):\n    \"\"\"Test that record_fuzz_target works when updating an existing entity.\"\"\"\n    data_types.FuzzTarget(\n        binary='child', engine='libFuzzer', project='test-project').put()\n    data_types.FuzzTargetJob(\n        fuzz_target_name='libFuzzer_child',\n        job='job',\n        engine='libFuzzer',\n        last_run=datetime.datetime(2017, 12, 31, 0, 0)).put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_no_binary_name(self):\n    \"\"\"Test recording fuzz target with no binary.\"\"\"\n    # Passing None to binary_name is an error. We shouldn't create any\n    # FuzzTargets as a result.\n    fuzz_task.record_fuzz_target('libFuzzer', None, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertIsNone(fuzz_target)\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertIsNone(job_mapping)\n\n  @parameterized.parameterized.expand(['child', 'proj_child'])\n  def test_record_fuzz_target_ossfuzz(self, binary_name):\n    \"\"\"Test that record_fuzz_target works with OSS-Fuzz projects.\"\"\"\n    self.mock.is_oss_fuzz.return_value = True\n    data_types.Job(name='job', environment_string='PROJECT_NAME = proj\\n').put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', binary_name, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_proj_child').get()\n    self.assertDictEqual({\n        'binary': binary_name,\n        'engine': 'libFuzzer',\n        'project': 'proj',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob,\n                          'libFuzzer_proj_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_proj_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_proj_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('proj_child', fuzz_target.project_qualified_name())\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass DoEngineFuzzingTest(fake_filesystem_unittest.TestCase):\n  \"\"\"do_engine_fuzzing tests.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'bot.fuzzers.engine_common.current_timestamp',\n        'bot.tasks.fuzz_task.GcsCorpus.sync_from_gcs',\n        'bot.tasks.fuzz_task.GcsCorpus.upload_files',\n        'build_management.revisions.get_component_list',\n        'bot.testcase_manager.upload_log',\n        'bot.testcase_manager.upload_testcase',\n        'metrics.fuzzer_stats.upload_stats',\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    os.environ['JOB_NAME'] = 'libfuzzer_asan_test'\n    os.environ['FUZZ_INPUTS'] = '/fuzz-inputs'\n    os.environ['FUZZ_INPUTS_DISK'] = '/fuzz-inputs-disk'\n    os.environ['BUILD_DIR'] = '/build_dir'\n    os.environ['MAX_TESTCASES'] = '2'\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label,auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component,auto_component1'\n\n    self.fs.create_file('/build_dir/test_target')\n    self.fs.create_file(\n        '/build_dir/test_target.labels', contents='label1\\nlabel2')\n    self.fs.create_file(\n        '/build_dir/test_target.owners', contents='owner1@email.com')\n    self.fs.create_file(\n        '/build_dir/test_target.components', contents='component1\\ncomponent2')\n    self.fs.create_file('/input')\n\n    self.mock.sync_from_gcs.return_value = True\n    self.mock.upload_files.return_value = True\n    self.mock.get_component_list.return_value = [{\n        'component': 'component',\n        'link_text': 'rev',\n    }]\n    self.mock.current_timestamp.return_value = 0.0\n\n  def test_basic(self):\n    \"\"\"Test basic fuzzing session.\"\"\"\n    session = fuzz_task.FuzzingSession('libFuzzer', 'libfuzzer_asan_test', 60)\n    session.testcase_directory = os.environ['FUZZ_INPUTS']\n    session.data_directory = '/data_dir'\n\n    os.environ['FUZZ_TARGET'] = 'test_target'\n    os.environ['APP_REVISION'] = '1'\n\n    expected_crashes = [engine.Crash('/input', 'stack', ['args'], 1.0)]\n\n    engine_impl = mock.Mock()\n    engine_impl.name = 'libFuzzer'\n    engine_impl.prepare.return_value = engine.FuzzOptions(\n        '/corpus', ['arg'], {\n            'strategy_1': 1,\n            'strategy_2': 50,\n        })\n    engine_impl.fuzz.side_effect = lambda *_: engine.FuzzResult(\n        'logs', ['cmd'], expected_crashes, {'stat': 1}, 42.0)\n\n    crashes, fuzzer_metadata = session.do_engine_fuzzing(engine_impl)\n    self.assertDictEqual({\n        'fuzzer_binary_name':\n            'test_target',\n        'issue_components':\n            'component1,component2,auto_component,auto_component1',\n        'issue_labels':\n            'label1,label2,auto_label,auto_label1',\n        'issue_owners':\n            'owner1@email.com',\n    }, fuzzer_metadata)\n\n    log_time = datetime.datetime(1970, 1, 1, 0, 0)\n    log_call = mock.call(\n        'Component revisions (build r1):\\n'\n        'component: rev\\n\\n'\n        'Return code: 1\\n\\n'\n        'Command: cmd\\nBot: None\\nTime ran: 42.0\\n\\n'\n        'logs\\n'\n        'cf::fuzzing_strategies: strategy_1:1,strategy_2:50', log_time)\n    self.mock.upload_log.assert_has_calls([log_call, log_call])\n    self.mock.upload_testcase.assert_has_calls([\n        mock.call('/input', log_time),\n        mock.call('/input', log_time),\n    ])\n\n    self.assertEqual(2, len(crashes))\n    for i in range(2):\n      self.assertEqual('/input', crashes[i].file_path)\n      self.assertEqual(1, crashes[i].return_code)\n      self.assertEqual('stack', crashes[i].unsymbolized_crash_stacktrace)\n      self.assertEqual(1.0, crashes[i].crash_time)\n      self.assertEqual('args', crashes[i].arguments)\n\n    for i in range(2):\n      upload_args = self.mock.upload_stats.call_args_list[i][0][0]\n      testcase_run = upload_args[0]\n      self.assertDictEqual({\n          'build_revision': 1,\n          'command': ['cmd'],\n          'fuzzer': u'libFuzzer_test_target',\n          'job': 'libfuzzer_asan_test',\n          'kind': 'TestcaseRun',\n          'stat': 1,\n          'strategy_strategy_1': 1,\n          'strategy_strategy_2': 50,\n          'timestamp': 0.0,\n      }, testcase_run.data)\n\n\nclass UntrustedRunEngineFuzzerTest(\n    untrusted_runner_helpers.UntrustedRunnerIntegrationTest):\n  \"\"\"Engine fuzzing tests for untrusted.\"\"\"\n\n  def setUp(self):\n    \"\"\"Set up.\"\"\"\n    super(UntrustedRunEngineFuzzerTest, self).setUp()\n    environment.set_value('JOB_NAME', 'libfuzzer_asan_job')\n\n    job = data_types.Job(\n        name='libfuzzer_asan_job',\n        environment_string=(\n            'RELEASE_BUILD_BUCKET_PATH = '\n            'gs://clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-([0-9]+).zip\\n'\n            'REVISION_VARS_URL = https://commondatastorage.googleapis.com/'\n            'clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-%s.srcmap.json\\n'))\n    job.put()\n\n    self.temp_dir = tempfile.mkdtemp(dir=environment.get_value('FUZZ_INPUTS'))\n    environment.set_value('USE_MINIJAIL', False)\n\n  def tearDown(self):\n    super(UntrustedRunEngineFuzzerTest, self).tearDown()\n    shutil.rmtree(self.temp_dir, ignore_errors=True)\n\n  def test_run_engine_fuzzer(self):\n    \"\"\"Test running engine fuzzer.\"\"\"\n    self._setup_env(job_type='libfuzzer_asan_job')\n    environment.set_value('FUZZ_TEST_TIMEOUT', 3600)\n\n    build_manager.setup_build()\n    corpus_directory = os.path.join(self.temp_dir, 'corpus')\n    testcase_directory = os.path.join(self.temp_dir, 'artifacts')\n    os.makedirs(file_host.rebase_to_worker_root(corpus_directory))\n    os.makedirs(file_host.rebase_to_worker_root(testcase_directory))\n\n    result, fuzzer_metadata = fuzz_task.run_engine_fuzzer(\n        libfuzzer_engine.LibFuzzerEngine(), 'test_fuzzer', corpus_directory,\n        testcase_directory)\n    self.assertIn(\n        'ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000',\n        result.logs)\n    self.assertEqual(1, len(result.crashes))\n    self.assertTrue(result.crashes[0].input_path.startswith(\n        os.environ['ROOT_DIR']))\n    self.assertTrue(os.path.exists(result.crashes[0].input_path))\n    self.assertIsInstance(result.stats.get('number_of_executed_units'), int)\n    self.assertIsInstance(result.stats.get('oom_count'), int)\n    self.assertIsInstance(\n        result.stats.get('strategy_selection_method'), six.string_types)\n\n    self.assertDictEqual({'fuzzer_binary_name': 'test_fuzzer'}, fuzzer_metadata)\n\n\nclass AddIssueMetadataFromEnvironmentTest(unittest.TestCase):\n  \"\"\"Tests for _add_issue_metadata_from_environment.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n\n  def test_add_no_existing(self):\n    \"\"\"Test adding issue metadata when there are none existing.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components': 'auto_component,auto_component1',\n        'issue_labels': 'auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_append(self):\n    \"\"\"Test adding issue metadata when there are already existing metadata.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {\n        'issue_components': 'existing_component',\n        'issue_labels': 'existing_label'\n    }\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components':\n            'existing_component,auto_component,auto_component1',\n        'issue_labels':\n            'existing_label,auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_numeric(self):\n    \"\"\"Tests adding a numeric label.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = '123'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_labels': '123',\n    }, metadata)\n    \n    \n    \n    )\n    \n\n    \n    \n        \n        \n    \n    \n        \n        )\n\n        \n    )\n        \n    \n    \n\n        )\n\n\n        \n    \n        \n\n    )",
    "after": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"fuzz_task tests.\"\"\"\n# pylint: disable=protected-access\nfrom builtins import object\nfrom builtins import range\nimport datetime\nimport mock\nimport os\nimport parameterized\nimport shutil\nimport tempfile\nimport time\nimport unittest\n\nfrom pyfakefs import fake_filesystem_unittest\nimport six\n\nfrom base import utils\nfrom bot import testcase_manager\nfrom bot.fuzzers import engine\nfrom bot.fuzzers.libFuzzer import engine as libfuzzer_engine\nfrom bot.tasks import fuzz_task\nfrom bot.untrusted_runner import file_host\nfrom build_management import build_manager\nfrom chrome import crash_uploader\nfrom crash_analysis.stack_parsing import stack_analyzer\nfrom datastore import data_handler\nfrom datastore import data_types\nfrom datastore import ndb\nfrom google_cloud_utils import big_query\nfrom metrics import monitor\nfrom metrics import monitoring_metrics\nfrom system import environment\nfrom tests.test_libs import helpers\nfrom tests.test_libs import test_utils\nfrom tests.test_libs import untrusted_runner_helpers\n\n\nclass TrackFuzzerRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_fuzzer_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_fuzzer_run_result(self):\n    \"\"\"Ensure _track_fuzzer_run_result set the right metrics.\"\"\"\n    fuzz_task._track_fuzzer_run_result('name', 10, 100, 2)\n    fuzz_task._track_fuzzer_run_result('name', 100, 200, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 2000, 2)\n    fuzz_task._track_fuzzer_run_result('name', 1000, 500, 0)\n    fuzz_task._track_fuzzer_run_result('name', 0, 1000, -1)\n    fuzz_task._track_fuzzer_run_result('name', 0, 0, 2)\n\n    self.assertEqual(\n        4,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 2\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': 0\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.FUZZER_RETURN_CODE_COUNT.get({\n            'fuzzer': 'name',\n            'return_code': -1\n        }))\n\n    testcase_count_ratio = (\n        monitoring_metrics.FUZZER_TESTCASE_COUNT_RATIO.get({\n            'fuzzer': 'name'\n        }))\n    self.assertEqual(3.1, testcase_count_ratio.sum)\n    self.assertEqual(5, testcase_count_ratio.count)\n\n    expected_buckets = [0 for _ in range(22)]\n    expected_buckets[1] = 1\n    expected_buckets[3] = 1\n    expected_buckets[11] = 2\n    expected_buckets[21] = 1\n    self.assertListEqual(expected_buckets, testcase_count_ratio.buckets)\n\n\nclass TrackBuildRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_build_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_build_run_result(self):\n    \"\"\"Ensure _track_build_run_result set the right metrics.\"\"\"\n    fuzz_task._track_build_run_result('name', 10000, True)\n    fuzz_task._track_build_run_result('name', 10001, True)\n    fuzz_task._track_build_run_result('name', 10002, False)\n\n    self.assertEqual(\n        2,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': True\n        }))\n    self.assertEqual(\n        1,\n        monitoring_metrics.JOB_BAD_BUILD_COUNT.get({\n            'job': 'name',\n            'bad_build': False\n        }))\n\n\nclass TrackTestcaseRunResultTest(unittest.TestCase):\n  \"\"\"Test _track_testcase_run_result.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def test_testcase_run_result(self):\n    \"\"\"Ensure _track_testcase_run_result sets the right metrics.\"\"\"\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 2, 5)\n    fuzz_task._track_testcase_run_result('fuzzer', 'job', 5, 10)\n\n    self.assertEqual(7,\n                     monitoring_metrics.JOB_NEW_CRASH_COUNT.get({\n                         'job': 'job'\n                     }))\n    self.assertEqual(\n        15, monitoring_metrics.JOB_KNOWN_CRASH_COUNT.get({\n            'job': 'job'\n        }))\n    self.assertEqual(\n        7, monitoring_metrics.FUZZER_NEW_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n    self.assertEqual(\n        15, monitoring_metrics.FUZZER_KNOWN_CRASH_COUNT.get({\n            'fuzzer': 'fuzzer'\n        }))\n\n\nclass TruncateFuzzerOutputTest(unittest.TestCase):\n  \"\"\"Truncate fuzzer output tests.\"\"\"\n\n  def test_no_truncation(self):\n    \"\"\"No truncation.\"\"\"\n    self.assertEqual('aaaa', fuzz_task.truncate_fuzzer_output('aaaa', 10))\n\n  def test_truncation(self):\n    \"\"\"Truncate.\"\"\"\n    self.assertEqual(\n        '123456\\n...truncated...\\n54321',\n        fuzz_task.truncate_fuzzer_output(\n            '123456xxxxxxxxxxxxxxxxxxxxxxxxxxx54321', 28))\n\n  def test_error(self):\n    \"\"\"Error if limit is too low.\"\"\"\n    with self.assertRaises(AssertionError):\n      self.assertEqual(\n          '', fuzz_task.truncate_fuzzer_output('123456xxxxxx54321', 10))\n\n\nclass TrackFuzzTimeTest(unittest.TestCase):\n  \"\"\"Test _TrackFuzzTime.\"\"\"\n\n  def setUp(self):\n    monitor.metrics_store().reset_for_testing()\n\n  def _test(self, timeout):\n    \"\"\"Test helper.\"\"\"\n    time_module = helpers.MockTime()\n    with fuzz_task._TrackFuzzTime('fuzzer', 'job', time_module) as tracker:\n      time_module.advance(5)\n      tracker.timeout = timeout\n\n    fuzzer_total_time = monitoring_metrics.FUZZER_TOTAL_FUZZ_TIME.get({\n        'fuzzer': 'fuzzer',\n        'timeout': timeout\n    })\n    self.assertEqual(5, fuzzer_total_time)\n\n  def test_success(self):\n    \"\"\"Test report metrics.\"\"\"\n    self._test(False)\n\n  def test_timeout(self):\n    \"\"\"Test timeout.\"\"\"\n    self._test(True)\n\n\nclass GetFuzzerMetadataFromOutputTest(unittest.TestCase):\n  \"\"\"Test get_fuzzer_metadata_from_output.\"\"\"\n\n  def test_no_metadata(self):\n    \"\"\"Tests no metadata in output.\"\"\"\n    data = 'abc\\ndef\\n123123'\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n    data = ''\n    self.assertDictEqual(fuzz_task.get_fuzzer_metadata_from_output(data), {})\n\n  def test_metadata(self):\n    \"\"\"Tests parsing of metadata.\"\"\"\n    data = ('abc\\n'\n            'def\\n'\n            'metadata:invalid: invalid\\n'\n            'metadat::invalid: invalid\\n'\n            'metadata::foo: bar\\n'\n            '123123\\n'\n            'metadata::blah: 1\\n'\n            'metadata::test:abcd\\n'\n            'metadata::test2:   def\\n')\n    self.assertDictEqual(\n        fuzz_task.get_fuzzer_metadata_from_output(data), {\n            'blah': '1',\n            'test': 'abcd',\n            'test2': 'def',\n            'foo': 'bar'\n        })\n\n\nclass GetRegressionTest(unittest.TestCase):\n  \"\"\"Test get_regression.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, ['build_management.build_manager.is_custom_binary'])\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('NA', fuzz_task.get_regression(True))\n\n  def test_custom_binary(self):\n    \"\"\"Test for custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = True\n    self.assertEqual('NA', fuzz_task.get_regression(False))\n\n  def test_reproducible_non_custom_binary(self):\n    \"\"\"Test for reproducible non-custom binary.\"\"\"\n    self.mock.is_custom_binary.return_value = False\n    self.assertEqual('', fuzz_task.get_regression(False))\n\n\nclass GetFixedOrMinimizedKeyTest(unittest.TestCase):\n  \"\"\"Test get_fixed_or_minimized_key.\"\"\"\n\n  def test_one_time_crasher(self):\n    \"\"\"Test when one_time_crasher_flag is True.\"\"\"\n    self.assertEqual('NA', fuzz_task.get_fixed_or_minimized_key(True))\n\n  def test_reproducible(self):\n    \"\"\"Test for reproducible.\"\"\"\n    self.assertEqual('', fuzz_task.get_fixed_or_minimized_key(False))\n\n\nclass CrashInitTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test Crash.__init__.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.FileMetadataInfo',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'bot.testcase_manager.get_additional_command_line_flags',\n        'bot.testcase_manager.get_command_line_for_application',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n    ])\n    helpers.patch_environ(self)\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = 'state'\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_crash_stacktrace_output.return_value = 'trace'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', False)\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n  def test_error(self):\n    \"\"\"Test failing to reading stacktrace file.\"\"\"\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/no_stack_file'))\n    self.assertIsNone(crash)\n\n  def _test_crash(self, should_be_ignored, security_flag):\n    \"\"\"Test crash.\"\"\"\n    self.mock.get_command_line_for_application.reset_mock()\n    self.mock.get_crash_data.reset_mock()\n    self.mock.get_crash_stacktrace_output.reset_mock()\n    self.mock.is_security_issue.reset_mock()\n    self.mock.ignore_stacktrace.reset_mock()\n\n    self.mock.is_security_issue.return_value = security_flag\n    self.mock.ignore_stacktrace.return_value = should_be_ignored\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], 'ges',\n                               '/stack_file_path'))\n\n    self.assertEqual('dir/path-http-name', crash.file_path)\n    self.assertEqual(123, crash.crash_time)\n    self.assertEqual(11, crash.return_code)\n    self.assertListEqual(['res'], crash.resource_list)\n    self.assertEqual('ges', crash.gestures)\n\n    self.assertEqual('path-http-name', crash.filename)\n    self.assertTrue(crash.http_flag)\n\n    self.assertEqual('cmd', crash.application_command_line)\n    self.mock.get_command_line_for_application.assert_called_once_with(\n        'dir/path-http-name', needs_http=True)\n\n    self.assertEqual('unsym', crash.unsymbolized_crash_stacktrace)\n\n    self.assertEqual('type', crash.crash_type)\n    self.assertEqual('address', crash.crash_address)\n    self.assertEqual('state', crash.crash_state)\n    self.assertListEqual(['frame 1', 'frame 2'], crash.crash_frames)\n    self.mock.get_crash_data.assert_called_once_with('unsym')\n\n    self.assertEqual('trace', crash.crash_stacktrace)\n    self.mock.get_crash_stacktrace_output.assert_called_once_with(\n        'cmd', 'orig_trace', 'unsym')\n\n    self.assertEqual(security_flag, crash.security_flag)\n    self.mock.is_security_issue.assert_called_once_with('unsym', 'type',\n                                                        'address')\n\n    self.assertEqual('type,state,%s' % security_flag, crash.key)\n\n    self.assertEqual(should_be_ignored, crash.should_be_ignored)\n    self.mock.ignore_stacktrace.assert_called_once_with('orig_trace')\n\n    self.assertFalse(hasattr(crash, 'fuzzed_key'))\n    return crash\n\n  def _test_validity_and_get_functional_crash(self):\n    \"\"\"Test validity of different crashes and return functional crash.\"\"\"\n    security_crash = self._test_crash(\n        should_be_ignored=False, security_flag=True)\n    self.assertIsNone(security_crash.get_error())\n    self.assertTrue(security_crash.is_valid())\n\n    ignored_crash = self._test_crash(should_be_ignored=True, security_flag=True)\n    self.assertIn('False crash', ignored_crash.get_error())\n    self.assertFalse(ignored_crash.is_valid())\n\n    functional_crash = self._test_crash(\n        should_be_ignored=False, security_flag=False)\n    return functional_crash\n\n  def test_valid_functional_bug(self):\n    \"\"\"Test valid because of functional bug.\"\"\"\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIsNone(functional_crash.get_error())\n    self.assertTrue(functional_crash.is_valid())\n\n  def test_invalid_functional_bug(self):\n    \"\"\"Test invalid because of functional bug.\"\"\"\n    environment.set_value('FILTER_FUNCTIONAL_BUGS', True)\n    functional_crash = self._test_validity_and_get_functional_crash()\n\n    self.assertIn('Functional crash', functional_crash.get_error())\n    self.assertFalse(functional_crash.is_valid())\n\n  def test_hydrate_fuzzed_key(self):\n    \"\"\"Test hydrating fuzzed_key.\"\"\"\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    self.assertEqual('fuzzed_key', crash.fuzzed_key)\n    self.assertTrue(crash.archived)\n    self.assertEqual('absolute_path', crash.absolute_path)\n    self.assertEqual('archive_filename', crash.archive_filename)\n\n  def test_hydrate_fuzzed_key_failure(self):\n    \"\"\"Test fail to hydrate fuzzed_key.\"\"\"\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (None,\n                                                                       False,\n                                                                       None,\n                                                                       None)\n\n    crash = self._test_crash(should_be_ignored=False, security_flag=True)\n    self.assertFalse(crash.is_archived())\n    self.assertIsNone(crash.get_error())\n    self.assertTrue(crash.is_valid())\n\n    crash.archive_testcase_in_blobstore()\n    self.assertTrue(crash.is_archived())\n    self.assertIn('Unable to store testcase in blobstore', crash.get_error())\n    self.assertFalse(crash.is_valid())\n\n    self.assertIsNone(crash.fuzzed_key)\n    self.assertFalse(crash.archived)\n    self.assertIsNone(crash.absolute_path)\n    self.assertIsNone(crash.archive_filename)\n\n  def test_args_from_testcase_manager(self):\n    \"\"\"Test args from testcase_manager.Crash.\"\"\"\n    testcase_manager_crash = testcase_manager.Crash('path', 0, 0, [], [],\n                                                    '/stack_file_path')\n    self.mock.get_additional_command_line_flags.return_value = 'minimized'\n    environment.set_value('APP_ARGS', 'app')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(testcase_manager_crash)\n    self.assertEqual('app minimized', crash.arguments)\n\n\nclass CrashGroupTest(unittest.TestCase):\n  \"\"\"Test CrashGroup.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.tasks.fuzz_task.find_main_crash',\n        'datastore.data_handler.find_testcase',\n        'datastore.data_handler.get_project_name',\n    ])\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.crashes = [self._make_crash('g1'), self._make_crash('g2')]\n    self.context = mock.MagicMock(\n        test_timeout=99, fuzzer_name='test', fuzz_target=None)\n    self.reproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=False)\n    self.unreproducible_testcase = self._make_testcase(\n        project_name='some_project',\n        bug_information='',\n        one_time_crasher_flag=True)\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        crash_type='type',\n        crash_state='state',\n        security_flag=True,\n        file_path='file_path',\n        http_flag=True,\n        gestures=gestures)\n    return crash\n\n  def _make_testcase(self,\n                     project_name,\n                     bug_information,\n                     one_time_crasher_flag,\n                     timestamp=datetime.datetime.now()):\n    \"\"\"Make testcase.\"\"\"\n    testcase = data_types.Testcase()\n    testcase.timestamp = timestamp\n    testcase.one_time_crasher_flag = one_time_crasher_flag\n    testcase.bug_information = bug_information\n    testcase.project_name = project_name\n    return testcase\n\n  def test_no_existing_testcase(self):\n    \"\"\"is_new=True and should_create_testcase=True when there's no existing\n        testcase.\"\"\"\n    self.mock.find_testcase.return_value = None\n    self.mock.find_main_crash.return_value = self.crashes[0], True\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertTrue(group.should_create_testcase())\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n\n    self.assertIsNone(group.existing_testcase)\n    self.assertEqual(self.crashes[0], group.main_crash)\n    self.assertTrue(group.is_new())\n\n  def test_has_existing_reproducible_testcase(self):\n    \"\"\"should_create_testcase=False when there's an existing reproducible\n      testcase.\"\"\"\n    self.mock.find_testcase.return_value = self.reproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.should_create_testcase())\n    self.assertTrue(group.has_existing_reproducible_testcase())\n\n  def test_reproducible_crash(self):\n    \"\"\"should_create_testcase=True when the group is reproducible.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], False)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertTrue(group.should_create_testcase())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertFalse(group.one_time_crasher_flag)\n\n  def test_has_existing_unreproducible_testcase(self):\n    \"\"\"should_create_testcase=False when the unreproducible testcase already\n    exists.\"\"\"\n    self.mock.find_testcase.return_value = self.unreproducible_testcase\n    self.mock.find_main_crash.return_value = (self.crashes[0], True)\n\n    group = fuzz_task.CrashGroup(self.crashes, self.context)\n\n    self.assertFalse(group.should_create_testcase())\n\n    self.assertEqual(self.crashes[0].gestures, group.main_crash.gestures)\n    self.mock.find_main_crash.assert_called_once_with(\n        self.crashes, 'test', 'test', self.context.test_timeout)\n    self.assertFalse(group.is_new())\n    self.assertFalse(group.has_existing_reproducible_testcase())\n    self.assertTrue(group.one_time_crasher_flag)\n\n\nclass FindMainCrashTest(unittest.TestCase):\n  \"\"\"Test find_main_crash.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'bot.testcase_manager.test_for_reproducibility',\n    ])\n    self.crashes = [\n        self._make_crash('g1'),\n        self._make_crash('g2'),\n        self._make_crash('g3'),\n        self._make_crash('g4')\n    ]\n    self.reproducible_crashes = []\n\n    # pylint: disable=unused-argument\n    def test_for_repro(fuzzer_name,\n                       full_fuzzer_name,\n                       file_path,\n                       state,\n                       security_flag,\n                       test_timeout,\n                       http_flag,\n                       gestures,\n                       arguments=None):\n      \"\"\"Mock test_for_reproducibility.\"\"\"\n      for c in self.reproducible_crashes:\n        if c.gestures == gestures:\n          return True\n      return False\n\n    self.mock.test_for_reproducibility.side_effect = test_for_repro\n\n  def _make_crash(self, gestures):\n    crash = mock.MagicMock(\n        file_path='file_path',\n        crash_state='state',\n        security_flag=True,\n        test_timeout=999,\n        gestures=gestures)\n    return crash\n\n  def test_reproducible_crash(self):\n    \"\"\"Find that the 2nd crash is reproducible.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = [self.crashes[2]]\n\n    self.assertEqual((self.crashes[2], False),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    self.crashes[0].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[1].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[2].archive_testcase_in_blobstore.assert_called_once_with()\n    self.crashes[3].archive_testcase_in_blobstore.assert_not_called()\n\n    # Calls for self.crashes[1] and self.crashes[2].\n    self.assertEqual(2, self.mock.test_for_reproducibility.call_count)\n\n  def test_unreproducible_crash(self):\n    \"\"\"No reproducible crash. Find the first valid one.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = True\n    self.crashes[0].is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((self.crashes[1], True),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    # Calls for every crash except self.crashes[0] because it's invalid.\n    self.assertEqual(\n        len(self.crashes) - 1, self.mock.test_for_reproducibility.call_count)\n\n  def test_no_valid_crash(self):\n    \"\"\"No valid crash.\"\"\"\n    for c in self.crashes:\n      c.is_valid.return_value = False\n    self.reproducible_crashes = []\n\n    self.assertEqual((None, None),\n                     fuzz_task.find_main_crash(self.crashes, 'test', 'test',\n                                               99))\n\n    for c in self.crashes:\n      c.archive_testcase_in_blobstore.assert_called_once_with()\n\n    self.assertEqual(0, self.mock.test_for_reproducibility.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass ProcessCrashesTest(fake_filesystem_unittest.TestCase):\n  \"\"\"Test process_crashes.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'chrome.crash_uploader.get_symbolized_stack_bytes',\n        'bot.tasks.task_creation.create_tasks',\n        'bot.tasks.setup.archive_testcase_and_dependencies_in_gcs',\n        'crash_analysis.stack_parsing.stack_analyzer.get_crash_data',\n        'build_management.revisions.get_real_revision',\n        'bot.testcase_manager.get_command_line_for_application',\n        'bot.testcase_manager.test_for_reproducibility',\n        'base.utils.get_crash_stacktrace_output',\n        'crash_analysis.crash_analyzer.ignore_stacktrace',\n        'crash_analysis.crash_analyzer.is_security_issue',\n        'datastore.data_handler.get_issue_tracker_name',\n        'datastore.data_handler.get_project_name',\n        'google.appengine.api.app_identity.get_application_id',\n        'google_cloud_utils.big_query.Client.insert',\n        'google_cloud_utils.big_query.get_api_client', 'time.sleep', 'time.time'\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    self.mock.time.return_value = 987\n\n    self.mock.get_issue_tracker_name.return_value = 'some_issue_tracker'\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.archive_testcase_and_dependencies_in_gcs.return_value = (\n        'fuzzed_key', True, 'absolute_path', 'archive_filename')\n\n  def _make_crash(self, trace, state='state'):\n    \"\"\"Make crash.\"\"\"\n    self.mock.get_real_revision.return_value = 'this.is.fake.ver'\n\n    self.mock.get_command_line_for_application.return_value = 'cmd'\n    dummy_state = stack_analyzer.StackAnalyzerState()\n    dummy_state.crash_type = 'type'\n    dummy_state.crash_address = 'address'\n    dummy_state.crash_state = state\n    dummy_state.crash_stacktrace = 'orig_trace'\n    dummy_state.crash_frames = ['frame 1', 'frame 2']\n    self.mock.get_crash_data.return_value = dummy_state\n    self.mock.get_symbolized_stack_bytes.return_value = 'f00df00d'\n    self.mock.get_crash_stacktrace_output.return_value = trace\n    self.mock.is_security_issue.return_value = True\n    self.mock.ignore_stacktrace.return_value = False\n\n    with open('/stack_file_path', 'w') as f:\n      f.write('unsym')\n\n    crash = fuzz_task.Crash.from_testcase_manager_crash(\n        testcase_manager.Crash('dir/path-http-name', 123, 11, ['res'], ['ges'],\n                               '/stack_file_path'))\n    return crash\n\n  def test_existing_unreproducible_testcase(self):\n    \"\"\"Test existing unreproducible testcase.\"\"\"\n    crashes = [self._make_crash('c1'), self._make_crash('c2')]\n    self.mock.test_for_reproducibility.return_value = False\n\n    existing_testcase = data_types.Testcase()\n    existing_testcase.crash_stacktrace = 'existing'\n    existing_testcase.crash_type = crashes[0].crash_type\n    existing_testcase.crash_state = crashes[0].crash_state\n    existing_testcase.security_flag = crashes[0].security_flag\n    existing_testcase.one_time_crasher_flag = True\n    existing_testcase.job_type = 'existing_job'\n    existing_testcase.timestamp = datetime.datetime.now()\n    existing_testcase.project_name = 'some_project'\n    existing_testcase.put()\n\n    variant = data_types.TestcaseVariant()\n    variant.status = data_types.TestcaseVariantStatus.UNREPRODUCIBLE\n    variant.job_type = 'job'\n    variant.testcase_id = existing_testcase.key.id()\n    variant.put()\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name='some_project',\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=True,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(0, new_crash_count)\n    self.assertEqual(2, known_crash_count)\n\n    self.assertEqual(1, len(groups))\n    self.assertEqual(2, len(groups[0].crashes))\n    self.assertFalse(groups[0].is_new())\n    self.assertEqual(crashes[0].crash_type, groups[0].main_crash.crash_type)\n    self.assertEqual(crashes[0].crash_state, groups[0].main_crash.crash_state)\n    self.assertEqual(crashes[0].security_flag,\n                     groups[0].main_crash.security_flag)\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(1, len(testcases))\n    self.assertEqual('existing', testcases[0].crash_stacktrace)\n\n    variant = data_handler.get_testcase_variant(existing_testcase.key.id(),\n                                                'job')\n    self.assertEqual(data_types.TestcaseVariantStatus.FLAKY, variant.status)\n    self.assertEqual('fuzzed_key', variant.reproducer_key)\n    self.assertEqual(1234, variant.revision)\n    self.assertEqual('type', variant.crash_type)\n    self.assertEqual('state', variant.crash_state)\n    self.assertEqual(True, variant.security_flag)\n    self.assertEqual(True, variant.is_similar)\n\n  @parameterized.parameterized.expand(['some_project', 'chromium'])\n  def test_create_many_groups(self, project_name):\n    \"\"\"Test creating many groups.\"\"\"\n    self.mock.get_project_name.return_value = project_name\n\n    self.mock.insert.return_value = {'insertErrors': [{'index': 0}]}\n\n    # TODO(metzman): Add a seperate test for strategies.\n    r2_stacktrace = ('r2\\ncf::fuzzing_strategies: value_profile\\n')\n\n    crashes = [\n        self._make_crash('r1', state='reproducible1'),\n        self._make_crash(r2_stacktrace, state='reproducible1'),\n        self._make_crash('r3', state='reproducible1'),\n        self._make_crash('r4', state='reproducible2'),\n        self._make_crash('u1', state='unreproducible1'),\n        self._make_crash('u2', state='unreproducible2'),\n        self._make_crash('u3', state='unreproducible2'),\n        self._make_crash('u4', state='unreproducible3')\n    ]\n\n    self.mock.test_for_reproducibility.side_effect = [\n        False,  # For r1. It returns False. So, r1 is demoted.\n        True,  # For r2. It returns True. So, r2 becomes primary for its group.\n        True,  # For r4.\n        False,  # For u1.\n        False,  # For u2.\n        False,  # For u3.\n        False\n    ]  # For u4.\n\n    new_crash_count, known_crash_count, groups = fuzz_task.process_crashes(\n        crashes=crashes,\n        context=fuzz_task.Context(\n            project_name=project_name,\n            bot_name='bot',\n            job_type='job',\n            fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n            redzone=111,\n            disable_ubsan=False,\n            platform_id='platform',\n            crash_revision=1234,\n            fuzzer_name='fuzzer',\n            window_argument='win_args',\n            fuzzer_metadata={},\n            testcases_metadata={},\n            timeout_multiplier=1,\n            test_timeout=2,\n            thread_wait_timeout=3,\n            data_directory='/data'))\n    self.assertEqual(5, new_crash_count)\n    self.assertEqual(3, known_crash_count)\n\n    self.assertEqual(5, len(groups))\n    self.assertEqual([\n        'reproducible1', 'reproducible2', 'unreproducible1', 'unreproducible2',\n        'unreproducible3'\n    ], [group.main_crash.crash_state for group in groups])\n    self.assertEqual([True, True, True, True, True],\n                     [group.is_new() for group in groups])\n    self.assertEqual([3, 1, 1, 2, 1], [len(group.crashes) for group in groups])\n\n    testcases = list(data_types.Testcase.query())\n    self.assertEqual(5, len(testcases))\n    self.assertSetEqual(\n        set([r2_stacktrace, 'r4', 'u1', 'u2', 'u4']),\n        set(t.crash_stacktrace for t in testcases))\n\n    self.assertSetEqual(\n        set([\n            '{\"fuzzing_strategies\": [\"value_profile\"]}', None, None, None, None\n        ]), set(t.additional_metadata for t in testcases))\n\n    # r2 is a reproducible crash, so r3 doesn't\n    # invoke archive_testcase_in_blobstore. Therefore, the\n    # archive_testcase_in_blobstore is called `len(crashes) - 1`.\n    self.assertEqual(\n        len(crashes) - 1,\n        self.mock.archive_testcase_and_dependencies_in_gcs.call_count)\n\n    # Check only the desired testcases were saved.\n    actual_crash_infos = [group.main_crash.crash_info for group in groups]\n    if project_name != 'chromium':\n      expected_crash_infos = [None] * len(actual_crash_infos)\n    else:\n      expected_saved_crash_info = crash_uploader.CrashReportInfo(\n          product='Chrome_' + environment.platform().lower().capitalize(),\n          version='this.is.fake.ver',\n          serialized_crash_stack_frames='f00df00d')\n      expected_crash_infos = [\n          expected_saved_crash_info,  # r2 is main crash for group r1,r2,r3\n          expected_saved_crash_info,  # r4 is main crash for its own group\n          None,  # u1 is not reproducible\n          None,  # u2, u3 are not reproducible\n          None,  # u4 is not reproducible\n      ]\n\n    self.assertEqual(len(expected_crash_infos), len(actual_crash_infos))\n    for expected, actual in zip(expected_crash_infos, actual_crash_infos):\n      if not expected:\n        self.assertIsNone(actual)\n        continue\n\n      self.assertEqual(expected.product, actual.product)\n      self.assertEqual(expected.version, actual.version)\n      self.assertEqual(expected.serialized_crash_stack_frames,\n                       actual.serialized_crash_stack_frames)\n\n    def _make_big_query_json(crash, reproducible_flag, new_flag, testcase_id):\n      return {\n          'crash_type': crash.crash_type,\n          'crash_state': crash.crash_state,\n          'created_at': 987,\n          'platform': 'platform',\n          'crash_time_in_ms': int(crash.crash_time * 1000),\n          'parent_fuzzer_name': 'engine',\n          'fuzzer_name': 'engine_binary',\n          'job_type': 'job',\n          'security_flag': crash.security_flag,\n          'reproducible_flag': reproducible_flag,\n          'revision': '1234',\n          'new_flag': new_flag,\n          'project': project_name,\n          'testcase_id': testcase_id\n      }\n\n    def _get_testcase_id(crash):\n      rows = list(\n          data_types.Testcase.query(\n              data_types.Testcase.crash_type == crash.crash_type,\n              data_types.Testcase.crash_state == crash.crash_state,\n              data_types.Testcase.security_flag == crash.security_flag))\n      if not rows:\n        return None\n      return str(rows[0].key.id())\n\n    # Calls to write 5 groups of crashes to BigQuery.\n    self.assertEqual(5, self.mock.insert.call_count)\n    self.mock.insert.assert_has_calls([\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[0], True, False, None),\n                '%s:bot:987:0' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[1], True, True,\n                                     _get_testcase_id(crashes[1])),\n                '%s:bot:987:1' % crashes[0].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[2], True, False, None),\n                '%s:bot:987:2' % crashes[0].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[3], True, True,\n                                     _get_testcase_id(crashes[3])),\n                '%s:bot:987:0' % crashes[3].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[4], False, True,\n                                     _get_testcase_id(crashes[4])),\n                '%s:bot:987:0' % crashes[4].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[5], False, True,\n                                     _get_testcase_id(crashes[5])),\n                '%s:bot:987:0' % crashes[5].key),\n            big_query.Insert(\n                _make_big_query_json(crashes[6], False, False, None),\n                '%s:bot:987:1' % crashes[5].key)\n        ]),\n        mock.call(mock.ANY, [\n            big_query.Insert(\n                _make_big_query_json(crashes[7], False, True,\n                                     _get_testcase_id(crashes[7])),\n                '%s:bot:987:0' % crashes[7].key)\n        ]),\n    ])\n\n\nclass WriteCrashToBigQueryTest(unittest.TestCase):\n  \"\"\"Test write_crash_to_big_query.\"\"\"\n\n  def setUp(self):\n    self.client = mock.Mock(spec_set=big_query.Client)\n    helpers.patch(self, [\n        'system.environment.get_value',\n        'datastore.data_handler.get_project_name',\n        'google_cloud_utils.big_query.Client',\n        'time.time',\n    ])\n    monitor.metrics_store().reset_for_testing()\n\n    self.mock.get_project_name.return_value = 'some_project'\n    self.mock.get_value.return_value = 'bot'\n    self.mock.Client.return_value = self.client\n    self.mock.time.return_value = 99\n    self.crashes = [\n        self._make_crash('c1'),\n        self._make_crash('c2'),\n        self._make_crash('c3')\n    ]\n\n    newly_created_testcase = mock.MagicMock()\n    newly_created_testcase.key.id.return_value = 't'\n    self.group = mock.MagicMock(\n        crashes=self.crashes,\n        main_crash=self.crashes[0],\n        one_time_crasher_flag=False,\n        newly_created_testcase=newly_created_testcase)\n    self.group.is_new.return_value = True\n\n  def _create_context(self, job_type, platform_id):\n    return fuzz_task.Context(\n        project_name='some_project',\n        bot_name='bot',\n        job_type=job_type,\n        fuzz_target=data_types.FuzzTarget(engine='engine', binary='binary'),\n        redzone=32,\n        disable_ubsan=False,\n        platform_id=platform_id,\n        crash_revision=1234,\n        fuzzer_name='engine',\n        window_argument='windows_args',\n        fuzzer_metadata={},\n        testcases_metadata={},\n        timeout_multiplier=1.0,\n        test_timeout=5,\n        thread_wait_timeout=6,\n        data_directory='data')\n\n  def _make_crash(self, state):\n    crash = mock.Mock(\n        crash_type='type',\n        crash_state=state,\n        crash_time=111,\n        security_flag=True,\n        key='key')\n    return crash\n\n  def _json(self, job, platform, state, new_flag, testcase_id):\n    return {\n        'crash_type': 'type',\n        'crash_state': state,\n        'created_at': 99,\n        'platform': platform,\n        'crash_time_in_ms': 111000,\n        'parent_fuzzer_name': 'engine',\n        'fuzzer_name': 'engine_binary',\n        'job_type': job,\n        'security_flag': True,\n        'reproducible_flag': True,\n        'revision': '1234',\n        'new_flag': new_flag,\n        'project': 'some_project',\n        'testcase_id': testcase_id\n    }\n\n  def test_all_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(3, success_count)\n    self.assertEqual(0, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_succeed(self):\n    \"\"\"Test writing succeeds.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job', 'linux', 'c1', True, 't'), 'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c2', False, None), 'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job', 'linux', 'c3', False, None), 'key:bot:99:2')\n    ])\n\n  def test_chromeos_platform(self):\n    \"\"\"Test ChromeOS platform is written in stats.\"\"\"\n    self.client.insert.return_value = {'insertErrors': [{'index': 1}]}\n    context = self._create_context('job_chromeos', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(2, success_count)\n    self.assertEqual(1, failure_count)\n\n    self.mock.Client.assert_called_once_with(\n        dataset_id='main', table_id='crashes$19700101')\n    self.client.insert.assert_called_once_with([\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c1', True, 't'),\n            'key:bot:99:0'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c2', False, None),\n            'key:bot:99:1'),\n        big_query.Insert(\n            self._json('job_chromeos', 'chrome', 'c3', False, None),\n            'key:bot:99:2')\n    ])\n\n  def test_exception(self):\n    \"\"\"Test writing raising an exception.\"\"\"\n    self.client.insert.side_effect = Exception('error')\n    context = self._create_context('job', 'linux')\n    fuzz_task.write_crashes_to_big_query(self.group, context)\n\n    success_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': True\n    })\n    failure_count = monitoring_metrics.BIG_QUERY_WRITE_COUNT.get({\n        'success': False\n    })\n\n    self.assertEqual(0, success_count)\n    self.assertEqual(3, failure_count)\n\n\nclass ConvertGroupsToCrashesTest(object):\n  \"\"\"Test convert_groups_to_crashes.\"\"\"\n\n  def test_convert(self):\n    \"\"\"Test converting.\"\"\"\n    groups = [\n        mock.Mock(\n            crashes=[mock.Mock(), mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t1', crash_state='s1', security_flag=True)),\n        mock.Mock(\n            crashes=[mock.Mock()],\n            main_crash=mock.Mock(\n                crash_type='t2', crash_state='s2', security_flag=False)),\n    ]\n    groups[0].is_new.return_value = False\n    groups[1].is_new.return_value = True\n\n    self.assertEqual([\n        {\n            'is_new': False,\n            'count': 2,\n            'crash_type': 't1',\n            'crash_state': 's1',\n            'security_flag': True\n        },\n        {\n            'is_new': True,\n            'count': 1,\n            'crash_type': 't2',\n            'crash_state': 's2',\n            'security_flag': False\n        },\n    ], fuzz_task.convert_groups_to_crashes(groups))\n\n\nclass TestCorpusSync(fake_filesystem_unittest.TestCase):\n  \"\"\"Test corpus sync.\"\"\"\n\n  def setUp(self):\n    helpers.patch(self, [\n        'fuzzing.corpus_manager.FuzzTargetCorpus.rsync_to_disk',\n        'fuzzing.corpus_manager.FuzzTargetCorpus.upload_files',\n        'google_cloud_utils.storage.last_updated',\n    ])\n\n    helpers.patch_environ(self)\n\n    os.environ['FAIL_RETRIES'] = '1'\n    os.environ['CORPUS_BUCKET'] = 'bucket'\n\n    self.mock.rsync_to_disk.return_value = True\n    test_utils.set_up_pyfakefs(self)\n    self.fs.create_dir('/dir')\n    self.fs.create_dir('/dir1')\n\n  def _write_corpus_files(self, *args, **kwargs):  # pylint: disable=unused-argument\n    self.fs.create_file('/dir/a')\n    self.fs.create_file('/dir/b')\n    return True\n\n  def test_sync(self):\n    \"\"\"Test corpus sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    self.mock.rsync_to_disk.side_effect = self._write_corpus_files\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertTrue(os.path.exists('/dir1/.child_sync'))\n    self.assertEqual(('/dir',), self.mock.rsync_to_disk.call_args[0][1:])\n    self.fs.create_file('/dir/c')\n    self.assertListEqual(['/dir/c'], corpus.get_new_files())\n\n    corpus.upload_files(corpus.get_new_files())\n    self.assertEqual((['/dir/c'],), self.mock.upload_files.call_args[0][1:])\n\n    self.assertListEqual([], corpus.get_new_files())\n\n  def test_no_sync(self):\n    \"\"\"Test no corpus sync when bundle is not updated since last sync.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = (\n        datetime.datetime.utcnow() - datetime.timedelta(days=1))\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(0, self.mock.rsync_to_disk.call_count)\n\n  def test_sync_with_failed_last_update(self):\n    \"\"\"Test corpus sync when failed to get last update info from gcs.\"\"\"\n    corpus = fuzz_task.GcsCorpus('parent', 'child', '/dir', '/dir1')\n\n    utils.write_data_to_file(time.time(), '/dir1/.child_sync')\n    self.mock.last_updated.return_value = None\n    self.assertTrue(corpus.sync_from_gcs())\n    self.assertEqual(1, self.mock.rsync_to_disk.call_count)\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass RecordFuzzTargetTest(unittest.TestCase):\n  \"\"\"Tests for record_fuzz_target.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'base.utils.is_oss_fuzz',\n        'base.utils.utcnow',\n    ])\n\n    self.mock.is_oss_fuzz.return_value = False\n    self.mock.utcnow.return_value = datetime.datetime(2018, 1, 1)\n\n  def test_record_fuzz_target(self):\n    \"\"\"Test that record_fuzz_target works.\"\"\"\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_existing(self):\n    \"\"\"Test that record_fuzz_target works when updating an existing entity.\"\"\"\n    data_types.FuzzTarget(\n        binary='child', engine='libFuzzer', project='test-project').put()\n    data_types.FuzzTargetJob(\n        fuzz_target_name='libFuzzer_child',\n        job='job',\n        engine='libFuzzer',\n        last_run=datetime.datetime(2017, 12, 31, 0, 0)).put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', 'child', 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertDictEqual({\n        'binary': 'child',\n        'engine': 'libFuzzer',\n        'project': 'test-project',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('child', fuzz_target.project_qualified_name())\n\n  def test_record_fuzz_target_no_binary_name(self):\n    \"\"\"Test recording fuzz target with no binary.\"\"\"\n    # Passing None to binary_name is an error. We shouldn't create any\n    # FuzzTargets as a result.\n    fuzz_task.record_fuzz_target('libFuzzer', None, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_child').get()\n    self.assertIsNone(fuzz_target)\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob, 'libFuzzer_child/job').get()\n    self.assertIsNone(job_mapping)\n\n  @parameterized.parameterized.expand(['child', 'proj_child'])\n  def test_record_fuzz_target_ossfuzz(self, binary_name):\n    \"\"\"Test that record_fuzz_target works with OSS-Fuzz projects.\"\"\"\n    self.mock.is_oss_fuzz.return_value = True\n    data_types.Job(name='job', environment_string='PROJECT_NAME = proj\\n').put()\n\n    fuzz_task.record_fuzz_target('libFuzzer', binary_name, 'job')\n    fuzz_target = ndb.Key(data_types.FuzzTarget, 'libFuzzer_proj_child').get()\n    self.assertDictEqual({\n        'binary': binary_name,\n        'engine': 'libFuzzer',\n        'project': 'proj',\n    }, fuzz_target.to_dict())\n\n    job_mapping = ndb.Key(data_types.FuzzTargetJob,\n                          'libFuzzer_proj_child/job').get()\n    self.assertDictEqual({\n        'fuzz_target_name': 'libFuzzer_proj_child',\n        'job': 'job',\n        'engine': 'libFuzzer',\n        'last_run': datetime.datetime(2018, 1, 1, 0, 0),\n        'weight': 1.0,\n    }, job_mapping.to_dict())\n\n    self.assertEqual('libFuzzer_proj_child', fuzz_target.fully_qualified_name())\n    self.assertEqual('proj_child', fuzz_target.project_qualified_name())\n\n\n@test_utils.with_cloud_emulators('datastore')\nclass DoEngineFuzzingTest(fake_filesystem_unittest.TestCase):\n  \"\"\"do_engine_fuzzing tests.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n    helpers.patch(self, [\n        'bot.fuzzers.engine_common.current_timestamp',\n        'bot.tasks.fuzz_task.GcsCorpus.sync_from_gcs',\n        'bot.tasks.fuzz_task.GcsCorpus.upload_files',\n        'build_management.revisions.get_component_list',\n        'bot.testcase_manager.upload_log',\n        'bot.testcase_manager.upload_testcase',\n        'metrics.fuzzer_stats.upload_stats',\n    ])\n    test_utils.set_up_pyfakefs(self)\n\n    os.environ['JOB_NAME'] = 'libfuzzer_asan_test'\n    os.environ['FUZZ_INPUTS'] = '/fuzz-inputs'\n    os.environ['FUZZ_INPUTS_DISK'] = '/fuzz-inputs-disk'\n    os.environ['BUILD_DIR'] = '/build_dir'\n    os.environ['MAX_TESTCASES'] = '2'\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label,auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component,auto_component1'\n\n    self.fs.create_file('/build_dir/test_target')\n    self.fs.create_file(\n        '/build_dir/test_target.labels', contents='label1\\nlabel2')\n    self.fs.create_file(\n        '/build_dir/test_target.owners', contents='owner1@email.com')\n    self.fs.create_file(\n        '/build_dir/test_target.components', contents='component1\\ncomponent2')\n    self.fs.create_file('/input')\n\n    self.mock.sync_from_gcs.return_value = True\n    self.mock.upload_files.return_value = True\n    self.mock.get_component_list.return_value = [{\n        'component': 'component',\n        'link_text': 'rev',\n    }]\n    self.mock.current_timestamp.return_value = 0.0\n\n  def test_basic(self):\n    \"\"\"Test basic fuzzing session.\"\"\"\n    session = fuzz_task.FuzzingSession('libFuzzer', 'libfuzzer_asan_test', 60)\n    session.testcase_directory = os.environ['FUZZ_INPUTS']\n    session.data_directory = '/data_dir'\n\n    os.environ['FUZZ_TARGET'] = 'test_target'\n    os.environ['APP_REVISION'] = '1'\n\n    expected_crashes = [engine.Crash('/input', 'stack', ['args'], 1.0)]\n\n    engine_impl = mock.Mock()\n    engine_impl.name = 'libFuzzer'\n    engine_impl.prepare.return_value = engine.FuzzOptions(\n        '/corpus', ['arg'], {\n            'strategy_1': 1,\n            'strategy_2': 50,\n        })\n    engine_impl.fuzz.side_effect = lambda *_: engine.FuzzResult(\n        'logs', ['cmd'], expected_crashes, {'stat': 1}, 42.0)\n\n    crashes, fuzzer_metadata = session.do_engine_fuzzing(engine_impl)\n    self.assertDictEqual({\n        'fuzzer_binary_name':\n            'test_target',\n        'issue_components':\n            'component1,component2,auto_component,auto_component1',\n        'issue_labels':\n            'label1,label2,auto_label,auto_label1',\n        'issue_owners':\n            'owner1@email.com',\n    }, fuzzer_metadata)\n\n    log_time = datetime.datetime(1970, 1, 1, 0, 0)\n    log_call = mock.call(\n        'Component revisions (build r1):\\n'\n        'component: rev\\n\\n'\n        'Return code: 1\\n\\n'\n        'Command: cmd\\nBot: None\\nTime ran: 42.0\\n\\n'\n        'logs\\n'\n        'cf::fuzzing_strategies: strategy_1:1,strategy_2:50', log_time)\n    self.mock.upload_log.assert_has_calls([log_call, log_call])\n    self.mock.upload_testcase.assert_has_calls([\n        mock.call('/input', log_time),\n        mock.call('/input', log_time),\n    ])\n\n    self.assertEqual(2, len(crashes))\n    for i in range(2):\n      self.assertEqual('/input', crashes[i].file_path)\n      self.assertEqual(1, crashes[i].return_code)\n      self.assertEqual('stack', crashes[i].unsymbolized_crash_stacktrace)\n      self.assertEqual(1.0, crashes[i].crash_time)\n      self.assertEqual('args', crashes[i].arguments)\n\n    for i in range(2):\n      upload_args = self.mock.upload_stats.call_args_list[i][0][0]\n      testcase_run = upload_args[0]\n      self.assertDictEqual({\n          'build_revision': 1,\n          'command': ['cmd'],\n          'fuzzer': u'libFuzzer_test_target',\n          'job': 'libfuzzer_asan_test',\n          'kind': 'TestcaseRun',\n          'stat': 1,\n          'strategy_strategy_1': 1,\n          'strategy_strategy_2': 50,\n          'timestamp': 0.0,\n      }, testcase_run.data)\n\n\nclass UntrustedRunEngineFuzzerTest(\n    untrusted_runner_helpers.UntrustedRunnerIntegrationTest):\n  \"\"\"Engine fuzzing tests for untrusted.\"\"\"\n\n  def setUp(self):\n    \"\"\"Set up.\"\"\"\n    super(UntrustedRunEngineFuzzerTest, self).setUp()\n    environment.set_value('JOB_NAME', 'libfuzzer_asan_job')\n\n    job = data_types.Job(\n        name='libfuzzer_asan_job',\n        environment_string=(\n            'RELEASE_BUILD_BUCKET_PATH = '\n            'gs://clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-([0-9]+).zip\\n'\n            'REVISION_VARS_URL = https://commondatastorage.googleapis.com/'\n            'clusterfuzz-test-data/test_libfuzzer_builds/'\n            'test-libfuzzer-build-%s.srcmap.json\\n'))\n    job.put()\n\n    self.temp_dir = tempfile.mkdtemp(dir=environment.get_value('FUZZ_INPUTS'))\n    environment.set_value('USE_MINIJAIL', False)\n\n  def tearDown(self):\n    super(UntrustedRunEngineFuzzerTest, self).tearDown()\n    shutil.rmtree(self.temp_dir, ignore_errors=True)\n\n  def test_run_engine_fuzzer(self):\n    \"\"\"Test running engine fuzzer.\"\"\"\n    self._setup_env(job_type='libfuzzer_asan_job')\n    environment.set_value('FUZZ_TEST_TIMEOUT', 3600)\n\n    build_manager.setup_build()\n    corpus_directory = os.path.join(self.temp_dir, 'corpus')\n    testcase_directory = os.path.join(self.temp_dir, 'artifacts')\n    os.makedirs(file_host.rebase_to_worker_root(corpus_directory))\n    os.makedirs(file_host.rebase_to_worker_root(testcase_directory))\n\n    result, fuzzer_metadata = fuzz_task.run_engine_fuzzer(\n        libfuzzer_engine.LibFuzzerEngine(), 'test_fuzzer', corpus_directory,\n        testcase_directory)\n    self.assertIn(\n        'ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000',\n        result.logs)\n    self.assertEqual(1, len(result.crashes))\n    self.assertTrue(result.crashes[0].input_path.startswith(\n        os.environ['ROOT_DIR']))\n    self.assertTrue(os.path.exists(result.crashes[0].input_path))\n    self.assertIsInstance(result.stats.get('number_of_executed_units'), int)\n    self.assertIsInstance(result.stats.get('oom_count'), int)\n    self.assertIsInstance(\n        result.stats.get('strategy_selection_method'), six.string_types)\n\n    self.assertDictEqual({'fuzzer_binary_name': 'test_fuzzer'}, fuzzer_metadata)\n\n\nclass AddIssueMetadataFromEnvironmentTest(unittest.TestCase):\n  \"\"\"Tests for _add_issue_metadata_from_environment.\"\"\"\n\n  def setUp(self):\n    helpers.patch_environ(self)\n\n  def test_add_no_existing(self):\n    \"\"\"Test adding issue metadata when there are none existing.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components': 'auto_component,auto_component1',\n        'issue_labels': 'auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_append(self):\n    \"\"\"Test adding issue metadata when there are already existing metadata.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = 'auto_label'\n    os.environ['AUTOMATIC_LABELS_1'] = 'auto_label1'\n    os.environ['AUTOMATIC_COMPONENTS'] = 'auto_component'\n    os.environ['AUTOMATIC_COMPONENTS_1'] = 'auto_component1'\n\n    metadata = {\n        'issue_components': 'existing_component',\n        'issue_labels': 'existing_label'\n    }\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_components':\n            'existing_component,auto_component,auto_component1',\n        'issue_labels':\n            'existing_label,auto_label,auto_label1',\n    }, metadata)\n\n  def test_add_numeric(self):\n    \"\"\"Tests adding a numeric label.\"\"\"\n    os.environ['AUTOMATIC_LABELS'] = '123'\n\n    metadata = {}\n    fuzz_task._add_issue_metadata_from_environment(metadata)\n    self.assertDictEqual({\n        'issue_labels': '123',\n    }, metadata)\n's.\n\n.\n\n, but, and's, and the.\n\n'\n\n.\n\n\n. \n\n'\n\n'\n\n'\n\n \n\nthe. \n'\n\n's.\n\n'\n\n.\n\n'\n\n.' "
  },
  "feature_stats": {
    "indices": [
      1,
      2,
      6781,
      3935,
      8932,
      5453,
      5150,
      3407,
      9023,
      8468,
      3176
    ],
    "f_before": [
      32.1451416015625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.2514786422252655,
      0.0
    ],
    "f_after": [
      32.1451416015625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.2514786422252655,
      0.0
    ],
    "g_before": [
      0.01743863895535469,
      5.722867012023926,
      3.4125545024871826,
      3.123914957046509,
      3.064659357070923,
      3.231292486190796,
      3.019371271133423,
      0.13981662690639496,
      0.0,
      3.011216402053833,
      0.022644726559519768
    ],
    "g_after": [
      0.01743863895535469,
      5.722867012023926,
      3.4125545024871826,
      3.123914957046509,
      3.064659357070923,
      3.231292486190796,
      3.019371271133423,
      0.13981662690639496,
      0.0,
      3.011216402053833,
      0.022644726559519768
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 15.652211345553399,
    "train_mean_l2": 11.55342114698887,
    "train_mean_l1": 4.098790381908417,
    "num_steps": 1000,
    "num_batches": 1000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251126-175135/feature_std_layer_12.html",
    "mean_std": 1.074162483215332,
    "max_std": 22.999488830566406
  }
}