{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "main.py sae.loss_option=2 sae.loss_module=option2_loss experiment.use_multi_contrast=true sae.alpha_concept.code=0.01 sae.alpha_concept.harm=0.01 sae.alpha_concept.struct=0.01 sae.guidance_method=mse sae.guidance_mse_pos_value=1.0 sae.guidance_mse_neg_value=0.0 sae.guidance_coeff=1.0 sae.use_l0=false",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 4,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0,
    "use_l0": false,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.01,
      "harm": 0.01,
      "struct": 0.01
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "mse",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      12
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "struct",
    "feature_idx": 2,
    "strength": 15.0
  },
  "prompt": "from Bio import SeqIO\nimport pandas as pd\nimport sys\nimport os\n\n# Put error and out into the log file\nsys.stderr = sys.stdout = open(snakemake.log[0], \"w\")\n\n###########################################################\n###########################################################\n\n# List that will contains all the contigs to filter\nall_contig_ids = []\n\n# Dataframe that contains all the informations about\noutput_df = pd.DataFrame(columns=[\"contig_id\", \"virsorter_cat\", \"deepvirfinder\"])\n\n# Get all the names from the virsorter keep2 list\nids_virsorter_keep2 = snakemake.input.ids_virsorter_keep2_checked\n\nwith open(ids_virsorter_keep2) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        all_contig_ids.append(rstrip_line)\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep2_checked\"\n\n# Get all the names from the virsorter keep1 list and remove redondant name\nids_virsorter_keep1 = snakemake.input.ids_virsorter_keep1\n\nwith open(ids_virsorter_keep1) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n            output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n            output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep1\"\n\n# Get all the names from the deepvirfinder list and remove redondant name\nids_virfinder = snakemake.input.ids_virfinder\n\nwith open(ids_virfinder) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"deepvirfinder\"] = \"Yes\"\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n# Fill the informations missing now the list of contigs we keep is set\ndict_map_virsorter = {}\n\nfiles_with_info = {\n    snakemake.input.ids_virsorter_keep2_suspicious: \"keep2_suspicious\",\n    snakemake.input.ids_virsorter_manual_check: \"to_manual_check\",\n    snakemake.input.ids_virsorter_discarded: \"discarded\",\n}\n\nfor file_ids in files_with_info:\n    with open(file_ids) as r_file:\n        r_file.readline()\n\n        for line in r_file:\n            rstrip_line = line.rstrip()\n            rstrip_line = rstrip_line.split(\"||\")[0]\n\n            if rstrip_line not in all_contig_ids:\n                dict_map_virsorter[rstrip_line] = files_with_info[file_ids]\n\n# Fill the dataframe\nlist_contig2add_virsorter_cat = list(dict_map_virsorter.keys())\noutput_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"virsorter_cat\"\n] = output_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"contig_id\"\n].map(\n    dict_map_virsorter\n)\n\noutput_df.fillna(\"No\", inplace=True)\n\n# Parse the fasta of the contig and create the new one\nfasta_contigs = snakemake.input.contigs\n\nwith open(snakemake.output.fasta, \"w\") as w_file:\n    with open(snakemake.output.translation_table, \"w\") as tsv_file:\n        tsv_file.write(\"old_contig_name\\tnew_contig_name\\n\")\n\n        parser = SeqIO.parse(fasta_contigs, \"fasta\")\n\n        for contig in parser:\n            if contig.id in all_contig_ids:\n                contig_id = f\"{snakemake.wildcards.sample}-{contig.id}\".replace(\n                    \"_\", \"-\"\n                )\n\n                tsv_file.write(f\"{contig.id}\\t{contig_id}\\n\")\n\n                contig.id = contig_id\n                contig.name = \"\"\n                contig.description = \"\"\n\n                SeqIO.write(contig, w_file, \"fasta\")\n\noutput_df.to_csv(snakemake.output.tsv, sep=\"\\t\", index=False)\n\n###########################################################\n###########################################################\n",
  "output": {
    "before": "from Bio import SeqIO\nimport pandas as pd\nimport sys\nimport os\n\n# Put error and out into the log file\nsys.stderr = sys.stdout = open(snakemake.log[0], \"w\")\n\n###########################################################\n###########################################################\n\n# List that will contains all the contigs to filter\nall_contig_ids = []\n\n# Dataframe that contains all the informations about\noutput_df = pd.DataFrame(columns=[\"contig_id\", \"virsorter_cat\", \"deepvirfinder\"])\n\n# Get all the names from the virsorter keep2 list\nids_virsorter_keep2 = snakemake.input.ids_virsorter_keep2_checked\n\nwith open(ids_virsorter_keep2) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        all_contig_ids.append(rstrip_line)\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep2_checked\"\n\n# Get all the names from the virsorter keep1 list and remove redondant name\nids_virsorter_keep1 = snakemake.input.ids_virsorter_keep1\n\nwith open(ids_virsorter_keep1) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n            output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n            output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep1\"\n\n# Get all the names from the deepvirfinder list and remove redondant name\nids_virfinder = snakemake.input.ids_virfinder\n\nwith open(ids_virfinder) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"deepvirfinder\"] = \"Yes\"\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n# Fill the informations missing now the list of contigs we keep is set\ndict_map_virsorter = {}\n\nfiles_with_info = {\n    snakemake.input.ids_virsorter_keep2_suspicious: \"keep2_suspicious\",\n    snakemake.input.ids_virsorter_manual_check: \"to_manual_check\",\n    snakemake.input.ids_virsorter_discarded: \"discarded\",\n}\n\nfor file_ids in files_with_info:\n    with open(file_ids) as r_file:\n        r_file.readline()\n\n        for line in r_file:\n            rstrip_line = line.rstrip()\n            rstrip_line = rstrip_line.split(\"||\")[0]\n\n            if rstrip_line not in all_contig_ids:\n                dict_map_virsorter[rstrip_line] = files_with_info[file_ids]\n\n# Fill the dataframe\nlist_contig2add_virsorter_cat = list(dict_map_virsorter.keys())\noutput_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"virsorter_cat\"\n] = output_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"contig_id\"\n].map(\n    dict_map_virsorter\n)\n\noutput_df.fillna(\"No\", inplace=True)\n\n# Parse the fasta of the contig and create the new one\nfasta_contigs = snakemake.input.contigs\n\nwith open(snakemake.output.fasta, \"w\") as w_file:\n    with open(snakemake.output.translation_table, \"w\") as tsv_file:\n        tsv_file.write(\"old_contig_name\\tnew_contig_name\\n\")\n\n        parser = SeqIO.parse(fasta_contigs, \"fasta\")\n\n        for contig in parser:\n            if contig.id in all_contig_ids:\n                contig_id = f\"{snakemake.wildcards.sample}-{contig.id}\".replace(\n                    \"_\", \"-\"\n                )\n\n                tsv_file.write(f\"{contig.id}\\t{contig_id}\\n\")\n\n                contig.id = contig_id\n                contig.name = \"\"\n                contig.description = \"\"\n\n                SeqIO.write(contig, w_file, \"fasta\")\n\noutput_df.to_csv(snakemake.output.tsv, sep=\"\\t\", index=False)\n\n###########################################################\n###########################################################\n```\n\nThis script does the following:\n\n1. **Reads in data from input files:** It reads the IDs from various input files (`ids_virsorter_keep2_checked`, `ids_virsorter_keep1`, `ids_",
    "after": "from Bio import SeqIO\nimport pandas as pd\nimport sys\nimport os\n\n# Put error and out into the log file\nsys.stderr = sys.stdout = open(snakemake.log[0], \"w\")\n\n###########################################################\n###########################################################\n\n# List that will contains all the contigs to filter\nall_contig_ids = []\n\n# Dataframe that contains all the informations about\noutput_df = pd.DataFrame(columns=[\"contig_id\", \"virsorter_cat\", \"deepvirfinder\"])\n\n# Get all the names from the virsorter keep2 list\nids_virsorter_keep2 = snakemake.input.ids_virsorter_keep2_checked\n\nwith open(ids_virsorter_keep2) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        all_contig_ids.append(rstrip_line)\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep2_checked\"\n\n# Get all the names from the virsorter keep1 list and remove redondant name\nids_virsorter_keep1 = snakemake.input.ids_virsorter_keep1\n\nwith open(ids_virsorter_keep1) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n        rstrip_line = rstrip_line.split(\"||\")[0]\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n            output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n            output_df.at[rstrip_line, \"virsorter_cat\"] = \"keep1\"\n\n# Get all the names from the deepvirfinder list and remove redondant name\nids_virfinder = snakemake.input.ids_virfinder\n\nwith open(ids_virfinder) as r_file:\n    r_file.readline()\n\n    for line in r_file:\n        rstrip_line = line.rstrip()\n\n        output_df.at[rstrip_line, \"contig_id\"] = rstrip_line\n        output_df.at[rstrip_line, \"deepvirfinder\"] = \"Yes\"\n\n        if rstrip_line not in all_contig_ids:\n            all_contig_ids.append(rstrip_line)\n\n# Fill the informations missing now the list of contigs we keep is set\ndict_map_virsorter = {}\n\nfiles_with_info = {\n    snakemake.input.ids_virsorter_keep2_suspicious: \"keep2_suspicious\",\n    snakemake.input.ids_virsorter_manual_check: \"to_manual_check\",\n    snakemake.input.ids_virsorter_discarded: \"discarded\",\n}\n\nfor file_ids in files_with_info:\n    with open(file_ids) as r_file:\n        r_file.readline()\n\n        for line in r_file:\n            rstrip_line = line.rstrip()\n            rstrip_line = rstrip_line.split(\"||\")[0]\n\n            if rstrip_line not in all_contig_ids:\n                dict_map_virsorter[rstrip_line] = files_with_info[file_ids]\n\n# Fill the dataframe\nlist_contig2add_virsorter_cat = list(dict_map_virsorter.keys())\noutput_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"virsorter_cat\"\n] = output_df.loc[\n    output_df.contig_id.isin(list_contig2add_virsorter_cat), \"contig_id\"\n].map(\n    dict_map_virsorter\n)\n\noutput_df.fillna(\"No\", inplace=True)\n\n# Parse the fasta of the contig and create the new one\nfasta_contigs = snakemake.input.contigs\n\nwith open(snakemake.output.fasta, \"w\") as w_file:\n    with open(snakemake.output.translation_table, \"w\") as tsv_file:\n        tsv_file.write(\"old_contig_name\\tnew_contig_name\\n\")\n\n        parser = SeqIO.parse(fasta_contigs, \"fasta\")\n\n        for contig in parser:\n            if contig.id in all_contig_ids:\n                contig_id = f\"{snakemake.wildcards.sample}-{contig.id}\".replace(\n                    \"_\", \"-\"\n                )\n\n                tsv_file.write(f\"{contig.id}\\t{contig_id}\\n\")\n\n                contig.id = contig_id\n                contig.name = \"\"\n                contig.description = \"\"\n\n                SeqIO.write(contig, w_file, \"fasta\")\n\noutput_df.to_csv(snakemake.output.tsv, sep=\"\\t\", index=False)\n\n###########################################################\n###########################################################\n# Filter the contigs\n#\n# This function filters the contigs based on the virsorter_cat, deepvirfinder, and contig_id\n#\n# @param:\n#   None\n#\n# @return:"
  },
  "feature_stats": {
    "indices": [
      2,
      0,
      4645,
      6994,
      5276,
      7186,
      526,
      5761,
      3073,
      1026,
      4405
    ],
    "f_before": [
      0.0,
      0.38770246505737305,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      0.38770246505737305,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_before": [
      0.22214142978191376,
      0.0,
      0.04723668843507767,
      0.0,
      0.0,
      0.041224896907806396,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.22214142978191376,
      0.0,
      0.04723668843507767,
      0.0,
      0.0,
      0.041224896907806396,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 8.54353929513693,
    "train_mean_l2": 6.013987733893097,
    "train_mean_l1": 2.5168445214927195,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251128-010452/feature_std_layer_12.html",
    "mean_std": 1.0416896343231201,
    "max_std": 30.567893981933594
  }
}