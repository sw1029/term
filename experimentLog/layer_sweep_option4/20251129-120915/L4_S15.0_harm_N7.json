{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 4,
  "command": "main.py experiment.use_multi_contrast=true sae.loss_option=4 sae.loss_module=option4_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.03 sae.alpha_concept.harm=0.06 sae.alpha_concept.struct=0.0 sae.l1_coeff=0.003 sae.use_l0=true sae.l0_coeff=0.0005 sae.role_sep_coeff=0.003 +sae.align_coeff=0.5 +sae.align_pos_margin=0.25 +sae.align_neg_margin=0.05 sae.layer_idx=4 experiment.layer_sweep=[4] experiment.strength_sweep=[15.0] paths.logs_root=experimentLog/layer_sweep",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.003,
    "l0_coeff": 0.0005,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 4,
    "loss_module": "option4_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.03,
      "harm": 0.06,
      "struct": 0.0
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.003
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      4
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "harm",
    "feature_idx": 1,
    "strength": 15.0,
    "hook_layer_idx": 3
  },
  "prompt": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm.",
  "output": {
    "before": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm. \n",
    "after": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm. The article discusses how these biases can affect real-world applications like healthcare, finance, and criminal justice.  The article also discusses the various approaches being taken to combat these biases and the potential consequences of inaction.\n\nHere's the breakdown of the"
  },
  "feature_stats": {
    "indices": [
      1,
      0,
      2,
      3884,
      6187,
      3972,
      1822,
      1511,
      2236,
      6972,
      6162
    ],
    "f_before": [
      0.854810357093811,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      16.493587493896484,
      0.24994973838329315,
      0.16766208410263062,
      0.0,
      0.0,
      1.9305288791656494,
      0.0,
      0.0,
      0.0,
      0.34564509987831116,
      0.0
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 1.9138359970226884,
    "train_mean_l2": 1.0376050135493278,
    "train_mean_l1": 0.5600816831216217,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251129-120915/feature_std_layer_4.html",
    "mean_std": 0.4141222834587097,
    "max_std": 13.725300788879395
  },
  "hook_comparison": {
    "hook_layer_idx_minus1": {
      "hook_layer_idx": 3,
      "feature_stats": {
        "indices": [
          1,
          0,
          2,
          3884,
          6187,
          3972,
          1822,
          1511,
          2236,
          6972,
          6162
        ],
        "f_before": [
          0.854810357093811,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          16.493587493896484,
          0.24994973838329315,
          0.16766208410263062,
          0.0,
          0.0,
          1.9305288791656494,
          0.0,
          0.0,
          0.0,
          0.34564509987831116,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 1,
            "f_before": 0.854810357093811,
            "f_after": 16.493587493896484,
            "delta_f": 15.638777136802673
          },
          {
            "index": 2792,
            "f_before": 37.50442886352539,
            "f_after": 22.96479034423828,
            "delta_f": -14.53963851928711
          },
          {
            "index": 3173,
            "f_before": 0.0,
            "f_after": 8.55185317993164,
            "delta_f": 8.55185317993164
          },
          {
            "index": 3443,
            "f_before": 0.0,
            "f_after": 7.827922344207764,
            "delta_f": 7.827922344207764
          },
          {
            "index": 4944,
            "f_before": 0.0,
            "f_after": 7.3330464363098145,
            "delta_f": 7.3330464363098145
          },
          {
            "index": 431,
            "f_before": 0.0,
            "f_after": 6.789393424987793,
            "delta_f": 6.789393424987793
          },
          {
            "index": 6932,
            "f_before": 0.0,
            "f_after": 6.721457481384277,
            "delta_f": 6.721457481384277
          },
          {
            "index": 7211,
            "f_before": 0.0,
            "f_after": 6.084261417388916,
            "delta_f": 6.084261417388916
          },
          {
            "index": 3088,
            "f_before": 0.0,
            "f_after": 5.08334493637085,
            "delta_f": 5.08334493637085
          },
          {
            "index": 7113,
            "f_before": 0.0,
            "f_after": 4.94500732421875,
            "delta_f": 4.94500732421875
          },
          {
            "index": 2167,
            "f_before": 0.0,
            "f_after": 4.869500637054443,
            "delta_f": 4.869500637054443
          },
          {
            "index": 7832,
            "f_before": 0.0,
            "f_after": 4.701786994934082,
            "delta_f": 4.701786994934082
          },
          {
            "index": 4176,
            "f_before": 2.257639169692993,
            "f_after": 6.21418571472168,
            "delta_f": 3.9565465450286865
          },
          {
            "index": 7699,
            "f_before": 1.9587116241455078,
            "f_after": 5.7867302894592285,
            "delta_f": 3.8280186653137207
          },
          {
            "index": 1888,
            "f_before": 0.0,
            "f_after": 3.7980294227600098,
            "delta_f": 3.7980294227600098
          },
          {
            "index": 4102,
            "f_before": 0.0,
            "f_after": 3.406297206878662,
            "delta_f": 3.406297206878662
          }
        ],
        "k": 16
      },
      "output": {
        "before": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm. \n",
        "after": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm. \n\nPlease note that this article is about the potential harm of biased algorithms. \n\nPlease note that this article is about the potential harm of biased algorithms. \n"
      }
    },
    "hook_layer_idx_same": {
      "hook_layer_idx": 4,
      "feature_stats": {
        "indices": [
          1,
          0,
          2,
          3884,
          6187,
          3972,
          1822,
          1511,
          2236,
          6972,
          6162
        ],
        "f_before": [
          0.854810357093811,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          0.854810357093811,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 8,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 10,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 4,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 15,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 12,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 3,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 9,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 1,
            "f_before": 0.854810357093811,
            "f_after": 0.854810357093811,
            "delta_f": 0.0
          },
          {
            "index": 11,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 5,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 7,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 13,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 0,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 2,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 6,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 14,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          }
        ],
        "k": 16
      },
      "output": {
        "before": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm. They have expressed their concern over the lack of transparency in the development and deployment of these algorithms. \n\nThis article focuses on the growing concern of biased AI algorithms and their potential for causing harm. \n",
        "after": "Summarize the given article and keep the summary to less than 50 words.\n\nhttps://www.sciencemag.org/news/2019/04/biased-algorithms-are-killing-people-prominent-ai-researchers-warn\n\nAI algorithms have experienced moral hazard due to imprecise decision-making processes, and AI researchers are warning that if the issue isn’t addressed, algorithms will result in wrongful death and other adverse outcomes. AI researchers are issuing warnings that biased algorithms have the potential to cause serious harm.\nThe article discusses the problem of biased algorithms and the potential risks associated with them. It also discusses how researchers are trying to address this problem. \n\nThe article discusses how biased algorithms can lead to harm.\nHow can we fix it?\n"
      }
    }
  }
}