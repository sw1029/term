{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "python main.py experiment.use_multi_contrast=true sae.loss_option=2 sae.loss_module=option2_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.0 sae.alpha_concept.harm=0.055 sae.alpha_concept.struct=0.0 sae.use_l0=true sae.l0_coeff=0.0003941940089286674 sae.role_sep_coeff=0.001",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0003941940089286674,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.0,
      "harm": 0.055,
      "struct": 0.0
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.001
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      12
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "code",
    "feature_idx": 0,
    "strength": 15.0
  },
  "prompt": "\"\"\"\nCopyright (c) 2004-Present VMware, Inc. or its affiliates.\n\nThis program and the accompanying materials are made available under\nthe terms of the under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\"\"\"\n\nimport pg\nimport os\nimport subprocess\nimport re\nimport multiprocessing\nimport tempfile\nimport time\nimport sys\nimport socket\nfrom optparse import OptionParser\nimport traceback\n\ndef is_digit(n):\n    try:\n        int(n)\n        return True\n    except ValueError:\n        return  False\n\ndef null_notice_receiver(notice):\n    '''\n        Tests ignore notice messages when analyzing results,\n        so silently drop notices from the pg.connection\n    '''\n    return\n\n\nclass SQLIsolationExecutor(object):\n    def __init__(self, dbname=''):\n        self.processes = {}\n        # The re.S flag makes the \".\" in the regex match newlines.\n        # When matched against a command in process_command(), all\n        # lines in the command are matched and sent as SQL query.\n        self.command_pattern = re.compile(r\"^(-?\\d+|[*])([&\\\\<\\\\>USq]*?)\\:(.*)\", re.S)\n        if dbname:\n            self.dbname = dbname\n        else:\n            self.dbname = os.environ.get('PGDATABASE')\n\n    class SQLConnection(object):\n        def __init__(self, out_file, name, mode, dbname):\n            self.name = name\n            self.mode = mode\n            self.out_file = out_file\n            self.dbname = dbname\n\n            parent_conn, child_conn = multiprocessing.Pipe(True)\n            self.p = multiprocessing.Process(target=self.session_process, args=(child_conn,))   \n            self.pipe = parent_conn\n            self.has_open = False\n            self.p.start()\n\n            # Close \"our\" copy of the child's handle, so that if the child dies,\n            # recv() on the pipe will fail.\n            child_conn.close();\n\n            self.out_file = out_file\n\n        def session_process(self, pipe):\n            sp = SQLIsolationExecutor.SQLSessionProcess(self.name, \n                self.mode, pipe, self.dbname)\n            sp.do()\n\n        def query(self, command):\n            print(file=self.out_file)\n            self.out_file.flush()\n            if len(command.strip()) == 0:\n                return\n            if self.has_open:\n                raise Exception(\"Cannot query command while waiting for results\")\n\n            self.pipe.send((command, False))\n            r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n\n        def fork(self, command, blocking):\n            print(\"  <waiting ...>\", file=self.out_file)\n            self.pipe.send((command, True))\n\n            if blocking:\n                time.sleep(0.5)\n                if self.pipe.poll(0):\n                    p = self.pipe.recv()\n                    raise Exception(\"Forked command is not blocking; got output: %s\" % p.strip())\n            self.has_open = True\n\n        def join(self):\n            r = None\n            print(\"  <... completed>\", file=self.out_file)\n            if self.has_open:\n                r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n            self.has_open = False\n\n        def stop(self):\n            self.pipe.send((\"\", False))\n            self.p.join()\n            if self.has_open:\n                raise Exception(\"Should not finish test case while waiting for results\")\n\n        def quit(self):\n            print(\" ... <quitting>\", file=self.out_file)\n            self.stop()\n        \n        def terminate(self):\n            self.pipe.close()\n            self.p.terminate()\n\n    class SQLSessionProcess(object):\n        def __init__(self, name, mode, pipe, dbname):\n            \"\"\"\n                Constructor\n            \"\"\"\n            self.name = name\n            self.mode = mode\n            self.pipe = pipe\n            self.dbname = dbname\n            if self.mode == \"utility\":\n                (hostname, port) = self.get_hostname_port(name, 'p')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port,\n                                          given_opt=\"-c gp_role=utility\")\n            elif self.mode == \"standby\":\n                # Connect to standby even when it's role is recorded\n                # as mirror.  This is useful for scenarios where a\n                # test needs to promote a standby without using\n                # gpactivatestandby.\n                (hostname, port) = self.get_hostname_port(name, 'm')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port)\n            else:\n                self.con = self.connectdb(self.dbname)\n\n        def connectdb(self, given_dbname, given_host = None, given_port = None, given_opt = None):\n            con = None\n            retry = 1000\n            while retry:\n                try:\n                    if (given_port is None):\n                        con = pg.connect(host= given_host,\n                                          opt= given_opt,\n                                          dbname= given_dbname)\n                    else:\n                        con = pg.connect(host= given_host,\n                                                  port= given_port,\n                                                  opt= given_opt,\n                                                  dbname= given_dbname)\n                    break\n                except Exception as e:\n                    if ((\"the database system is starting up\" in str(e) or\n                         \"the database system is in recovery mode\" in str(e)) and\n                        retry > 1):\n                        retry -= 1\n                        time.sleep(0.1)\n                    else:\n                        raise\n            con.set_notice_receiver(null_notice_receiver)\n            return con\n\n        def get_hostname_port(self, contentid, role):\n            \"\"\"\n                Gets the port number/hostname combination of the\n                contentid and role\n            \"\"\"\n            query = (\"SELECT hostname, port FROM gp_segment_configuration WHERE\"\n                     \" content = %s AND role = '%s'\") % (contentid, role)\n            con = self.connectdb(self.dbname, given_opt=\"-c gp_role=utility\")\n            r = con.query(query).getresult()\n            con.close()\n            if len(r) == 0:\n                raise Exception(\"Invalid content %s\" % contentid)\n            if r[0][0] == socket.gethostname():\n                return (None, int(r[0][1]))\n            return (r[0][0], int(r[0][1]))\n\n        def printout_result(self, r):\n            \"\"\"\n            Print out a pygresql result set (a Query object, after the query\n            has been executed), in a format that imitates the default\n            formatting of psql. This isn't a perfect imitation: we left-justify\n            all the fields and headers, whereas psql centers the header, and\n            right-justifies numeric fields. But this is close enough, to make\n            gpdiff.pl recognize the result sets as such. (We used to just call\n            str(r), and let PyGreSQL do the formatting. But even though\n            PyGreSQL's default formatting is close to psql's, it's not close\n            enough.)\n            \"\"\"\n            widths = []\n\n            # Figure out the widths of each column.\n            fields = r.listfields()\n            for f in fields:\n                widths.append(len(str(f)))\n\n            rset = r.getresult()\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if col is None:\n                        col = \"\"\n                    widths[colno] = max(widths[colno], len(str(col)))\n                    colno = colno + 1\n\n            # Start printing. Header first.\n            result = \"\"\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"|\"\n                result += \" \" + f.ljust(widths[colno]) + \" \"\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the bar (\"----+----\")\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"+\"\n                result += \"\".ljust(widths[colno] + 2, \"-\")\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the result set itself\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if colno > 0:\n                        result += \"|\"\n                    if isinstance(col, float):\n                        col = format(col, \"g\")\n                    elif isinstance(col, bool):\n                        if col:\n                            col = 't'\n                        else:\n                            col = 'f'\n                    elif col is None:\n                        col = \"\"\n                    result += \" \" + str(col).ljust(widths[colno]) + \" \"\n                    colno = colno + 1\n                result += \"\\n\"\n\n            # Finally, the row count\n            if len(rset) == 1:\n                result += \"(1 row)\\n\"\n            else:\n                result += \"(\" + str(len(rset)) + \" rows)\\n\"\n\n            return result\n\n        def execute_command(self, command):\n            \"\"\"\n                Executes a given command\n            \"\"\"\n            try:\n                r = self.con.query(command)\n                if r is not None:\n                    if type(r) == str:\n                        # INSERT, UPDATE, etc that returns row count but not result set\n                        echo_content = command[:-1].partition(\" \")[0].upper()\n                        return \"%s %s\" % (echo_content, r)\n                    else:\n                        # SELECT or similar, print the result set without the command (type pg.Query)\n                        return self.printout_result(r)\n                else:\n                    # CREATE or other DDL without a result set or count\n                    echo_content = command[:-1].partition(\" \")[0].upper()\n                    return echo_content\n            except Exception as e:\n                return str(e)\n\n        def do(self):\n            \"\"\"\n                Process loop.\n                Ends when the command None is received\n            \"\"\"\n            (c, wait) = self.pipe.recv()\n            while c:\n                if wait:\n                    time.sleep(0.1)\n                r = self.execute_command(c)\n                self.pipe.send(r)\n                r = None\n\n                (c, wait) = self.pipe.recv()\n\n\n    def get_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n            Gets or creates the process by the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            if not dbname:\n                dbname = self.dbname\n            self.processes[(name, mode)] = SQLIsolationExecutor.SQLConnection(out_file, name, mode, dbname)\n        return self.processes[(name, mode)]\n\n    def quit_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n        Quits a process with the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            raise Exception(\"Sessions not started cannot be quit\")\n\n        self.processes[(name, mode)].quit()\n        del self.processes[(name, mode)]\n\n    def get_all_primary_contentids(self, dbname):\n        \"\"\"\n        Retrieves all primary content IDs (including the master). Intended for\n        use by *U queries.\n        \"\"\"\n        if not dbname:\n            dbname = self.dbname\n\n        con = pg.connect(dbname=dbname)\n        result = con.query(\"SELECT content FROM gp_segment_configuration WHERE role = 'p'\").getresult()\n        if len(result) == 0:\n            raise Exception(\"Invalid gp_segment_configuration contents\")\n        return [int(content[0]) for content in result]\n\n    def process_command(self, command, output_file):\n        \"\"\"\n            Processes the given command.\n            The command at this point still includes the isolation behavior\n            flags, e.g. which session to use.\n        \"\"\"\n        process_name = \"\"\n        sql = command\n        flag = \"\"\n        con_mode = \"\"\n        dbname = \"\"\n        m = self.command_pattern.match(command)\n        if m:\n            process_name = m.groups()[0]\n            flag = m.groups()[1]\n            if flag and flag[0] == \"U\":\n                con_mode = \"utility\"\n            elif flag and flag[0] == \"S\":\n                if len(flag) > 1:\n                    flag = flag[1:]\n                con_mode = \"standby\"\n            sql = m.groups()[2]\n            sql = sql.lstrip()\n            # If db_name is specifed , it should be of the following syntax:\n            # 1:@db_name <db_name>: <sql>\n            if sql.startswith('@db_name'):\n                sql_parts = sql.split(':', 2)\n                if not len(sql_parts) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not sql_parts[0].startswith('@db_name'):\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not len(sql_parts[0].split()) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                dbname = sql_parts[0].split()[1].strip()\n                if not dbname:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                sql = sql_parts[1]\n        if not flag:\n            if sql.startswith('!'):\n                sql = sql[1:]\n\n                # Check for execution mode. E.g.\n                #     !\\retcode path/to/executable --option1 --option2 ...\n                #\n                # At the moment, we only recognize the \\retcode mode, which\n                # ignores all program output in the diff (it's still printed)\n                # and adds the return code.\n                mode = None\n                if sql.startswith('\\\\'):\n                    mode, sql = sql.split(None, 1)\n                    if mode != '\\\\retcode':\n                        raise Exception('Invalid execution mode: {}'.format(mode))\n\n                cmd_output = subprocess.Popen(sql.strip(), stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)\n                stdout, _ = cmd_output.communicate()\n                print(file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- start_ignore', file=output_file)\n                print(stdout.decode(), file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- end_ignore', file=output_file)\n                    print('(exited with code {})'.format(cmd_output.returncode), file=output_file)\n            else:\n                self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \">\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), False)\n        elif flag == \"<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"q\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"U\":\n            if process_name == '*':\n                process_names = [str(content) for content in self.get_all_primary_contentids(dbname)]\n            else:\n                process_names = [process_name]\n\n            for name in process_names:\n                self.get_process(output_file, name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"U&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \"U<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"Uq\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"S\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        else:\n            raise Exception(\"Invalid isolation flag\")\n\n    def process_isolation_file(self, sql_file, output_file):\n        \"\"\"\n            Processes the given sql file and writes the output\n            to output file\n        \"\"\"\n        try:\n            command = \"\"\n            newline = False\n            for line in sql_file:\n                # this logic replicates the python2 behavior of a trailing comma at the end of print\n                # i.e. ''' print >>output_file, line.strip(), '''\n                print((\" \" if command and not newline else \"\") + line.strip(), end=\"\", file=output_file)\n                newline = False\n                if line[0] == \"!\":\n                    command_part = line # shell commands can use -- for multichar options like --include\n                elif re.match(r\";.*--\", line) or re.match(r\"^--\", line):\n                    command_part = line.partition(\"--\")[0] # remove comment from line\n                else:\n                    command_part = line\n                if command_part == \"\" or command_part == \"\\n\":\n                    print(file=output_file) \n                    newline = True\n                elif re.match(r\".*;\\s*$\", command_part) or re.match(r\"^\\d+[q\\\\<]:$\", line) or re.match(r\"^-?\\d+[SU][q\\\\<]:$\", line):\n                    command += command_part\n                    try:\n                        self.process_command(command, output_file)\n                    except Exception as e:\n                        print(\"FAILED: \", e, file=output_file)\n                    command = \"\"\n                else:\n                    command += command_part\n\n            for process in list(self.processes.values()):\n                process.stop()\n        except:\n            for process in list(self.processes.values()):\n                process.terminate()\n            raise\n        finally:\n            for process in list(self.processes.values()):\n                process.terminate()\n\nclass SQLIsolationTestCase:\n    \"\"\"\n        The isolation test case allows a fine grained control of interleaved\n        executing transactions. This is mainly used to test isolation behavior.\n\n        [<#>[flag]:] <sql> | ! <shell scripts or command>\n        #: either an integer indicating a unique session, or a content-id if\n           followed by U (for utility-mode connections). In 'U' mode, the\n           content-id can alternatively be an asterisk '*' to perform a\n           utility-mode query on the master and all primaries.\n        flag:\n            &: expect blocking behavior\n            >: running in background without blocking\n            <: join an existing session\n            q: quit the given session\n\n            U: connect in utility mode to primary contentid from gp_segment_configuration\n            U&: expect blocking behavior in utility mode (does not currently support an asterisk target)\n            U<: join an existing utility mode session (does not currently support an asterisk target)\n\n        An example is:\n\n        Execute BEGIN in transaction 1\n        Execute BEGIN in transaction 2\n        Execute INSERT in transaction 2\n        Execute SELECT in transaction 1\n        Execute COMMIT in transaction 2\n        Execute SELECT in transaction 1\n\n        The isolation tests are specified identical to sql-scripts in normal\n        SQLTestCases. However, it is possible to prefix a SQL line with\n        an tranaction identifier followed by a colon (\":\").\n        The above example would be defined by\n        1: BEGIN;\n        2: BEGIN;\n        2: INSERT INTO a VALUES (1);\n        1: SELECT * FROM a;\n        2: COMMIT;\n        1: SELECT * FROM a;\n\n        Blocking behavior can be tested by forking and joining.\n        1: BEGIN;\n        2: BEGIN;\n        1: DELETE FROM foo WHERE a = 4;\n        2&: DELETE FROM foo WHERE a = 4;\n        1: COMMIT;\n        2<:\n        2: COMMIT;\n\n        2& forks the command. It is executed in the background. If the\n        command is NOT blocking at this point, it is considered an error.\n        2< joins the background command and outputs the result of the   \n        command execution.\n\n        Session ids should be smaller than 1024.\n\n        2U: Executes a utility command connected to port 40000. \n\n        One difference to SQLTestCase is the output of INSERT.\n        SQLTestCase would output \"INSERT 0 1\" if one tuple is inserted.\n        SQLIsolationTestCase would output \"INSERT 1\". As the\n        SQLIsolationTestCase needs to have a more fine-grained control\n        over the execution order than possible with PSQL, it uses\n        the pygresql python library instead.\n\n        Connecting to a specific database:\n        1. If you specify a db_name metadata in the sql file, connect to that database in all open sessions.\n        2. If you want a specific session to be connected to a specific database , specify the sql as follows:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        etc\n\n        Here session 1 will be connected to testdb and session 2 will be connected to test2db. You can specify @db_name only at the beginning of the session. For eg:, following would error out:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: @db_name testdb: <sql>\n        2: <sql>\n        etc\n\n        Quitting sessions:\n        By default, all opened sessions will be stopped only at the end of the sql file execution. If you want to explicitly quit a session\n        in the middle of the test execution, you can specify a flag 'q' with the session identifier. For eg:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        1q:\n        2: <sql>\n        3: <sql>\n        2q:\n        3: <sql>\n        2: @db_name test: <sql>\n\n        1q:  ---> Will quit the session established with testdb.\n        2q:  ---> Will quit the session established with test2db.\n\n        The subsequent 2: @db_name test: <sql> will open a new session with the database test and execute the sql against that session.\n\n        Catalog Modification:\n\n        Some tests are easier to write if it's possible to modify a system\n        catalog across the *entire* cluster. To perform a utility-mode query on\n        all segments and the master, you can use *U commands:\n\n        *U: SET allow_system_table_mods = true;\n        *U: UPDATE pg_catalog.<table> SET <column> = <value> WHERE <cond>;\n\n        Since the number of query results returned by a *U command depends on\n        the developer's cluster configuration, it can be useful to wrap them in\n        a start_/end_ignore block. (Unfortunately, this also hides legitimate\n        failures; a better long-term solution is needed.)\n\n        Block/join flags are not currently supported with *U.\n\n        Line continuation:\n        If a line is not ended by a semicolon ';' which is followed by 0 or more spaces, the line will be combined with next line and\n        sent together as a single statement.\n\n        e.g.: Send to the server separately:\n        1: SELECT * FROM t1; -> send \"SELECT * FROM t1;\"\n        SELECT * FROM t2; -> send \"SELECT * FROM t2;\"\n\n        e.g.: Send to the server once:\n        1: SELECT * FROM\n        t1; SELECT * FROM t2; -> \"send SELECT * FROM t1; SELECT * FROM t2;\"\n\n        ATTENTION:\n        Send multi SQL statements once:\n        Multi SQL statements can be sent at once, but there are some known issues. Generally only the last query result will be printed.\n        But due to the difficulties of dealing with semicolons insides quotes, we always echo the first SQL command instead of the last\n        one if query() returns None. This created some strange issues like:\n\n        CREATE TABLE t1 (a INT); INSERT INTO t1 SELECT generate_series(1,1000);\n        CREATE 1000 (Should be INSERT 1000, but here the CREATE is taken due to the limitation)\n    \"\"\"\n\n    def run_sql_file(self, sql_file, out_file = None, out_dir = None, optimizer = None):\n        \"\"\"\n        Given a sql file and an ans file, this adds the specified gucs (self.gucs) to the sql file , runs the sql\n        against the test case database (self.db_name) and verifies the output with the ans file.\n        If an 'init_file' exists in the same location as the sql_file, this will be used\n        while doing gpdiff.\n        \"\"\"\n        # Add gucs to the test sql and form the actual sql file to be run\n        if not out_dir:\n            out_dir = self.get_out_dir()\n            \n        if not os.path.exists(out_dir):\n            TINCSystem.make_dirs(out_dir, ignore_exists_error = True)\n            \n        if optimizer is None:\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file))\n        else:\n            # sql file will be <basename>_opt.sql or <basename>_planner.sql based on optimizer\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file).replace('.sql', '_%s.sql' %self._optimizer_suffix(optimizer)))\n            \n        self._add_gucs_to_sql_file(sql_file, gucs_sql_file, optimizer)\n        self.test_artifacts.append(gucs_sql_file)\n\n        \n        if not out_file:\n            if optimizer is None:\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '.out'))\n            else:\n                # out file will be *_opt.out or *_planner.out based on optimizer\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '_%s.out' %self._optimizer_suffix(optimizer)))\n        \n        self.test_artifacts.append(out_file)\n        executor = SQLIsolationExecutor(dbname=self.db_name)\n        with open(out_file, \"w\") as f:\n            executor.process_isolation_file(open(sql_file), f)\n            f.flush()   \n        \n        if out_file[-2:] == '.t':\n            out_file = out_file[:-2]\n\n        return out_file\n\nif __name__ == \"__main__\":\n\n    parser = OptionParser()\n    parser.add_option(\"--dbname\", dest=\"dbname\",\n                      help=\"connect to database DBNAME\", metavar=\"DBNAME\")\n    (options, args) = parser.parse_args()\n\n    executor = SQLIsolationExecutor(dbname=options.dbname)\n\n    executor.process_isolation_file(sys.stdin, sys.stdout)\n",
  "output": {
    "before": "\"\"\"\nCopyright (c) 2004-Present VMware, Inc. or its affiliates.\n\nThis program and the accompanying materials are made available under\nthe terms of the under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\"\"\"\n\nimport pg\nimport os\nimport subprocess\nimport re\nimport multiprocessing\nimport tempfile\nimport time\nimport sys\nimport socket\nfrom optparse import OptionParser\nimport traceback\n\ndef is_digit(n):\n    try:\n        int(n)\n        return True\n    except ValueError:\n        return  False\n\ndef null_notice_receiver(notice):\n    '''\n        Tests ignore notice messages when analyzing results,\n        so silently drop notices from the pg.connection\n    '''\n    return\n\n\nclass SQLIsolationExecutor(object):\n    def __init__(self, dbname=''):\n        self.processes = {}\n        # The re.S flag makes the \".\" in the regex match newlines.\n        # When matched against a command in process_command(), all\n        # lines in the command are matched and sent as SQL query.\n        self.command_pattern = re.compile(r\"^(-?\\d+|[*])([&\\\\<\\\\>USq]*?)\\:(.*)\", re.S)\n        if dbname:\n            self.dbname = dbname\n        else:\n            self.dbname = os.environ.get('PGDATABASE')\n\n    class SQLConnection(object):\n        def __init__(self, out_file, name, mode, dbname):\n            self.name = name\n            self.mode = mode\n            self.out_file = out_file\n            self.dbname = dbname\n\n            parent_conn, child_conn = multiprocessing.Pipe(True)\n            self.p = multiprocessing.Process(target=self.session_process, args=(child_conn,))   \n            self.pipe = parent_conn\n            self.has_open = False\n            self.p.start()\n\n            # Close \"our\" copy of the child's handle, so that if the child dies,\n            # recv() on the pipe will fail.\n            child_conn.close();\n\n            self.out_file = out_file\n\n        def session_process(self, pipe):\n            sp = SQLIsolationExecutor.SQLSessionProcess(self.name, \n                self.mode, pipe, self.dbname)\n            sp.do()\n\n        def query(self, command):\n            print(file=self.out_file)\n            self.out_file.flush()\n            if len(command.strip()) == 0:\n                return\n            if self.has_open:\n                raise Exception(\"Cannot query command while waiting for results\")\n\n            self.pipe.send((command, False))\n            r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n\n        def fork(self, command, blocking):\n            print(\"  <waiting ...>\", file=self.out_file)\n            self.pipe.send((command, True))\n\n            if blocking:\n                time.sleep(0.5)\n                if self.pipe.poll(0):\n                    p = self.pipe.recv()\n                    raise Exception(\"Forked command is not blocking; got output: %s\" % p.strip())\n            self.has_open = True\n\n        def join(self):\n            r = None\n            print(\"  <... completed>\", file=self.out_file)\n            if self.has_open:\n                r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n            self.has_open = False\n\n        def stop(self):\n            self.pipe.send((\"\", False))\n            self.p.join()\n            if self.has_open:\n                raise Exception(\"Should not finish test case while waiting for results\")\n\n        def quit(self):\n            print(\" ... <quitting>\", file=self.out_file)\n            self.stop()\n        \n        def terminate(self):\n            self.pipe.close()\n            self.p.terminate()\n\n    class SQLSessionProcess(object):\n        def __init__(self, name, mode, pipe, dbname):\n            \"\"\"\n                Constructor\n            \"\"\"\n            self.name = name\n            self.mode = mode\n            self.pipe = pipe\n            self.dbname = dbname\n            if self.mode == \"utility\":\n                (hostname, port) = self.get_hostname_port(name, 'p')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port,\n                                          given_opt=\"-c gp_role=utility\")\n            elif self.mode == \"standby\":\n                # Connect to standby even when it's role is recorded\n                # as mirror.  This is useful for scenarios where a\n                # test needs to promote a standby without using\n                # gpactivatestandby.\n                (hostname, port) = self.get_hostname_port(name, 'm')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port)\n            else:\n                self.con = self.connectdb(self.dbname)\n\n        def connectdb(self, given_dbname, given_host = None, given_port = None, given_opt = None):\n            con = None\n            retry = 1000\n            while retry:\n                try:\n                    if (given_port is None):\n                        con = pg.connect(host= given_host,\n                                          opt= given_opt,\n                                          dbname= given_dbname)\n                    else:\n                        con = pg.connect(host= given_host,\n                                                  port= given_port,\n                                                  opt= given_opt,\n                                                  dbname= given_dbname)\n                    break\n                except Exception as e:\n                    if ((\"the database system is starting up\" in str(e) or\n                         \"the database system is in recovery mode\" in str(e)) and\n                        retry > 1):\n                        retry -= 1\n                        time.sleep(0.1)\n                    else:\n                        raise\n            con.set_notice_receiver(null_notice_receiver)\n            return con\n\n        def get_hostname_port(self, contentid, role):\n            \"\"\"\n                Gets the port number/hostname combination of the\n                contentid and role\n            \"\"\"\n            query = (\"SELECT hostname, port FROM gp_segment_configuration WHERE\"\n                     \" content = %s AND role = '%s'\") % (contentid, role)\n            con = self.connectdb(self.dbname, given_opt=\"-c gp_role=utility\")\n            r = con.query(query).getresult()\n            con.close()\n            if len(r) == 0:\n                raise Exception(\"Invalid content %s\" % contentid)\n            if r[0][0] == socket.gethostname():\n                return (None, int(r[0][1]))\n            return (r[0][0], int(r[0][1]))\n\n        def printout_result(self, r):\n            \"\"\"\n            Print out a pygresql result set (a Query object, after the query\n            has been executed), in a format that imitates the default\n            formatting of psql. This isn't a perfect imitation: we left-justify\n            all the fields and headers, whereas psql centers the header, and\n            right-justifies numeric fields. But this is close enough, to make\n            gpdiff.pl recognize the result sets as such. (We used to just call\n            str(r), and let PyGreSQL do the formatting. But even though\n            PyGreSQL's default formatting is close to psql's, it's not close\n            enough.)\n            \"\"\"\n            widths = []\n\n            # Figure out the widths of each column.\n            fields = r.listfields()\n            for f in fields:\n                widths.append(len(str(f)))\n\n            rset = r.getresult()\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if col is None:\n                        col = \"\"\n                    widths[colno] = max(widths[colno], len(str(col)))\n                    colno = colno + 1\n\n            # Start printing. Header first.\n            result = \"\"\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"|\"\n                result += \" \" + f.ljust(widths[colno]) + \" \"\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the bar (\"----+----\")\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"+\"\n                result += \"\".ljust(widths[colno] + 2, \"-\")\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the result set itself\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if colno > 0:\n                        result += \"|\"\n                    if isinstance(col, float):\n                        col = format(col, \"g\")\n                    elif isinstance(col, bool):\n                        if col:\n                            col = 't'\n                        else:\n                            col = 'f'\n                    elif col is None:\n                        col = \"\"\n                    result += \" \" + str(col).ljust(widths[colno]) + \" \"\n                    colno = colno + 1\n                result += \"\\n\"\n\n            # Finally, the row count\n            if len(rset) == 1:\n                result += \"(1 row)\\n\"\n            else:\n                result += \"(\" + str(len(rset)) + \" rows)\\n\"\n\n            return result\n\n        def execute_command(self, command):\n            \"\"\"\n                Executes a given command\n            \"\"\"\n            try:\n                r = self.con.query(command)\n                if r is not None:\n                    if type(r) == str:\n                        # INSERT, UPDATE, etc that returns row count but not result set\n                        echo_content = command[:-1].partition(\" \")[0].upper()\n                        return \"%s %s\" % (echo_content, r)\n                    else:\n                        # SELECT or similar, print the result set without the command (type pg.Query)\n                        return self.printout_result(r)\n                else:\n                    # CREATE or other DDL without a result set or count\n                    echo_content = command[:-1].partition(\" \")[0].upper()\n                    return echo_content\n            except Exception as e:\n                return str(e)\n\n        def do(self):\n            \"\"\"\n                Process loop.\n                Ends when the command None is received\n            \"\"\"\n            (c, wait) = self.pipe.recv()\n            while c:\n                if wait:\n                    time.sleep(0.1)\n                r = self.execute_command(c)\n                self.pipe.send(r)\n                r = None\n\n                (c, wait) = self.pipe.recv()\n\n\n    def get_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n            Gets or creates the process by the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            if not dbname:\n                dbname = self.dbname\n            self.processes[(name, mode)] = SQLIsolationExecutor.SQLConnection(out_file, name, mode, dbname)\n        return self.processes[(name, mode)]\n\n    def quit_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n        Quits a process with the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            raise Exception(\"Sessions not started cannot be quit\")\n\n        self.processes[(name, mode)].quit()\n        del self.processes[(name, mode)]\n\n    def get_all_primary_contentids(self, dbname):\n        \"\"\"\n        Retrieves all primary content IDs (including the master). Intended for\n        use by *U queries.\n        \"\"\"\n        if not dbname:\n            dbname = self.dbname\n\n        con = pg.connect(dbname=dbname)\n        result = con.query(\"SELECT content FROM gp_segment_configuration WHERE role = 'p'\").getresult()\n        if len(result) == 0:\n            raise Exception(\"Invalid gp_segment_configuration contents\")\n        return [int(content[0]) for content in result]\n\n    def process_command(self, command, output_file):\n        \"\"\"\n            Processes the given command.\n            The command at this point still includes the isolation behavior\n            flags, e.g. which session to use.\n        \"\"\"\n        process_name = \"\"\n        sql = command\n        flag = \"\"\n        con_mode = \"\"\n        dbname = \"\"\n        m = self.command_pattern.match(command)\n        if m:\n            process_name = m.groups()[0]\n            flag = m.groups()[1]\n            if flag and flag[0] == \"U\":\n                con_mode = \"utility\"\n            elif flag and flag[0] == \"S\":\n                if len(flag) > 1:\n                    flag = flag[1:]\n                con_mode = \"standby\"\n            sql = m.groups()[2]\n            sql = sql.lstrip()\n            # If db_name is specifed , it should be of the following syntax:\n            # 1:@db_name <db_name>: <sql>\n            if sql.startswith('@db_name'):\n                sql_parts = sql.split(':', 2)\n                if not len(sql_parts) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not sql_parts[0].startswith('@db_name'):\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not len(sql_parts[0].split()) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                dbname = sql_parts[0].split()[1].strip()\n                if not dbname:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                sql = sql_parts[1]\n        if not flag:\n            if sql.startswith('!'):\n                sql = sql[1:]\n\n                # Check for execution mode. E.g.\n                #     !\\retcode path/to/executable --option1 --option2 ...\n                #\n                # At the moment, we only recognize the \\retcode mode, which\n                # ignores all program output in the diff (it's still printed)\n                # and adds the return code.\n                mode = None\n                if sql.startswith('\\\\'):\n                    mode, sql = sql.split(None, 1)\n                    if mode != '\\\\retcode':\n                        raise Exception('Invalid execution mode: {}'.format(mode))\n\n                cmd_output = subprocess.Popen(sql.strip(), stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)\n                stdout, _ = cmd_output.communicate()\n                print(file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- start_ignore', file=output_file)\n                print(stdout.decode(), file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- end_ignore', file=output_file)\n                    print('(exited with code {})'.format(cmd_output.returncode), file=output_file)\n            else:\n                self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \">\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), False)\n        elif flag == \"<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"q\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"U\":\n            if process_name == '*':\n                process_names = [str(content) for content in self.get_all_primary_contentids(dbname)]\n            else:\n                process_names = [process_name]\n\n            for name in process_names:\n                self.get_process(output_file, name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"U&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \"U<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"Uq\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"S\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        else:\n            raise Exception(\"Invalid isolation flag\")\n\n    def process_isolation_file(self, sql_file, output_file):\n        \"\"\"\n            Processes the given sql file and writes the output\n            to output file\n        \"\"\"\n        try:\n            command = \"\"\n            newline = False\n            for line in sql_file:\n                # this logic replicates the python2 behavior of a trailing comma at the end of print\n                # i.e. ''' print >>output_file, line.strip(), '''\n                print((\" \" if command and not newline else \"\") + line.strip(), end=\"\", file=output_file)\n                newline = False\n                if line[0] == \"!\":\n                    command_part = line # shell commands can use -- for multichar options like --include\n                elif re.match(r\";.*--\", line) or re.match(r\"^--\", line):\n                    command_part = line.partition(\"--\")[0] # remove comment from line\n                else:\n                    command_part = line\n                if command_part == \"\" or command_part == \"\\n\":\n                    print(file=output_file) \n                    newline = True\n                elif re.match(r\".*;\\s*$\", command_part) or re.match(r\"^\\d+[q\\\\<]:$\", line) or re.match(r\"^-?\\d+[SU][q\\\\<]:$\", line):\n                    command += command_part\n                    try:\n                        self.process_command(command, output_file)\n                    except Exception as e:\n                        print(\"FAILED: \", e, file=output_file)\n                    command = \"\"\n                else:\n                    command += command_part\n\n            for process in list(self.processes.values()):\n                process.stop()\n        except:\n            for process in list(self.processes.values()):\n                process.terminate()\n            raise\n        finally:\n            for process in list(self.processes.values()):\n                process.terminate()\n\nclass SQLIsolationTestCase:\n    \"\"\"\n        The isolation test case allows a fine grained control of interleaved\n        executing transactions. This is mainly used to test isolation behavior.\n\n        [<#>[flag]:] <sql> | ! <shell scripts or command>\n        #: either an integer indicating a unique session, or a content-id if\n           followed by U (for utility-mode connections). In 'U' mode, the\n           content-id can alternatively be an asterisk '*' to perform a\n           utility-mode query on the master and all primaries.\n        flag:\n            &: expect blocking behavior\n            >: running in background without blocking\n            <: join an existing session\n            q: quit the given session\n\n            U: connect in utility mode to primary contentid from gp_segment_configuration\n            U&: expect blocking behavior in utility mode (does not currently support an asterisk target)\n            U<: join an existing utility mode session (does not currently support an asterisk target)\n\n        An example is:\n\n        Execute BEGIN in transaction 1\n        Execute BEGIN in transaction 2\n        Execute INSERT in transaction 2\n        Execute SELECT in transaction 1\n        Execute COMMIT in transaction 2\n        Execute SELECT in transaction 1\n\n        The isolation tests are specified identical to sql-scripts in normal\n        SQLTestCases. However, it is possible to prefix a SQL line with\n        an tranaction identifier followed by a colon (\":\").\n        The above example would be defined by\n        1: BEGIN;\n        2: BEGIN;\n        2: INSERT INTO a VALUES (1);\n        1: SELECT * FROM a;\n        2: COMMIT;\n        1: SELECT * FROM a;\n\n        Blocking behavior can be tested by forking and joining.\n        1: BEGIN;\n        2: BEGIN;\n        1: DELETE FROM foo WHERE a = 4;\n        2&: DELETE FROM foo WHERE a = 4;\n        1: COMMIT;\n        2<:\n        2: COMMIT;\n\n        2& forks the command. It is executed in the background. If the\n        command is NOT blocking at this point, it is considered an error.\n        2< joins the background command and outputs the result of the   \n        command execution.\n\n        Session ids should be smaller than 1024.\n\n        2U: Executes a utility command connected to port 40000. \n\n        One difference to SQLTestCase is the output of INSERT.\n        SQLTestCase would output \"INSERT 0 1\" if one tuple is inserted.\n        SQLIsolationTestCase would output \"INSERT 1\". As the\n        SQLIsolationTestCase needs to have a more fine-grained control\n        over the execution order than possible with PSQL, it uses\n        the pygresql python library instead.\n\n        Connecting to a specific database:\n        1. If you specify a db_name metadata in the sql file, connect to that database in all open sessions.\n        2. If you want a specific session to be connected to a specific database , specify the sql as follows:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        etc\n\n        Here session 1 will be connected to testdb and session 2 will be connected to test2db. You can specify @db_name only at the beginning of the session. For eg:, following would error out:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: @db_name testdb: <sql>\n        2: <sql>\n        etc\n\n        Quitting sessions:\n        By default, all opened sessions will be stopped only at the end of the sql file execution. If you want to explicitly quit a session\n        in the middle of the test execution, you can specify a flag 'q' with the session identifier. For eg:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        1q:\n        2: <sql>\n        3: <sql>\n        2q:\n        3: <sql>\n        2: @db_name test: <sql>\n\n        1q:  ---> Will quit the session established with testdb.\n        2q:  ---> Will quit the session established with test2db.\n\n        The subsequent 2: @db_name test: <sql> will open a new session with the database test and execute the sql against that session.\n\n        Catalog Modification:\n\n        Some tests are easier to write if it's possible to modify a system\n        catalog across the *entire* cluster. To perform a utility-mode query on\n        all segments and the master, you can use *U commands:\n\n        *U: SET allow_system_table_mods = true;\n        *U: UPDATE pg_catalog.<table> SET <column> = <value> WHERE <cond>;\n\n        Since the number of query results returned by a *U command depends on\n        the developer's cluster configuration, it can be useful to wrap them in\n        a start_/end_ignore block. (Unfortunately, this also hides legitimate\n        failures; a better long-term solution is needed.)\n\n        Block/join flags are not currently supported with *U.\n\n        Line continuation:\n        If a line is not ended by a semicolon ';' which is followed by 0 or more spaces, the line will be combined with next line and\n        sent together as a single statement.\n\n        e.g.: Send to the server separately:\n        1: SELECT * FROM t1; -> send \"SELECT * FROM t1;\"\n        SELECT * FROM t2; -> send \"SELECT * FROM t2;\"\n\n        e.g.: Send to the server once:\n        1: SELECT * FROM\n        t1; SELECT * FROM t2; -> \"send SELECT * FROM t1; SELECT * FROM t2;\"\n\n        ATTENTION:\n        Send multi SQL statements once:\n        Multi SQL statements can be sent at once, but there are some known issues. Generally only the last query result will be printed.\n        But due to the difficulties of dealing with semicolons insides quotes, we always echo the first SQL command instead of the last\n        one if query() returns None. This created some strange issues like:\n\n        CREATE TABLE t1 (a INT); INSERT INTO t1 SELECT generate_series(1,1000);\n        CREATE 1000 (Should be INSERT 1000, but here the CREATE is taken due to the limitation)\n    \"\"\"\n\n    def run_sql_file(self, sql_file, out_file = None, out_dir = None, optimizer = None):\n        \"\"\"\n        Given a sql file and an ans file, this adds the specified gucs (self.gucs) to the sql file , runs the sql\n        against the test case database (self.db_name) and verifies the output with the ans file.\n        If an 'init_file' exists in the same location as the sql_file, this will be used\n        while doing gpdiff.\n        \"\"\"\n        # Add gucs to the test sql and form the actual sql file to be run\n        if not out_dir:\n            out_dir = self.get_out_dir()\n            \n        if not os.path.exists(out_dir):\n            TINCSystem.make_dirs(out_dir, ignore_exists_error = True)\n            \n        if optimizer is None:\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file))\n        else:\n            # sql file will be <basename>_opt.sql or <basename>_planner.sql based on optimizer\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file).replace('.sql', '_%s.sql' %self._optimizer_suffix(optimizer)))\n            \n        self._add_gucs_to_sql_file(sql_file, gucs_sql_file, optimizer)\n        self.test_artifacts.append(gucs_sql_file)\n\n        \n        if not out_file:\n            if optimizer is None:\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '.out'))\n            else:\n                # out file will be *_opt.out or *_planner.out based on optimizer\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '_%s.out' %self._optimizer_suffix(optimizer)))\n        \n        self.test_artifacts.append(out_file)\n        executor = SQLIsolationExecutor(dbname=self.db_name)\n        with open(out_file, \"w\") as f:\n            executor.process_isolation_file(open(sql_file), f)\n            f.flush()   \n        \n        if out_file[-2:] == '.t':\n            out_file = out_file[:-2]\n\n        return out_file\n\nif __name__ == \"__main__\":\n\n    parser = OptionParser()\n    parser.add_option(\"--dbname\", dest=\"dbname\",\n                      help=\"connect to database DBNAME\", metavar=\"DBNAME\")\n    (options, args) = parser.parse_args()\n\n    executor = SQLIsolationExecutor(dbname=options.dbname)\n\n    executor.process_isolation_file(sys.stdin, sys.stdout)\n```\n\n**How to Use:**\n1. **Run the script:**\n    ```bash\n    python <your_script_name>.py --dbname=your_database\n    ```\n2. **SQL File:**\n    * Create",
    "after": "\"\"\"\nCopyright (c) 2004-Present VMware, Inc. or its affiliates.\n\nThis program and the accompanying materials are made available under\nthe terms of the under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\"\"\"\n\nimport pg\nimport os\nimport subprocess\nimport re\nimport multiprocessing\nimport tempfile\nimport time\nimport sys\nimport socket\nfrom optparse import OptionParser\nimport traceback\n\ndef is_digit(n):\n    try:\n        int(n)\n        return True\n    except ValueError:\n        return  False\n\ndef null_notice_receiver(notice):\n    '''\n        Tests ignore notice messages when analyzing results,\n        so silently drop notices from the pg.connection\n    '''\n    return\n\n\nclass SQLIsolationExecutor(object):\n    def __init__(self, dbname=''):\n        self.processes = {}\n        # The re.S flag makes the \".\" in the regex match newlines.\n        # When matched against a command in process_command(), all\n        # lines in the command are matched and sent as SQL query.\n        self.command_pattern = re.compile(r\"^(-?\\d+|[*])([&\\\\<\\\\>USq]*?)\\:(.*)\", re.S)\n        if dbname:\n            self.dbname = dbname\n        else:\n            self.dbname = os.environ.get('PGDATABASE')\n\n    class SQLConnection(object):\n        def __init__(self, out_file, name, mode, dbname):\n            self.name = name\n            self.mode = mode\n            self.out_file = out_file\n            self.dbname = dbname\n\n            parent_conn, child_conn = multiprocessing.Pipe(True)\n            self.p = multiprocessing.Process(target=self.session_process, args=(child_conn,))   \n            self.pipe = parent_conn\n            self.has_open = False\n            self.p.start()\n\n            # Close \"our\" copy of the child's handle, so that if the child dies,\n            # recv() on the pipe will fail.\n            child_conn.close();\n\n            self.out_file = out_file\n\n        def session_process(self, pipe):\n            sp = SQLIsolationExecutor.SQLSessionProcess(self.name, \n                self.mode, pipe, self.dbname)\n            sp.do()\n\n        def query(self, command):\n            print(file=self.out_file)\n            self.out_file.flush()\n            if len(command.strip()) == 0:\n                return\n            if self.has_open:\n                raise Exception(\"Cannot query command while waiting for results\")\n\n            self.pipe.send((command, False))\n            r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n\n        def fork(self, command, blocking):\n            print(\"  <waiting ...>\", file=self.out_file)\n            self.pipe.send((command, True))\n\n            if blocking:\n                time.sleep(0.5)\n                if self.pipe.poll(0):\n                    p = self.pipe.recv()\n                    raise Exception(\"Forked command is not blocking; got output: %s\" % p.strip())\n            self.has_open = True\n\n        def join(self):\n            r = None\n            print(\"  <... completed>\", file=self.out_file)\n            if self.has_open:\n                r = self.pipe.recv()\n            if r is None:\n                raise Exception(\"Execution failed\")\n            print(r.rstrip(), file=self.out_file)\n            self.has_open = False\n\n        def stop(self):\n            self.pipe.send((\"\", False))\n            self.p.join()\n            if self.has_open:\n                raise Exception(\"Should not finish test case while waiting for results\")\n\n        def quit(self):\n            print(\" ... <quitting>\", file=self.out_file)\n            self.stop()\n        \n        def terminate(self):\n            self.pipe.close()\n            self.p.terminate()\n\n    class SQLSessionProcess(object):\n        def __init__(self, name, mode, pipe, dbname):\n            \"\"\"\n                Constructor\n            \"\"\"\n            self.name = name\n            self.mode = mode\n            self.pipe = pipe\n            self.dbname = dbname\n            if self.mode == \"utility\":\n                (hostname, port) = self.get_hostname_port(name, 'p')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port,\n                                          given_opt=\"-c gp_role=utility\")\n            elif self.mode == \"standby\":\n                # Connect to standby even when it's role is recorded\n                # as mirror.  This is useful for scenarios where a\n                # test needs to promote a standby without using\n                # gpactivatestandby.\n                (hostname, port) = self.get_hostname_port(name, 'm')\n                self.con = self.connectdb(given_dbname=self.dbname,\n                                          given_host=hostname,\n                                          given_port=port)\n            else:\n                self.con = self.connectdb(self.dbname)\n\n        def connectdb(self, given_dbname, given_host = None, given_port = None, given_opt = None):\n            con = None\n            retry = 1000\n            while retry:\n                try:\n                    if (given_port is None):\n                        con = pg.connect(host= given_host,\n                                          opt= given_opt,\n                                          dbname= given_dbname)\n                    else:\n                        con = pg.connect(host= given_host,\n                                                  port= given_port,\n                                                  opt= given_opt,\n                                                  dbname= given_dbname)\n                    break\n                except Exception as e:\n                    if ((\"the database system is starting up\" in str(e) or\n                         \"the database system is in recovery mode\" in str(e)) and\n                        retry > 1):\n                        retry -= 1\n                        time.sleep(0.1)\n                    else:\n                        raise\n            con.set_notice_receiver(null_notice_receiver)\n            return con\n\n        def get_hostname_port(self, contentid, role):\n            \"\"\"\n                Gets the port number/hostname combination of the\n                contentid and role\n            \"\"\"\n            query = (\"SELECT hostname, port FROM gp_segment_configuration WHERE\"\n                     \" content = %s AND role = '%s'\") % (contentid, role)\n            con = self.connectdb(self.dbname, given_opt=\"-c gp_role=utility\")\n            r = con.query(query).getresult()\n            con.close()\n            if len(r) == 0:\n                raise Exception(\"Invalid content %s\" % contentid)\n            if r[0][0] == socket.gethostname():\n                return (None, int(r[0][1]))\n            return (r[0][0], int(r[0][1]))\n\n        def printout_result(self, r):\n            \"\"\"\n            Print out a pygresql result set (a Query object, after the query\n            has been executed), in a format that imitates the default\n            formatting of psql. This isn't a perfect imitation: we left-justify\n            all the fields and headers, whereas psql centers the header, and\n            right-justifies numeric fields. But this is close enough, to make\n            gpdiff.pl recognize the result sets as such. (We used to just call\n            str(r), and let PyGreSQL do the formatting. But even though\n            PyGreSQL's default formatting is close to psql's, it's not close\n            enough.)\n            \"\"\"\n            widths = []\n\n            # Figure out the widths of each column.\n            fields = r.listfields()\n            for f in fields:\n                widths.append(len(str(f)))\n\n            rset = r.getresult()\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if col is None:\n                        col = \"\"\n                    widths[colno] = max(widths[colno], len(str(col)))\n                    colno = colno + 1\n\n            # Start printing. Header first.\n            result = \"\"\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"|\"\n                result += \" \" + f.ljust(widths[colno]) + \" \"\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the bar (\"----+----\")\n            colno = 0\n            for f in fields:\n                if colno > 0:\n                    result += \"+\"\n                result += \"\".ljust(widths[colno] + 2, \"-\")\n                colno = colno + 1\n            result += \"\\n\"\n\n            # Then the result set itself\n            for row in rset:\n                colno = 0\n                for col in row:\n                    if colno > 0:\n                        result += \"|\"\n                    if isinstance(col, float):\n                        col = format(col, \"g\")\n                    elif isinstance(col, bool):\n                        if col:\n                            col = 't'\n                        else:\n                            col = 'f'\n                    elif col is None:\n                        col = \"\"\n                    result += \" \" + str(col).ljust(widths[colno]) + \" \"\n                    colno = colno + 1\n                result += \"\\n\"\n\n            # Finally, the row count\n            if len(rset) == 1:\n                result += \"(1 row)\\n\"\n            else:\n                result += \"(\" + str(len(rset)) + \" rows)\\n\"\n\n            return result\n\n        def execute_command(self, command):\n            \"\"\"\n                Executes a given command\n            \"\"\"\n            try:\n                r = self.con.query(command)\n                if r is not None:\n                    if type(r) == str:\n                        # INSERT, UPDATE, etc that returns row count but not result set\n                        echo_content = command[:-1].partition(\" \")[0].upper()\n                        return \"%s %s\" % (echo_content, r)\n                    else:\n                        # SELECT or similar, print the result set without the command (type pg.Query)\n                        return self.printout_result(r)\n                else:\n                    # CREATE or other DDL without a result set or count\n                    echo_content = command[:-1].partition(\" \")[0].upper()\n                    return echo_content\n            except Exception as e:\n                return str(e)\n\n        def do(self):\n            \"\"\"\n                Process loop.\n                Ends when the command None is received\n            \"\"\"\n            (c, wait) = self.pipe.recv()\n            while c:\n                if wait:\n                    time.sleep(0.1)\n                r = self.execute_command(c)\n                self.pipe.send(r)\n                r = None\n\n                (c, wait) = self.pipe.recv()\n\n\n    def get_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n            Gets or creates the process by the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            if not dbname:\n                dbname = self.dbname\n            self.processes[(name, mode)] = SQLIsolationExecutor.SQLConnection(out_file, name, mode, dbname)\n        return self.processes[(name, mode)]\n\n    def quit_process(self, out_file, name, mode=\"\", dbname=\"\"):\n        \"\"\"\n        Quits a process with the given name\n        \"\"\"\n        if len(name) > 0 and not is_digit(name):\n            raise Exception(\"Name should be a number\")\n        if len(name) > 0 and mode != \"utility\" and int(name) >= 1024:\n            raise Exception(\"Session name should be smaller than 1024 unless it is utility mode number\")\n\n        if not (name, mode) in self.processes:\n            raise Exception(\"Sessions not started cannot be quit\")\n\n        self.processes[(name, mode)].quit()\n        del self.processes[(name, mode)]\n\n    def get_all_primary_contentids(self, dbname):\n        \"\"\"\n        Retrieves all primary content IDs (including the master). Intended for\n        use by *U queries.\n        \"\"\"\n        if not dbname:\n            dbname = self.dbname\n\n        con = pg.connect(dbname=dbname)\n        result = con.query(\"SELECT content FROM gp_segment_configuration WHERE role = 'p'\").getresult()\n        if len(result) == 0:\n            raise Exception(\"Invalid gp_segment_configuration contents\")\n        return [int(content[0]) for content in result]\n\n    def process_command(self, command, output_file):\n        \"\"\"\n            Processes the given command.\n            The command at this point still includes the isolation behavior\n            flags, e.g. which session to use.\n        \"\"\"\n        process_name = \"\"\n        sql = command\n        flag = \"\"\n        con_mode = \"\"\n        dbname = \"\"\n        m = self.command_pattern.match(command)\n        if m:\n            process_name = m.groups()[0]\n            flag = m.groups()[1]\n            if flag and flag[0] == \"U\":\n                con_mode = \"utility\"\n            elif flag and flag[0] == \"S\":\n                if len(flag) > 1:\n                    flag = flag[1:]\n                con_mode = \"standby\"\n            sql = m.groups()[2]\n            sql = sql.lstrip()\n            # If db_name is specifed , it should be of the following syntax:\n            # 1:@db_name <db_name>: <sql>\n            if sql.startswith('@db_name'):\n                sql_parts = sql.split(':', 2)\n                if not len(sql_parts) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not sql_parts[0].startswith('@db_name'):\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                if not len(sql_parts[0].split()) == 2:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                dbname = sql_parts[0].split()[1].strip()\n                if not dbname:\n                    raise Exception(\"Invalid syntax with dbname, should be of the form 1:@db_name <db_name>: <sql>\")\n                sql = sql_parts[1]\n        if not flag:\n            if sql.startswith('!'):\n                sql = sql[1:]\n\n                # Check for execution mode. E.g.\n                #     !\\retcode path/to/executable --option1 --option2 ...\n                #\n                # At the moment, we only recognize the \\retcode mode, which\n                # ignores all program output in the diff (it's still printed)\n                # and adds the return code.\n                mode = None\n                if sql.startswith('\\\\'):\n                    mode, sql = sql.split(None, 1)\n                    if mode != '\\\\retcode':\n                        raise Exception('Invalid execution mode: {}'.format(mode))\n\n                cmd_output = subprocess.Popen(sql.strip(), stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)\n                stdout, _ = cmd_output.communicate()\n                print(file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- start_ignore', file=output_file)\n                print(stdout.decode(), file=output_file)\n                if mode == '\\\\retcode':\n                    print('-- end_ignore', file=output_file)\n                    print('(exited with code {})'.format(cmd_output.returncode), file=output_file)\n            else:\n                self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \">\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), False)\n        elif flag == \"<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"q\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"U\":\n            if process_name == '*':\n                process_names = [str(content) for content in self.get_all_primary_contentids(dbname)]\n            else:\n                process_names = [process_name]\n\n            for name in process_names:\n                self.get_process(output_file, name, con_mode, dbname=dbname).query(sql.strip())\n        elif flag == \"U&\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).fork(sql.strip(), True)\n        elif flag == \"U<\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on join\")\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).join()\n        elif flag == \"Uq\":\n            if len(sql) > 0:\n                raise Exception(\"No query should be given on quit\")\n            self.quit_process(output_file, process_name, con_mode, dbname=dbname)\n        elif flag == \"S\":\n            self.get_process(output_file, process_name, con_mode, dbname=dbname).query(sql.strip())\n        else:\n            raise Exception(\"Invalid isolation flag\")\n\n    def process_isolation_file(self, sql_file, output_file):\n        \"\"\"\n            Processes the given sql file and writes the output\n            to output file\n        \"\"\"\n        try:\n            command = \"\"\n            newline = False\n            for line in sql_file:\n                # this logic replicates the python2 behavior of a trailing comma at the end of print\n                # i.e. ''' print >>output_file, line.strip(), '''\n                print((\" \" if command and not newline else \"\") + line.strip(), end=\"\", file=output_file)\n                newline = False\n                if line[0] == \"!\":\n                    command_part = line # shell commands can use -- for multichar options like --include\n                elif re.match(r\";.*--\", line) or re.match(r\"^--\", line):\n                    command_part = line.partition(\"--\")[0] # remove comment from line\n                else:\n                    command_part = line\n                if command_part == \"\" or command_part == \"\\n\":\n                    print(file=output_file) \n                    newline = True\n                elif re.match(r\".*;\\s*$\", command_part) or re.match(r\"^\\d+[q\\\\<]:$\", line) or re.match(r\"^-?\\d+[SU][q\\\\<]:$\", line):\n                    command += command_part\n                    try:\n                        self.process_command(command, output_file)\n                    except Exception as e:\n                        print(\"FAILED: \", e, file=output_file)\n                    command = \"\"\n                else:\n                    command += command_part\n\n            for process in list(self.processes.values()):\n                process.stop()\n        except:\n            for process in list(self.processes.values()):\n                process.terminate()\n            raise\n        finally:\n            for process in list(self.processes.values()):\n                process.terminate()\n\nclass SQLIsolationTestCase:\n    \"\"\"\n        The isolation test case allows a fine grained control of interleaved\n        executing transactions. This is mainly used to test isolation behavior.\n\n        [<#>[flag]:] <sql> | ! <shell scripts or command>\n        #: either an integer indicating a unique session, or a content-id if\n           followed by U (for utility-mode connections). In 'U' mode, the\n           content-id can alternatively be an asterisk '*' to perform a\n           utility-mode query on the master and all primaries.\n        flag:\n            &: expect blocking behavior\n            >: running in background without blocking\n            <: join an existing session\n            q: quit the given session\n\n            U: connect in utility mode to primary contentid from gp_segment_configuration\n            U&: expect blocking behavior in utility mode (does not currently support an asterisk target)\n            U<: join an existing utility mode session (does not currently support an asterisk target)\n\n        An example is:\n\n        Execute BEGIN in transaction 1\n        Execute BEGIN in transaction 2\n        Execute INSERT in transaction 2\n        Execute SELECT in transaction 1\n        Execute COMMIT in transaction 2\n        Execute SELECT in transaction 1\n\n        The isolation tests are specified identical to sql-scripts in normal\n        SQLTestCases. However, it is possible to prefix a SQL line with\n        an tranaction identifier followed by a colon (\":\").\n        The above example would be defined by\n        1: BEGIN;\n        2: BEGIN;\n        2: INSERT INTO a VALUES (1);\n        1: SELECT * FROM a;\n        2: COMMIT;\n        1: SELECT * FROM a;\n\n        Blocking behavior can be tested by forking and joining.\n        1: BEGIN;\n        2: BEGIN;\n        1: DELETE FROM foo WHERE a = 4;\n        2&: DELETE FROM foo WHERE a = 4;\n        1: COMMIT;\n        2<:\n        2: COMMIT;\n\n        2& forks the command. It is executed in the background. If the\n        command is NOT blocking at this point, it is considered an error.\n        2< joins the background command and outputs the result of the   \n        command execution.\n\n        Session ids should be smaller than 1024.\n\n        2U: Executes a utility command connected to port 40000. \n\n        One difference to SQLTestCase is the output of INSERT.\n        SQLTestCase would output \"INSERT 0 1\" if one tuple is inserted.\n        SQLIsolationTestCase would output \"INSERT 1\". As the\n        SQLIsolationTestCase needs to have a more fine-grained control\n        over the execution order than possible with PSQL, it uses\n        the pygresql python library instead.\n\n        Connecting to a specific database:\n        1. If you specify a db_name metadata in the sql file, connect to that database in all open sessions.\n        2. If you want a specific session to be connected to a specific database , specify the sql as follows:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        etc\n\n        Here session 1 will be connected to testdb and session 2 will be connected to test2db. You can specify @db_name only at the beginning of the session. For eg:, following would error out:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: @db_name testdb: <sql>\n        2: <sql>\n        etc\n\n        Quitting sessions:\n        By default, all opened sessions will be stopped only at the end of the sql file execution. If you want to explicitly quit a session\n        in the middle of the test execution, you can specify a flag 'q' with the session identifier. For eg:\n\n        1:@db_name testdb: <sql>\n        2:@db_name test2db: <sql>\n        1: <sql>\n        2: <sql>\n        1q:\n        2: <sql>\n        3: <sql>\n        2q:\n        3: <sql>\n        2: @db_name test: <sql>\n\n        1q:  ---> Will quit the session established with testdb.\n        2q:  ---> Will quit the session established with test2db.\n\n        The subsequent 2: @db_name test: <sql> will open a new session with the database test and execute the sql against that session.\n\n        Catalog Modification:\n\n        Some tests are easier to write if it's possible to modify a system\n        catalog across the *entire* cluster. To perform a utility-mode query on\n        all segments and the master, you can use *U commands:\n\n        *U: SET allow_system_table_mods = true;\n        *U: UPDATE pg_catalog.<table> SET <column> = <value> WHERE <cond>;\n\n        Since the number of query results returned by a *U command depends on\n        the developer's cluster configuration, it can be useful to wrap them in\n        a start_/end_ignore block. (Unfortunately, this also hides legitimate\n        failures; a better long-term solution is needed.)\n\n        Block/join flags are not currently supported with *U.\n\n        Line continuation:\n        If a line is not ended by a semicolon ';' which is followed by 0 or more spaces, the line will be combined with next line and\n        sent together as a single statement.\n\n        e.g.: Send to the server separately:\n        1: SELECT * FROM t1; -> send \"SELECT * FROM t1;\"\n        SELECT * FROM t2; -> send \"SELECT * FROM t2;\"\n\n        e.g.: Send to the server once:\n        1: SELECT * FROM\n        t1; SELECT * FROM t2; -> \"send SELECT * FROM t1; SELECT * FROM t2;\"\n\n        ATTENTION:\n        Send multi SQL statements once:\n        Multi SQL statements can be sent at once, but there are some known issues. Generally only the last query result will be printed.\n        But due to the difficulties of dealing with semicolons insides quotes, we always echo the first SQL command instead of the last\n        one if query() returns None. This created some strange issues like:\n\n        CREATE TABLE t1 (a INT); INSERT INTO t1 SELECT generate_series(1,1000);\n        CREATE 1000 (Should be INSERT 1000, but here the CREATE is taken due to the limitation)\n    \"\"\"\n\n    def run_sql_file(self, sql_file, out_file = None, out_dir = None, optimizer = None):\n        \"\"\"\n        Given a sql file and an ans file, this adds the specified gucs (self.gucs) to the sql file , runs the sql\n        against the test case database (self.db_name) and verifies the output with the ans file.\n        If an 'init_file' exists in the same location as the sql_file, this will be used\n        while doing gpdiff.\n        \"\"\"\n        # Add gucs to the test sql and form the actual sql file to be run\n        if not out_dir:\n            out_dir = self.get_out_dir()\n            \n        if not os.path.exists(out_dir):\n            TINCSystem.make_dirs(out_dir, ignore_exists_error = True)\n            \n        if optimizer is None:\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file))\n        else:\n            # sql file will be <basename>_opt.sql or <basename>_planner.sql based on optimizer\n            gucs_sql_file = os.path.join(out_dir, os.path.basename(sql_file).replace('.sql', '_%s.sql' %self._optimizer_suffix(optimizer)))\n            \n        self._add_gucs_to_sql_file(sql_file, gucs_sql_file, optimizer)\n        self.test_artifacts.append(gucs_sql_file)\n\n        \n        if not out_file:\n            if optimizer is None:\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '.out'))\n            else:\n                # out file will be *_opt.out or *_planner.out based on optimizer\n                out_file = os.path.join(self.get_out_dir(), os.path.basename(sql_file).replace('.sql', '_%s.out' %self._optimizer_suffix(optimizer)))\n        \n        self.test_artifacts.append(out_file)\n        executor = SQLIsolationExecutor(dbname=self.db_name)\n        with open(out_file, \"w\") as f:\n            executor.process_isolation_file(open(sql_file), f)\n            f.flush()   \n        \n        if out_file[-2:] == '.t':\n            out_file = out_file[:-2]\n\n        return out_file\n\nif __name__ == \"__main__\":\n\n    parser = OptionParser()\n    parser.add_option(\"--dbname\", dest=\"dbname\",\n                      help=\"connect to database DBNAME\", metavar=\"DBNAME\")\n    (options, args) = parser.parse_args()\n\n    executor = SQLIsolationExecutor(dbname=options.dbname)\n\n    executor.process_isolation_file(sys.stdin, sys.stdout)\n```"
  },
  "feature_stats": {
    "indices": [
      0,
      2,
      789,
      3452,
      5035,
      708,
      5862,
      3111,
      3368,
      3298,
      154
    ],
    "f_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.011390801519155502,
      0.0,
      0.3819332420825958,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.011390801519155502,
      0.0,
      0.3819332420825958,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 9.458886481672526,
    "train_mean_l2": 5.731930392324925,
    "train_mean_l1": 3.525482515364885,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251128-144741/feature_std_layer_12.html",
    "mean_std": 1.0523178577423096,
    "max_std": 18.52631378173828
  }
}