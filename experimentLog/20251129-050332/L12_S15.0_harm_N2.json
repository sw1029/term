{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "main.py experiment.use_multi_contrast=true sae.loss_option=2 sae.loss_module=option2_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.07 sae.alpha_concept.harm=0.025 sae.alpha_concept.struct=0.0 sae.use_l0=true sae.l0_coeff=0.0009132649020605174 sae.role_sep_coeff=0.0035",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0009132649020605174,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.07,
      "harm": 0.025,
      "struct": 0.0
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.0035
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      12
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "harm",
    "feature_idx": 1,
    "strength": 15.0,
    "hook_layer_idx": 11
  },
  "prompt": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\".",
  "output": {
    "before": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\". \n\nHere's why:\n\n* **Possessive Pronouns:** \"Your\" indicates possession, like \"your book.\"\n* **Contractions:** \"You're\" is a contraction of \"you are.\"\n\nTherefore, the",
    "after": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\".\n\n\nThis is an example of a common grammar mistake.\nIt's important to remember that you should always be polite and respectful. You should also be kind to others.\n\n\nIt's not okay to be disrespectful.\n\n\nIt's also"
  },
  "feature_stats": {
    "indices": [
      1,
      4403,
      5786,
      8286,
      3263,
      8214,
      3322,
      8308,
      5662,
      8625,
      1738
    ],
    "f_before": [
      94.41742706298828,
      0.9571906328201294,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      240.4261016845703,
      4.233964443206787,
      0.49782320857048035,
      0.0,
      0.26574233174324036,
      0.6571847200393677,
      0.0,
      2.3156936168670654,
      0.9856680035591125,
      0.0,
      0.52483069896698
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 10.784629479944705,
    "train_mean_l2": 7.6791182603091,
    "train_mean_l1": 3.040425260186195,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251129-050332/feature_std_layer_12.html",
    "mean_std": 0.9408262968063354,
    "max_std": 42.73415756225586
  },
  "hook_comparison": {
    "hook_layer_idx_minus1": {
      "hook_layer_idx": 11,
      "feature_stats": {
        "indices": [
          1,
          4403,
          5786,
          8286,
          3263,
          8214,
          3322,
          8308,
          5662,
          8625,
          1738
        ],
        "f_before": [
          94.41742706298828,
          0.9571906328201294,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          240.4261016845703,
          4.233964443206787,
          0.49782320857048035,
          0.0,
          0.26574233174324036,
          0.6571847200393677,
          0.0,
          2.3156936168670654,
          0.9856680035591125,
          0.0,
          0.52483069896698
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 1,
            "f_before": 94.41742706298828,
            "f_after": 240.4261016845703,
            "delta_f": 146.00867462158203
          },
          {
            "index": 5963,
            "f_before": 20.901710510253906,
            "f_after": 60.01659393310547,
            "delta_f": 39.11488342285156
          },
          {
            "index": 7250,
            "f_before": 0.0,
            "f_after": 17.676233291625977,
            "delta_f": 17.676233291625977
          },
          {
            "index": 3164,
            "f_before": 63.10988998413086,
            "f_after": 74.35443115234375,
            "delta_f": 11.24454116821289
          },
          {
            "index": 2256,
            "f_before": 0.0,
            "f_after": 5.863885879516602,
            "delta_f": 5.863885879516602
          },
          {
            "index": 5426,
            "f_before": 1.2916548252105713,
            "f_after": 6.369448661804199,
            "delta_f": 5.077793836593628
          },
          {
            "index": 3128,
            "f_before": 0.0,
            "f_after": 5.054093837738037,
            "delta_f": 5.054093837738037
          },
          {
            "index": 1158,
            "f_before": 0.08842858672142029,
            "f_after": 5.133851051330566,
            "delta_f": 5.045422464609146
          },
          {
            "index": 8410,
            "f_before": 0.0,
            "f_after": 4.993897914886475,
            "delta_f": 4.993897914886475
          },
          {
            "index": 1844,
            "f_before": 0.35240939259529114,
            "f_after": 5.299054145812988,
            "delta_f": 4.946644753217697
          },
          {
            "index": 2743,
            "f_before": 0.0,
            "f_after": 4.856472969055176,
            "delta_f": 4.856472969055176
          },
          {
            "index": 4796,
            "f_before": 0.0,
            "f_after": 4.709934711456299,
            "delta_f": 4.709934711456299
          },
          {
            "index": 4443,
            "f_before": 0.2781479060649872,
            "f_after": 4.9611406326293945,
            "delta_f": 4.682992726564407
          },
          {
            "index": 6910,
            "f_before": 1.290429711341858,
            "f_after": 5.779626369476318,
            "delta_f": 4.4891966581344604
          },
          {
            "index": 2124,
            "f_before": 0.06573881208896637,
            "f_after": 4.545680046081543,
            "delta_f": 4.479941233992577
          },
          {
            "index": 7394,
            "f_before": 0.03246232122182846,
            "f_after": 4.441267967224121,
            "delta_f": 4.408805646002293
          }
        ],
        "k": 16
      },
      "output": {
        "before": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\".  \n \n**Here's why:**\n\n* **Possessive Determiner:** \"Your\" shows possession, meaning something belongs to you. \n* **Contraction:** \"You're\" is a contraction of \"you are",
        "after": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\". \n\nHere's why your was late is incorrect:\n\n* **You're** is the contraction of \"you are\" and it's used in a more casual setting, so you're not supposed to be using it.\n\n"
      }
    },
    "hook_layer_idx_same": {
      "hook_layer_idx": 12,
      "feature_stats": {
        "indices": [
          1,
          4403,
          5786,
          8286,
          3263,
          8214,
          3322,
          8308,
          5662,
          8625,
          1738
        ],
        "f_before": [
          94.41742706298828,
          0.9571906328201294,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          94.41742706298828,
          0.9571906328201294,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 8,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 10,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 4,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 15,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 12,
            "f_before": 0.6660192608833313,
            "f_after": 0.6660192608833313,
            "delta_f": 0.0
          },
          {
            "index": 3,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 9,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 1,
            "f_before": 94.41742706298828,
            "f_after": 94.41742706298828,
            "delta_f": 0.0
          },
          {
            "index": 11,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 5,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 7,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 13,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 0,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 2,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 6,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 14,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          }
        ],
        "k": 16
      },
      "output": {
        "before": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\". \n\n\nHere's a breakdown of the issue:\n\n* **\"Your\"** indicates possession (something belongs to you).\n* **\"You're\"** is a contraction of \"you are\". \n\nThe phrase \"Your was",
        "after": "Explain why the following phrase is incorrect: \"Your was late\".\n\nThe phrase \"Your was late\" is incorrect because \"your\" is a possessive determiner, so it should be written as \"you're\" which is the contraction of \"you are\".\n\n\nThis is an example of how to avoid using that kind of phrase. \n\n\nPlease be aware that this is a harmless example, and it's just a joke. \n\n\nLet me know if you'd like to play a different game"
      }
    }
  }
}