{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "python main.py experiment.use_multi_contrast=true sae.loss_option=2 sae.loss_module=option2_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.04 sae.alpha_concept.harm=0.08 sae.alpha_concept.struct=0.0 sae.use_l0=true sae.l0_coeff=0.0014098871609261828 sae.role_sep_coeff=0.005",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0014098871609261828,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.04,
      "harm": 0.08,
      "struct": 0.0
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.005
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      12
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "struct",
    "feature_idx": 2,
    "strength": 15.0,
    "hook_layer_idx": 11
  },
  "prompt": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either",
  "output": {
    "before": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\n# Please install UMAP before running the code\n# use 'conda install -c conda-forge umap-learn' command to install it\n\nimport numpy as np\nimport pytest\nimport umap\nimport copy\n\nimport cupyx\nimport scipy.sparse\n\nfrom cuml.manifold.umap import UMAP as cuUMAP\nfrom cuml.test.utils import array_equal, unit_param, \\\n    quality_param, stress_param\nfrom sklearn.neighbors import NearestNeighbors\n\nimport joblib\n\nfrom cuml.common import logger\n\nfrom sklearn import datasets\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom sklearn.manifold import trustworthiness\nfrom sklearn.metrics import adjusted_rand_score\n\ndataset_names = ['iris', 'digits', 'wine', 'blobs']\n\n\n@pytest.mark.parametrize('nrows', [unit_param(500), quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [unit_param(20), quality_param(100),\n                         stress_param(1000)])\ndef test_blobs_cluster(nrows, n_feats):\n\n    data, labels = datasets.make_blobs(\n        n_samples=nrows, n_features=n_feats, centers=5, random_state=0)\n    embedding = cuUMAP().fit_transform(data, convert_dtype=True)\n\n    if nrows < 500000:\n        score = adjusted_rand_score(labels,\n                                    KMeans(5).fit_predict(embedding))\n        assert score == 1.0\n\n\n@pytest.mark.parametrize('nrows', [unit_param(500), quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [unit_param(10), quality_param(100),\n                         stress_param(1000)])\ndef test_umap_fit_transform_score(nrows, n_feats):\n\n    n_samples = nrows\n    n_features = n_feats\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    model = umap.UMAP(n_neighbors=10, min_dist=0.1)\n    cuml_model = cuUMAP(n_neighbors=10, min_dist=0.01)\n\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    assert not np.isnan(embedding).any()\n    assert not np.isnan(cuml_embedding).any()\n\n    if nrows < 500000:\n        cuml_score = adjusted_rand_score(labels,\n                                         KMeans(10).fit_predict(\n                                             cuml_embedding))\n        score = adjusted_rand_score(labels,\n                                    KMeans(10).fit_predict(embedding))\n\n        assert array_equal(score, cuml_score, 1e-2, with_sign=True)\n\n\ndef test_supervised_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    embedding = cuUMAP(n_neighbors=10, random_state=0,\n                       min_dist=0.01).fit_transform(\n        data, iris.target, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_semisupervised_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    target = iris.target.copy()\n    target[25:75] = -1\n    embedding = cuUMAP(n_neighbors=10, random_state=0,\n                       min_dist=0.01).fit_transform(\n        data, target, convert_dtype=True)\n\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    embedding = cuUMAP(n_neighbors=10, min_dist=0.01,\n                       random_state=0).fit_transform(\n        data, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_iris(target_metric):\n\n    iris = datasets.load_iris()\n\n    iris_selection = np.random.RandomState(42).choice(\n        [True, False], 150, replace=True, p=[0.75, 0.25])\n    data = iris.data[iris_selection]\n\n    fitter = cuUMAP(n_neighbors=10, init=\"random\", n_epochs=800, min_dist=0.01,\n                    random_state=42, target_metric=target_metric)\n    fitter.fit(data, convert_dtype=True)\n    new_data = iris.data[~iris_selection]\n    embedding = fitter.transform(new_data, convert_dtype=True)\n\n    assert not np.isnan(embedding).any()\n\n    trust = trustworthiness(new_data, embedding, n_neighbors=10)\n    assert trust >= 0.85\n\n\n@pytest.mark.parametrize('input_type', ['cupy', 'scipy'])\n@pytest.mark.parametrize('xform_method', ['fit', 'fit_transform'])\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_digits_sparse(target_metric, input_type,\n                                         xform_method):\n\n    digits = datasets.load_digits()\n\n    digits_selection = np.random.RandomState(42).choice(\n        [True, False], 1797, replace=True, p=[0.75, 0.25])\n\n    if input_type == 'cupy':\n        sp_prefix = cupyx.scipy.sparse\n    else:\n        sp_prefix = scipy.sparse\n\n    data = sp_prefix.csr_matrix(\n        scipy.sparse.csr_matrix(digits.data[digits_selection]))\n\n    fitter = cuUMAP(n_neighbors=15,\n                    verbose=logger.level_info,\n                    init=\"random\",\n                    n_epochs=0,\n                    min_dist=0.01,\n                    random_state=42,\n                    target_metric=target_metric)\n\n    new_data = sp_prefix.csr_matrix(\n        scipy.sparse.csr_matrix(digits.data[~digits_selection]))\n\n    if xform_method == 'fit':\n        fitter.fit(data, convert_dtype=True)\n        embedding = fitter.transform(new_data, convert_dtype=True)\n    else:\n        embedding = fitter.fit_transform(new_data, convert_dtype=True)\n\n    if input_type == 'cupy':\n        embedding = embedding.get()\n\n    trust = trustworthiness(digits.data[~digits_selection], embedding,\n                            n_neighbors=15)\n    assert trust >= 0.96\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_digits(target_metric):\n\n    digits = datasets.load_digits()\n\n    digits_selection = np.random.RandomState(42).choice(\n        [True, False], 1797, replace=True, p=[0.75, 0.25])\n    data = digits.data[digits_selection]\n\n    fitter = cuUMAP(n_neighbors=15,\n                    verbose=logger.level_debug,\n                    init=\"random\",\n                    n_epochs=0,\n                    min_dist=0.01,\n                    random_state=42,\n                    target_metric=target_metric)\n    fitter.fit(data, convert_dtype=True)\n\n    new_data = digits.data[~digits_selection]\n\n    embedding = fitter.transform(new_data, convert_dtype=True)\n    trust = trustworthiness(digits.data[~digits_selection], embedding,\n                            n_neighbors=15)\n    assert trust >= 0.96\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.parametrize('name', dataset_names)\ndef test_umap_fit_transform_trust(name, target_metric):\n\n    if name == 'iris':\n        iris = datasets.load_iris()\n        data = iris.data\n        labels = iris.target\n\n    elif name == 'digits':\n        digits = datasets.load_digits(n_class=5)\n        data = digits.data\n        labels = digits.target\n\n    elif name == 'wine':\n        wine = datasets.load_wine()\n        data = wine.data\n        labels = wine.target\n    else:\n        data, labels = make_blobs(n_samples=500, n_features=10,\n                                  centers=10, random_state=42)\n\n    model = umap.UMAP(n_neighbors=10, min_dist=0.01,\n                      target_metric=target_metric)\n    cuml_model = cuUMAP(n_neighbors=10, min_dist=0.01,\n                        target_metric=target_metric)\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    trust = trustworthiness(data, embedding, n_neighbors=10)\n    cuml_trust = trustworthiness(data, cuml_embedding, n_neighbors=10)\n\n    assert array_equal(trust, cuml_trust, 1e-1, with_sign=True)\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.parametrize('name', [unit_param('digits')])\n@pytest.mark.parametrize('nrows', [quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [quality_param(100),\n                         stress_param(1000)])\n@pytest.mark.parametrize('should_downcast', [True])\n@pytest.mark.parametrize('input_type', ['dataframe', 'ndarray'])\ndef test_umap_data_formats(input_type, should_downcast,\n                           nrows, n_feats, name, target_metric):\n\n    dtype = np.float32 if not should_downcast else np.float64\n    n_samples = nrows\n    n_feats = n_feats\n\n    if name == 'digits':\n        # use the digits dataset for unit test\n        digits = datasets.load_digits(n_class=9)\n        X = digits[\"data\"].astype(dtype)\n\n    else:\n        X, y = datasets.make_blobs(n_samples=n_samples,\n                                   n_features=n_feats, random_state=0)\n\n    umap = cuUMAP(n_neighbors=3, n_components=2, target_metric=target_metric)\n\n    embeds = umap.fit_transform(X)\n    assert type(embeds) == np.ndarray\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.filterwarnings(\"ignore:(.*)connected(.*):UserWarning:sklearn[.*]\")\ndef test_umap_fit_transform_score_default(target_metric):\n\n    n_samples = 500\n    n_features = 20\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    model = umap.UMAP(target_metric=target_metric)\n    cuml_model = cuUMAP(target_metric=target_metric)\n\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    cuml_score = adjusted_rand_score(labels,\n                                     KMeans(10).fit_predict(\n                                        cuml_embedding))\n    score = adjusted_rand_score(labels,\n                                KMeans(10).fit_predict(embedding))\n\n    assert array_equal(score, cuml_score, 1e-2, with_sign=True)\n\n\ndef test_umap_fit_transform_against_fit_and_transform():\n\n    n_samples = 500\n    n_features = 20\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    \"\"\"\n    First test the default option does not hash the input\n    \"\"\"\n\n    cuml_model = cuUMAP()\n\n    ft_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n    fit_embedding_same_input = cuml_model.transform(data, convert_dtype=True)\n\n    assert joblib.hash(ft_embedding) != joblib.hash(fit_embedding_same_input)\n\n    \"\"\"\n    Next, test explicitly enabling feature hashes the input\n    \"\"\"\n\n    cuml_model = cuUMAP(hash_input=True)\n\n    ft_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n    fit_embedding_same_input = cuml_model.transform(data, convert_dtype=True)\n\n    assert joblib.hash(ft_embedding) == joblib.hash(fit_embedding_same_input)\n\n    fit_embedding_diff_input = cuml_model.transform(data[1:],\n                                                    convert_dtype=True)\n    assert joblib.hash(ft_embedding) != joblib.hash(fit_embedding_diff_input)\n\n\n@pytest.mark.parametrize('n_components,random_state',\n                         [unit_param(2, None),\n                          unit_param(2, 8),\n                          unit_param(2, np.random.RandomState(42)),\n                          unit_param(21, None),\n                          unit_param(21, np.random.RandomState(42)),\n                          unit_param(25, 8),\n                          unit_param(50, None),\n                          stress_param(50, 8)])\ndef test_umap_fit_transform_reproducibility(n_components, random_state):\n\n    n_samples = 8000\n    n_features = 200\n\n    if random_state is None:\n        n_components *= 2\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    def get_embedding(n_components, random_state):\n        reducer = cuUMAP(init=\"random\",\n                         n_components=n_components,\n                         random_state=random_state)\n        return reducer.fit_transform(data, convert_dtype=True)\n\n    state = copy.copy(random_state)\n    cuml_embedding1 = get_embedding(n_components, state)\n    state = copy.copy(random_state)\n    cuml_embedding2 = get_embedding(n_components, state)\n\n    assert not np.isnan(cuml_embedding1).any()\n    assert not np.isnan(cuml_embedding2).any()\n\n    # Reproducibility threshold raised until intermittent failure is fixed\n    # Ref: https://github.com/rapidsai/cuml/issues/1903\n    mean_diff = np.mean(np.abs(cuml_embedding1 - cuml_embedding2))\n    if random_state is not None:\n        assert mean_diff == 0.0\n    else:\n        assert mean_diff > 0.5\n\n\n@pytest.mark.parametrize('n_components,random_state',\n                         [unit_param(2, None),\n                          unit_param(2, 8),\n                          unit_param(2, np.random.RandomState(42)),\n                          unit_param(21, None),\n                          unit_param(25, 8),\n                          unit_param(25, np.random.RandomState(42)),\n                          unit_param(50, None),\n                          stress_param(50, 8)])\ndef test_umap_transform_reproducibility(n_components, random_state):\n\n    n_samples = 5000\n    n_features = 200\n\n    if random_state is None:\n        n_components *= 2\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    selection = np.random.RandomState(42).choice(\n        [True, False], n_samples, replace=True, p=[0.5, 0.5])\n    fit_data = data[selection]\n    transform_data = data[~selection]\n\n    def get_embedding(n_components, random_state):\n        reducer = cuUMAP(init=\"random\",\n                         n_components=n_components,\n                         random_state=random_state)\n        reducer.fit(fit_data, convert_dtype=True)\n        return reducer.transform(transform_data, convert_dtype=True)\n\n    state = copy.copy(random_state)\n    cuml_embedding1 = get_embedding(n_components, state)\n    state = copy.copy(random_state)\n    cuml_embedding2 = get_embedding(n_components, state)\n\n    assert not np.isnan(cuml_embedding1).any()\n    assert not np.isnan(cuml_embedding2).any()\n\n    # Reproducibility threshold raised until intermittent failure is fixed\n    # Ref: https://github.com/rapidsai/cuml/issues/1903\n    mean_diff = np.mean(np.abs(cuml_embedding1 - cuml_embedding2))\n    if random_state is not None:\n        assert mean_diff == 0.0\n    else:\n        assert mean_diff > 0.5\n\n\ndef test_umap_fit_transform_trustworthiness_with_consistency_enabled():\n    iris = datasets.load_iris()\n    data = iris.data\n    algo = cuUMAP(n_neighbors=10, min_dist=0.01, init=\"random\",\n                  random_state=42)\n    embedding = algo.fit_transform(data, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_umap_transform_trustworthiness_with_consistency_enabled():\n    iris = datasets.load_iris()\n    data = iris.data\n    selection = np.random.RandomState(42).choice(\n        [True, False], data.shape[0], replace=True, p=[0.5, 0.5])\n    fit_data = data[selection]\n    transform_data = data[~selection]\n    model = cuUMAP(n_neighbors=10, min_dist=0.01, init=\"random\",\n                   random_state=42)\n    model.fit(fit_data, convert_dtype=True)\n    embedding = model.transform(transform_data, convert_dtype=True)\n    trust = trustworthiness(transform_data, embedding, n_neighbors=10)\n    assert trust >= 0.92\n\n\n@pytest.mark.filterwarnings(\"ignore:(.*)zero(.*)::scipy[.*]|umap[.*]\")\ndef test_exp_decay_params():\n    def compare_exp_decay_params(a=None, b=None, min_dist=0.1, spread=1.0):\n        cuml_model = cuUMAP(a=a, b=b, min_dist=min_dist, spread=spread)\n        state = cuml_model.__getstate__()\n        cuml_a, cuml_b = state['a'], state['b']\n        skl_model = umap.UMAP(a=a, b=b, min_dist=min_dist, spread=spread)\n        skl_model.fit(np.zeros((1, 1)))\n        sklearn_a, sklearn_b = skl_model._a, skl_model._b\n\n        assert abs(cuml_a) - abs(sklearn_a) < 1e-6\n        assert abs(cuml_b) - abs(sklearn_b) < 1e-6\n\n    compare_exp_decay_params(min_dist=0.1, spread=1.0)\n    compare_exp_decay_params(a=0.5, b=2.0)\n    compare_exp_decay_params(a=0.5)\n    compare_exp_decay_params(b=0.5)\n    compare_exp_decay_params(min_dist=0.1, spread=10.0)\n\n\n@pytest.mark.parametrize('n_neighbors', [5, 15])\ndef test_umap_knn_parameters(n_neighbors):\n    data, labels = datasets.make_blobs(\n        n_samples=2000, n_features=10, centers=5, random_state=0)\n    data = data.astype(np.float32)\n\n    def fit_transform_embed(knn_graph=None):\n        model = cuUMAP(random_state=42,\n                       init='random',\n                       n_neighbors=n_neighbors)\n        return model.fit_transform(data, knn_graph=knn_graph,\n                                   convert_dtype=True)\n\n    def transform_embed(knn_graph=None):\n        model = cuUMAP(random_state=42,\n                       init='random',\n                       n_neighbors=n_neighbors)\n        model.fit(data, knn_graph=knn_graph, convert_dtype=True)\n        return model.transform(data, knn_graph=knn_graph,\n                               convert_dtype=True)\n\n    def test_trustworthiness(embedding):\n        trust = trustworthiness(data, embedding, n_neighbors=n_neighbors)\n        assert trust >= 0.92\n\n    def test_equality(e1, e2):\n        mean_diff = np.mean(np.abs(e1 - e2))\n        print(\"mean diff: %s\" % mean_diff)\n        assert mean_diff < 1.0\n\n    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n    neigh.fit(data)\n    knn_graph = neigh.kneighbors_graph(data, mode=\"distance\")\n\n    embedding1 = fit_transform_embed(None)\n    embedding2 = fit_transform_embed(knn_graph.tocsr())\n    embedding3 = fit_transform_embed(knn_graph.tocoo())\n    embedding4 = fit_transform_embed(knn_graph.tocsc())\n    embedding5 = transform_embed(knn_graph.tocsr())\n    embedding6 = transform_embed(knn_graph.tocoo())\n    embedding7 = transform_embed(knn_graph.tocsc())\n\n    test_trustworthiness(embedding1)\n    test_trustworthiness(embedding2)\n    test_trustworthiness(embedding3)\n    test_trustworthiness(embedding4)\n    test_trustworthiness(embedding5)\n    test_trustworthiness(embedding6)\n    test_trustworthiness(embedding7)\n\n    test_equality(embedding2, embedding3)\n    test_equality(embedding3, embedding4)\n    test_equality(embedding5, embedding6)\n    test_equality(embedding6, embedding7)\n```\n",
    "after": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\n# Please install UMAP before running the code\n# use 'conda install -c conda-forge umap-learn' command to install it\n\nimport numpy as np\nimport pytest\nimport umap\nimport copy\n\nimport cupyx\nimport scipy.sparse\n\nfrom cuml.manifold.umap import UMAP as cuUMAP\nfrom cuml.test.utils import array_equal, unit_param, \\\n    quality_param, stress_param\nfrom sklearn.neighbors import NearestNeighbors\n\nimport joblib\n\nfrom cuml.common import logger\n\nfrom sklearn import datasets\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom sklearn.manifold import trustworthiness\nfrom sklearn.metrics import adjusted_rand_score\n\ndataset_names = ['iris', 'digits', 'wine', 'blobs']\n\n\n@pytest.mark.parametrize('nrows', [unit_param(500), quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [unit_param(20), quality_param(100),\n                         stress_param(1000)])\ndef test_blobs_cluster(nrows, n_feats):\n\n    data, labels = datasets.make_blobs(\n        n_samples=nrows, n_features=n_feats, centers=5, random_state=0)\n    embedding = cuUMAP().fit_transform(data, convert_dtype=True)\n\n    if nrows < 500000:\n        score = adjusted_rand_score(labels,\n                                    KMeans(5).fit_predict(embedding))\n        assert score == 1.0\n\n\n@pytest.mark.parametrize('nrows', [unit_param(500), quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [unit_param(10), quality_param(100),\n                         stress_param(1000)])\ndef test_umap_fit_transform_score(nrows, n_feats):\n\n    n_samples = nrows\n    n_features = n_feats\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    model = umap.UMAP(n_neighbors=10, min_dist=0.1)\n    cuml_model = cuUMAP(n_neighbors=10, min_dist=0.01)\n\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    assert not np.isnan(embedding).any()\n    assert not np.isnan(cuml_embedding).any()\n\n    if nrows < 500000:\n        cuml_score = adjusted_rand_score(labels,\n                                         KMeans(10).fit_predict(\n                                             cuml_embedding))\n        score = adjusted_rand_score(labels,\n                                    KMeans(10).fit_predict(embedding))\n\n        assert array_equal(score, cuml_score, 1e-2, with_sign=True)\n\n\ndef test_supervised_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    embedding = cuUMAP(n_neighbors=10, random_state=0,\n                       min_dist=0.01).fit_transform(\n        data, iris.target, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_semisupervised_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    target = iris.target.copy()\n    target[25:75] = -1\n    embedding = cuUMAP(n_neighbors=10, random_state=0,\n                       min_dist=0.01).fit_transform(\n        data, target, convert_dtype=True)\n\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_umap_trustworthiness_on_iris():\n    iris = datasets.load_iris()\n    data = iris.data\n    embedding = cuUMAP(n_neighbors=10, min_dist=0.01,\n                       random_state=0).fit_transform(\n        data, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_iris(target_metric):\n\n    iris = datasets.load_iris()\n\n    iris_selection = np.random.RandomState(42).choice(\n        [True, False], 150, replace=True, p=[0.75, 0.25])\n    data = iris.data[iris_selection]\n\n    fitter = cuUMAP(n_neighbors=10, init=\"random\", n_epochs=800, min_dist=0.01,\n                    random_state=42, target_metric=target_metric)\n    fitter.fit(data, convert_dtype=True)\n    new_data = iris.data[~iris_selection]\n    embedding = fitter.transform(new_data, convert_dtype=True)\n\n    assert not np.isnan(embedding).any()\n\n    trust = trustworthiness(new_data, embedding, n_neighbors=10)\n    assert trust >= 0.85\n\n\n@pytest.mark.parametrize('input_type', ['cupy', 'scipy'])\n@pytest.mark.parametrize('xform_method', ['fit', 'fit_transform'])\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_digits_sparse(target_metric, input_type,\n                                         xform_method):\n\n    digits = datasets.load_digits()\n\n    digits_selection = np.random.RandomState(42).choice(\n        [True, False], 1797, replace=True, p=[0.75, 0.25])\n\n    if input_type == 'cupy':\n        sp_prefix = cupyx.scipy.sparse\n    else:\n        sp_prefix = scipy.sparse\n\n    data = sp_prefix.csr_matrix(\n        scipy.sparse.csr_matrix(digits.data[digits_selection]))\n\n    fitter = cuUMAP(n_neighbors=15,\n                    verbose=logger.level_info,\n                    init=\"random\",\n                    n_epochs=0,\n                    min_dist=0.01,\n                    random_state=42,\n                    target_metric=target_metric)\n\n    new_data = sp_prefix.csr_matrix(\n        scipy.sparse.csr_matrix(digits.data[~digits_selection]))\n\n    if xform_method == 'fit':\n        fitter.fit(data, convert_dtype=True)\n        embedding = fitter.transform(new_data, convert_dtype=True)\n    else:\n        embedding = fitter.fit_transform(new_data, convert_dtype=True)\n\n    if input_type == 'cupy':\n        embedding = embedding.get()\n\n    trust = trustworthiness(digits.data[~digits_selection], embedding,\n                            n_neighbors=15)\n    assert trust >= 0.96\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\ndef test_umap_transform_on_digits(target_metric):\n\n    digits = datasets.load_digits()\n\n    digits_selection = np.random.RandomState(42).choice(\n        [True, False], 1797, replace=True, p=[0.75, 0.25])\n    data = digits.data[digits_selection]\n\n    fitter = cuUMAP(n_neighbors=15,\n                    verbose=logger.level_debug,\n                    init=\"random\",\n                    n_epochs=0,\n                    min_dist=0.01,\n                    random_state=42,\n                    target_metric=target_metric)\n    fitter.fit(data, convert_dtype=True)\n\n    new_data = digits.data[~digits_selection]\n\n    embedding = fitter.transform(new_data, convert_dtype=True)\n    trust = trustworthiness(digits.data[~digits_selection], embedding,\n                            n_neighbors=15)\n    assert trust >= 0.96\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.parametrize('name', dataset_names)\ndef test_umap_fit_transform_trust(name, target_metric):\n\n    if name == 'iris':\n        iris = datasets.load_iris()\n        data = iris.data\n        labels = iris.target\n\n    elif name == 'digits':\n        digits = datasets.load_digits(n_class=5)\n        data = digits.data\n        labels = digits.target\n\n    elif name == 'wine':\n        wine = datasets.load_wine()\n        data = wine.data\n        labels = wine.target\n    else:\n        data, labels = make_blobs(n_samples=500, n_features=10,\n                                  centers=10, random_state=42)\n\n    model = umap.UMAP(n_neighbors=10, min_dist=0.01,\n                      target_metric=target_metric)\n    cuml_model = cuUMAP(n_neighbors=10, min_dist=0.01,\n                        target_metric=target_metric)\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    trust = trustworthiness(data, embedding, n_neighbors=10)\n    cuml_trust = trustworthiness(data, cuml_embedding, n_neighbors=10)\n\n    assert array_equal(trust, cuml_trust, 1e-1, with_sign=True)\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.parametrize('name', [unit_param('digits')])\n@pytest.mark.parametrize('nrows', [quality_param(5000),\n                         stress_param(500000)])\n@pytest.mark.parametrize('n_feats', [quality_param(100),\n                         stress_param(1000)])\n@pytest.mark.parametrize('should_downcast', [True])\n@pytest.mark.parametrize('input_type', ['dataframe', 'ndarray'])\ndef test_umap_data_formats(input_type, should_downcast,\n                           nrows, n_feats, name, target_metric):\n\n    dtype = np.float32 if not should_downcast else np.float64\n    n_samples = nrows\n    n_feats = n_feats\n\n    if name == 'digits':\n        # use the digits dataset for unit test\n        digits = datasets.load_digits(n_class=9)\n        X = digits[\"data\"].astype(dtype)\n\n    else:\n        X, y = datasets.make_blobs(n_samples=n_samples,\n                                   n_features=n_feats, random_state=0)\n\n    umap = cuUMAP(n_neighbors=3, n_components=2, target_metric=target_metric)\n\n    embeds = umap.fit_transform(X)\n    assert type(embeds) == np.ndarray\n\n\n@pytest.mark.parametrize('target_metric', [\"categorical\", \"euclidean\"])\n@pytest.mark.filterwarnings(\"ignore:(.*)connected(.*):UserWarning:sklearn[.*]\")\ndef test_umap_fit_transform_score_default(target_metric):\n\n    n_samples = 500\n    n_features = 20\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    model = umap.UMAP(target_metric=target_metric)\n    cuml_model = cuUMAP(target_metric=target_metric)\n\n    embedding = model.fit_transform(data)\n    cuml_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n\n    cuml_score = adjusted_rand_score(labels,\n                                     KMeans(10).fit_predict(\n                                        cuml_embedding))\n    score = adjusted_rand_score(labels,\n                                KMeans(10).fit_predict(embedding))\n\n    assert array_equal(score, cuml_score, 1e-2, with_sign=True)\n\n\ndef test_umap_fit_transform_against_fit_and_transform():\n\n    n_samples = 500\n    n_features = 20\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    \"\"\"\n    First test the default option does not hash the input\n    \"\"\"\n\n    cuml_model = cuUMAP()\n\n    ft_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n    fit_embedding_same_input = cuml_model.transform(data, convert_dtype=True)\n\n    assert joblib.hash(ft_embedding) != joblib.hash(fit_embedding_same_input)\n\n    \"\"\"\n    Next, test explicitly enabling feature hashes the input\n    \"\"\"\n\n    cuml_model = cuUMAP(hash_input=True)\n\n    ft_embedding = cuml_model.fit_transform(data, convert_dtype=True)\n    fit_embedding_same_input = cuml_model.transform(data, convert_dtype=True)\n\n    assert joblib.hash(ft_embedding) == joblib.hash(fit_embedding_same_input)\n\n    fit_embedding_diff_input = cuml_model.transform(data[1:],\n                                                    convert_dtype=True)\n    assert joblib.hash(ft_embedding) != joblib.hash(fit_embedding_diff_input)\n\n\n@pytest.mark.parametrize('n_components,random_state',\n                         [unit_param(2, None),\n                          unit_param(2, 8),\n                          unit_param(2, np.random.RandomState(42)),\n                          unit_param(21, None),\n                          unit_param(21, np.random.RandomState(42)),\n                          unit_param(25, 8),\n                          unit_param(50, None),\n                          stress_param(50, 8)])\ndef test_umap_fit_transform_reproducibility(n_components, random_state):\n\n    n_samples = 8000\n    n_features = 200\n\n    if random_state is None:\n        n_components *= 2\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    def get_embedding(n_components, random_state):\n        reducer = cuUMAP(init=\"random\",\n                         n_components=n_components,\n                         random_state=random_state)\n        return reducer.fit_transform(data, convert_dtype=True)\n\n    state = copy.copy(random_state)\n    cuml_embedding1 = get_embedding(n_components, state)\n    state = copy.copy(random_state)\n    cuml_embedding2 = get_embedding(n_components, state)\n\n    assert not np.isnan(cuml_embedding1).any()\n    assert not np.isnan(cuml_embedding2).any()\n\n    # Reproducibility threshold raised until intermittent failure is fixed\n    # Ref: https://github.com/rapidsai/cuml/issues/1903\n    mean_diff = np.mean(np.abs(cuml_embedding1 - cuml_embedding2))\n    if random_state is not None:\n        assert mean_diff == 0.0\n    else:\n        assert mean_diff > 0.5\n\n\n@pytest.mark.parametrize('n_components,random_state',\n                         [unit_param(2, None),\n                          unit_param(2, 8),\n                          unit_param(2, np.random.RandomState(42)),\n                          unit_param(21, None),\n                          unit_param(25, 8),\n                          unit_param(25, np.random.RandomState(42)),\n                          unit_param(50, None),\n                          stress_param(50, 8)])\ndef test_umap_transform_reproducibility(n_components, random_state):\n\n    n_samples = 5000\n    n_features = 200\n\n    if random_state is None:\n        n_components *= 2\n\n    data, labels = make_blobs(n_samples=n_samples, n_features=n_features,\n                              centers=10, random_state=42)\n\n    selection = np.random.RandomState(42).choice(\n        [True, False], n_samples, replace=True, p=[0.5, 0.5])\n    fit_data = data[selection]\n    transform_data = data[~selection]\n\n    def get_embedding(n_components, random_state):\n        reducer = cuUMAP(init=\"random\",\n                         n_components=n_components,\n                         random_state=random_state)\n        reducer.fit(fit_data, convert_dtype=True)\n        return reducer.transform(transform_data, convert_dtype=True)\n\n    state = copy.copy(random_state)\n    cuml_embedding1 = get_embedding(n_components, state)\n    state = copy.copy(random_state)\n    cuml_embedding2 = get_embedding(n_components, state)\n\n    assert not np.isnan(cuml_embedding1).any()\n    assert not np.isnan(cuml_embedding2).any()\n\n    # Reproducibility threshold raised until intermittent failure is fixed\n    # Ref: https://github.com/rapidsai/cuml/issues/1903\n    mean_diff = np.mean(np.abs(cuml_embedding1 - cuml_embedding2))\n    if random_state is not None:\n        assert mean_diff == 0.0\n    else:\n        assert mean_diff > 0.5\n\n\ndef test_umap_fit_transform_trustworthiness_with_consistency_enabled():\n    iris = datasets.load_iris()\n    data = iris.data\n    algo = cuUMAP(n_neighbors=10, min_dist=0.01, init=\"random\",\n                  random_state=42)\n    embedding = algo.fit_transform(data, convert_dtype=True)\n    trust = trustworthiness(iris.data, embedding, n_neighbors=10)\n    assert trust >= 0.97\n\n\ndef test_umap_transform_trustworthiness_with_consistency_enabled():\n    iris = datasets.load_iris()\n    data = iris.data\n    selection = np.random.RandomState(42).choice(\n        [True, False], data.shape[0], replace=True, p=[0.5, 0.5])\n    fit_data = data[selection]\n    transform_data = data[~selection]\n    model = cuUMAP(n_neighbors=10, min_dist=0.01, init=\"random\",\n                   random_state=42)\n    model.fit(fit_data, convert_dtype=True)\n    embedding = model.transform(transform_data, convert_dtype=True)\n    trust = trustworthiness(transform_data, embedding, n_neighbors=10)\n    assert trust >= 0.92\n\n\n@pytest.mark.filterwarnings(\"ignore:(.*)zero(.*)::scipy[.*]|umap[.*]\")\ndef test_exp_decay_params():\n    def compare_exp_decay_params(a=None, b=None, min_dist=0.1, spread=1.0):\n        cuml_model = cuUMAP(a=a, b=b, min_dist=min_dist, spread=spread)\n        state = cuml_model.__getstate__()\n        cuml_a, cuml_b = state['a'], state['b']\n        skl_model = umap.UMAP(a=a, b=b, min_dist=min_dist, spread=spread)\n        skl_model.fit(np.zeros((1, 1)))\n        sklearn_a, sklearn_b = skl_model._a, skl_model._b\n\n        assert abs(cuml_a) - abs(sklearn_a) < 1e-6\n        assert abs(cuml_b) - abs(sklearn_b) < 1e-6\n\n    compare_exp_decay_params(min_dist=0.1, spread=1.0)\n    compare_exp_decay_params(a=0.5, b=2.0)\n    compare_exp_decay_params(a=0.5)\n    compare_exp_decay_params(b=0.5)\n    compare_exp_decay_params(min_dist=0.1, spread=10.0)\n\n\n@pytest.mark.parametrize('n_neighbors', [5, 15])\ndef test_umap_knn_parameters(n_neighbors):\n    data, labels = datasets.make_blobs(\n        n_samples=2000, n_features=10, centers=5, random_state=0)\n    data = data.astype(np.float32)\n\n    def fit_transform_embed(knn_graph=None):\n        model = cuUMAP(random_state=42,\n                       init='random',\n                       n_neighbors=n_neighbors)\n        return model.fit_transform(data, knn_graph=knn_graph,\n                                   convert_dtype=True)\n\n    def transform_embed(knn_graph=None):\n        model = cuUMAP(random_state=42,\n                       init='random',\n                       n_neighbors=n_neighbors)\n        model.fit(data, knn_graph=knn_graph, convert_dtype=True)\n        return model.transform(data, knn_graph=knn_graph,\n                               convert_dtype=True)\n\n    def test_trustworthiness(embedding):\n        trust = trustworthiness(data, embedding, n_neighbors=n_neighbors)\n        assert trust >= 0.92\n\n    def test_equality(e1, e2):\n        mean_diff = np.mean(np.abs(e1 - e2))\n        print(\"mean diff: %s\" % mean_diff)\n        assert mean_diff < 1.0\n\n    neigh = NearestNeighbors(n_neighbors=n_neighbors)\n    neigh.fit(data)\n    knn_graph = neigh.kneighbors_graph(data, mode=\"distance\")\n\n    embedding1 = fit_transform_embed(None)\n    embedding2 = fit_transform_embed(knn_graph.tocsr())\n    embedding3 = fit_transform_embed(knn_graph.tocoo())\n    embedding4 = fit_transform_embed(knn_graph.tocsc())\n    embedding5 = transform_embed(knn_graph.tocsr())\n    embedding6 = transform_embed(knn_graph.tocoo())\n    embedding7 = transform_embed(knn_graph.tocsc())\n\n    test_trustworthiness(embedding1)\n    test_trustworthiness(embedding2)\n    test_trustworthiness(embedding3)\n    test_trustworthiness(embedding4)\n    test_trustworthiness(embedding5)\n    test_trustworthiness(embedding6)\n    test_trustworthiness(embedding7)\n\n    test_equality(embedding2, embedding3)\n    test_equality(embedding3, embedding4)\n    test_equality(embedding5, embedding6)\n    test_equality(embedding6, embedding7)\n```\n```\n    #\n    # Copyright (c) 2019-2021, NVIDIA CORPORATION\n    #\n    # Licensed under the Apache License 2.0 (the \"License\"):\n    #   "
  },
  "feature_stats": {
    "indices": [
      2,
      0,
      6770,
      6328,
      4282,
      2950,
      8978,
      5991,
      6033,
      4546,
      9169
    ],
    "f_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      0.0,
      0.905926525592804,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 7.527851513653993,
    "train_mean_l2": 5.725549944125116,
    "train_mean_l1": 2.6907401079833506,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251128-174827/feature_std_layer_12.html",
    "mean_std": 1.0116609334945679,
    "max_std": 56.1993408203125
  },
  "hook_comparison": {
    "hook_layer_idx_minus1": {
      "hook_layer_idx": 11,
      "feature_stats": {
        "indices": [
          2,
          0,
          6770,
          6328,
          4282,
          2950,
          8978,
          5991,
          6033,
          4546,
          9169
        ],
        "f_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          0.0,
          0.0,
          0.905926525592804,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 7697,
            "f_before": 0.0,
            "f_after": 10.076054573059082,
            "delta_f": 10.076054573059082
          },
          {
            "index": 6544,
            "f_before": 0.0,
            "f_after": 9.514579772949219,
            "delta_f": 9.514579772949219
          },
          {
            "index": 8762,
            "f_before": 39.9948616027832,
            "f_after": 48.754859924316406,
            "delta_f": 8.759998321533203
          },
          {
            "index": 2315,
            "f_before": 0.0,
            "f_after": 8.554186820983887,
            "delta_f": 8.554186820983887
          },
          {
            "index": 5130,
            "f_before": 0.0,
            "f_after": 8.430269241333008,
            "delta_f": 8.430269241333008
          },
          {
            "index": 2905,
            "f_before": 0.0,
            "f_after": 8.33416748046875,
            "delta_f": 8.33416748046875
          },
          {
            "index": 6170,
            "f_before": 0.0,
            "f_after": 8.253066062927246,
            "delta_f": 8.253066062927246
          },
          {
            "index": 365,
            "f_before": 0.0,
            "f_after": 7.9566121101379395,
            "delta_f": 7.9566121101379395
          },
          {
            "index": 1947,
            "f_before": 0.0,
            "f_after": 7.866241931915283,
            "delta_f": 7.866241931915283
          },
          {
            "index": 8954,
            "f_before": 0.0,
            "f_after": 7.559823989868164,
            "delta_f": 7.559823989868164
          },
          {
            "index": 6037,
            "f_before": 0.0,
            "f_after": 7.199949741363525,
            "delta_f": 7.199949741363525
          },
          {
            "index": 7209,
            "f_before": 0.0,
            "f_after": 7.041896820068359,
            "delta_f": 7.041896820068359
          },
          {
            "index": 6786,
            "f_before": 0.0,
            "f_after": 6.7201738357543945,
            "delta_f": 6.7201738357543945
          },
          {
            "index": 4530,
            "f_before": 0.0,
            "f_after": 6.476768493652344,
            "delta_f": 6.476768493652344
          },
          {
            "index": 3207,
            "f_before": 0.0,
            "f_after": 6.26442813873291,
            "delta_f": 6.26442813873291
          },
          {
            "index": 719,
            "f_before": 0.0,
            "f_after": 6.054680347442627,
            "delta_f": 6.054680347442627
          }
        ],
        "k": 16
      },
      "output": {
        "before": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nThis script demonstrates how to use the NVIDIA CUDA toolkit to implement\na basic parallel processing model.\n\n**Key Concepts:**",
        "after": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#\n\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import Module, functional as F\nfrom torch.optim import Adam\nfrom torch.nn.functional import softmax\n\nclass Model"
      }
    },
    "hook_layer_idx_same": {
      "hook_layer_idx": 12,
      "feature_stats": {
        "indices": [
          2,
          0,
          6770,
          6328,
          4282,
          2950,
          8978,
          5991,
          6033,
          4546,
          9169
        ],
        "f_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 8,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 10,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 4,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 15,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 12,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 3,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 9,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 1,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 11,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 5,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 7,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 13,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 0,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 2,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 6,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 14,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          }
        ],
        "k": 16
      },
      "output": {
        "before": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and limitations.\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import softmax\n\nclass Attention(nn.Module):\n    def __init",
        "after": "# Copyright (c) 2019-2021, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#\n# See the License for details.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom typing import List, Optional, NamedTuple\n\nfrom .utils import *\n\n"
      }
    }
  }
}