{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 8,
  "command": "main.py experiment.use_multi_contrast=true sae.loss_option=2 sae.loss_module=option2_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.05 sae.alpha_concept.harm=0.05 sae.alpha_concept.struct=0.05 sae.use_l0=true sae.l0_coeff=0.0009132649020605174 sae.role_sep_coeff=0.0035 sae.layer_idx=8 experiment.layer_sweep=[8] experiment.strength_sweep=[15.0] paths.logs_root=experimentLog/layer_sweep",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0009132649020605174,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.05,
      "harm": 0.05,
      "struct": 0.05
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.0035
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      8
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "code",
    "feature_idx": 0,
    "strength": 15.0,
    "hook_layer_idx": 7
  },
  "prompt": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\n",
  "output": {
    "before": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .Image import Image\n\n__all__ = [\n    \"SaliencyMap\",\n    \"DeepDream\",\n    \"GradCam\",\n    \"Weights\",\n    \"Base\",\n    \"ClassActivationMapping\",\n    \"",
    "after": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .ObjectDetection import ObjectDetection\nfrom .YOLOv3 import YOLOv3\nfrom .Vision import Vision\nfrom .DeepLab import DeepLab\nfrom .ImageNet import ImageNet\nfrom .FastText import FastText\n"
  },
  "feature_stats": {
    "indices": [
      0,
      2,
      569,
      8995,
      1,
      3493,
      2779,
      1670,
      7489,
      5428,
      5963
    ],
    "f_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      17.017242431640625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      0.0,
      3.1829073429107666,
      0.5275411009788513,
      0.1032082736492157,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.45626479387283325,
      0.0
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 3.898901983863674,
    "train_mean_l2": 2.7101913648620246,
    "train_mean_l1": 1.4800856967270375,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251129-081956/feature_std_layer_8.html",
    "mean_std": 0.39236578345298767,
    "max_std": 33.38655471801758
  },
  "hook_comparison": {
    "hook_layer_idx_minus1": {
      "hook_layer_idx": 7,
      "feature_stats": {
        "indices": [
          0,
          2,
          569,
          8995,
          1,
          3493,
          2779,
          1670,
          7489,
          5428,
          5963
        ],
        "f_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          17.017242431640625,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          0.0,
          3.1829073429107666,
          0.5275411009788513,
          0.1032082736492157,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.45626479387283325,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 4900,
            "f_before": 23.753681182861328,
            "f_after": 45.86259078979492,
            "delta_f": 22.108909606933594
          },
          {
            "index": 1,
            "f_before": 17.017242431640625,
            "f_after": 0.0,
            "delta_f": -17.017242431640625
          },
          {
            "index": 6098,
            "f_before": 26.515310287475586,
            "f_after": 13.64130973815918,
            "delta_f": -12.874000549316406
          },
          {
            "index": 4635,
            "f_before": 10.365837097167969,
            "f_after": 20.47064971923828,
            "delta_f": 10.104812622070312
          },
          {
            "index": 8539,
            "f_before": 0.0,
            "f_after": 7.208261013031006,
            "delta_f": 7.208261013031006
          },
          {
            "index": 5261,
            "f_before": 7.620987415313721,
            "f_after": 14.105063438415527,
            "delta_f": 6.484076023101807
          },
          {
            "index": 5832,
            "f_before": 0.0,
            "f_after": 6.150143623352051,
            "delta_f": 6.150143623352051
          },
          {
            "index": 4877,
            "f_before": 0.0,
            "f_after": 5.023508548736572,
            "delta_f": 5.023508548736572
          },
          {
            "index": 5307,
            "f_before": 0.0,
            "f_after": 4.902997970581055,
            "delta_f": 4.902997970581055
          },
          {
            "index": 4015,
            "f_before": 8.573831558227539,
            "f_after": 13.442971229553223,
            "delta_f": 4.869139671325684
          },
          {
            "index": 4287,
            "f_before": 2.590644598007202,
            "f_after": 7.260826587677002,
            "delta_f": 4.6701819896698
          },
          {
            "index": 3332,
            "f_before": 0.0,
            "f_after": 3.8153178691864014,
            "delta_f": 3.8153178691864014
          },
          {
            "index": 1592,
            "f_before": 0.0,
            "f_after": 3.710940361022949,
            "delta_f": 3.710940361022949
          },
          {
            "index": 2534,
            "f_before": 0.0,
            "f_after": 3.6748435497283936,
            "delta_f": 3.6748435497283936
          },
          {
            "index": 625,
            "f_before": 0.0,
            "f_after": 3.3266916275024414,
            "delta_f": 3.3266916275024414
          },
          {
            "index": 7154,
            "f_before": 1.3990967273712158,
            "f_after": 4.702574253082275,
            "delta_f": 3.3034775257110596
          }
        ],
        "k": 16
      },
      "output": {
        "before": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .Image import Image\nfrom .Output import Output\nfrom .Visualization import Visualization\n\n__all__ = [\n    \"SaliencyMap\",\n    \"DeepDream\",\n    \"GradCam\",\n    \"Weights\",\n    \"",
        "after": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .utils import utils\nfrom .utils import get_default_settings\n\n# import tensorflow as tf\nimport numpy as np\n\nclass ImageClassifier:\n    \"\"\"\n    Image Classifier for classification tasks.\n\n    \"\"\"\n\n    def __init"
      }
    },
    "hook_layer_idx_same": {
      "hook_layer_idx": 8,
      "feature_stats": {
        "indices": [
          0,
          2,
          569,
          8995,
          1,
          3493,
          2779,
          1670,
          7489,
          5428,
          5963
        ],
        "f_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          17.017242431640625,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          17.017242431640625,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 8,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 10,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 4,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 15,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 12,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 3,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 9,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 1,
            "f_before": 17.017242431640625,
            "f_after": 17.017242431640625,
            "delta_f": 0.0
          },
          {
            "index": 11,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 5,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 7,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 13,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 0,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 2,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 6,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 14,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          }
        ],
        "k": 16
      },
      "output": {
        "before": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .Visualizations import Visualizations\nfrom .utils import utils\n\nclass ImageClassifier:\n    \"\"\"\n    A class for image classification using various saliency-based methods.\n    \"\"\"\n\n    def __init__(self, model, device",
        "after": "from .SaliencyMap import SaliencyMap\nfrom .DeepDream import DeepDream\nfrom .GradCam import GradCam\nfrom .Weights import Weights\nfrom .Base import Base\nfrom .ClassActivationMapping import ClassActivationMapping\nfrom .Visualization import Visualization\nfrom .Tensors import Tensors\n\nfrom typing import List\nfrom PIL import Image\n\ndef get_activation_map(model, input_tensor):\n    \"\"\"\n    Get activation map for a given model."
      }
    }
  }
}