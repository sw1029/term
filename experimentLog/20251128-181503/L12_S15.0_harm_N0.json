{
  "model_name": "google/gemma-2-2b-it",
  "layer_idx": 12,
  "command": "python main.py experiment.use_multi_contrast=true sae.loss_option=2 sae.loss_module=option2_loss sae.guidance_method=contrastive sae.guidance_coeff=1.0 sae.alpha_concept.code=0.08 sae.alpha_concept.harm=0.01 sae.alpha_concept.struct=0.0 sae.use_l0=true sae.l0_coeff=0.0012084886699870719 sae.role_sep_coeff=0.0045000000000000005",
  "sae": {
    "input_dim": 2304,
    "sae_dim": 9216,
    "fixed_v_cnt": 3,
    "batch_size": 3,
    "epochs": 2,
    "max_steps": 2000,
    "l1_coeff": 0.005,
    "l0_coeff": 0.0012084886699870719,
    "use_l0": true,
    "concept_samples_per_label": 100,
    "loss_option": 2,
    "loss_module": "option2_loss",
    "concept_feature_indices": {
      "code": 0,
      "harm": 1,
      "struct": 2
    },
    "alpha_concept": {
      "code": 0.08,
      "harm": 0.01,
      "struct": 0.0
    },
    "positive_targets": {
      "code": 1,
      "harm": 1,
      "struct": 1
    },
    "guidance_method": "contrastive",
    "guidance_margin": 0.0,
    "guidance_coeff": 1.0,
    "guidance_mse_pos_value": 1.0,
    "guidance_mse_neg_value": 0.0,
    "jumprelu_bandwidth": 0.001,
    "jumprelu_init_threshold": 0.001,
    "role_sep_coeff": 0.0045000000000000005
  },
  "gnn": {
    "use_gnn": true,
    "top_k": 10
  },
  "experiment": {
    "device": "cuda",
    "dataset_name": "wikitext",
    "dataset_config": "wikitext-2-raw-v1",
    "use_multi_contrast": true,
    "num_steering_samples_per_label": 10,
    "top_k_for_plot": 10,
    "layer_sweep": [
      12
    ],
    "strength_sweep": [
      15.0
    ]
  },
  "steering": {
    "label": "harm",
    "feature_idx": 1,
    "strength": 15.0,
    "hook_layer_idx": 11
  },
  "prompt": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(",
  "output": {
    "before": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\r\n        super(MeanShift, self).__init__(3, 3, kernel_size=1)\r\n        std = torch.Tensor(rgb_std)\r\n        self.weight.data = torch.eye(3).view(3, 3, 1, 1)\r\n        self.weight.data.div_(std.view(3, 1, 1, 1))\r\n        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)\r\n        self.bias.data.div_(std)\r\n        self.requires_grad = False\r\n\r\nclass BasicBlock(nn.Sequential):\r\n    def __init__(\r\n        self, in_channels, out_channels, kernel_size, stride=1, bias=False,\r\n        bn=True, act=nn.ReLU(True)):\r\n\r\n        m = [nn.Conv2d(\r\n            in_channels, out_channels, kernel_size,\r\n            padding=(kernel_size//2), stride=stride, bias=bias)\r\n        ]\r\n        if bn: m.append(nn.BatchNorm2d(out_channels))\r\n        if act is not None: m.append(act)\r\n        super(BasicBlock, self).__init__(*m)\r\n\r\nclass ResBlock(nn.Module):\r\n    def __init__(\r\n        self, conv, n_feats, kernel_size,\r\n        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\r\n\r\n        super(ResBlock, self).__init__()\r\n        m = []\r\n        for i in range(2):\r\n            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\r\n            if bn: m.append(nn.BatchNorm2d(n_feats))\r\n            if i == 0: m.append(act)\r\n\r\n        self.body = nn.Sequential(*m)\r\n        self.res_scale = res_scale\r\n\r\n    def forward(self, x):\r\n        res = self.body(x).mul(self.res_scale)\r\n        res += x\r\n\r\n        return res\r\n\r\n\r\nclass Upsampler(nn.Sequential):\r\n    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\r\n\r\n        m = []\r\n        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\r\n            for _ in range(int(math.log(scale, 2))):\r\n                m.append(conv(n_feats, 4 * n_feats, 3, bias))\r\n                m.append(nn.PixelShuffle(2))\r\n                if bn: m.append(nn.BatchNorm2d(n_feats))\r\n\r\n                if act == 'relu':\r\n                    m.append(nn.ReLU(True))\r\n                elif act == 'prelu':\r\n                    m.append(nn.PReLU(n_feats))\r\n\r\n        elif scale == 3:\r\n            m.append(conv(n_feats, 9 * n_feats, 3, bias))\r\n            m.append(nn.PixelShuffle(3))\r\n            if bn: m.append(nn.BatchNorm2d(n_feats))\r\n\r\n            if act == 'relu':\r\n                m.append(nn.ReLU(True))\r\n            elif act == 'prelu':\r\n                m.append(nn.PReLU(n_feats))\r\n        else:\r\n            raise NotImplementedError\r\n\r\n        super(Upsampler, self).__init__(*m)\n",
    "after": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\r\n        super(MeanShift, self).__init__(3, 3, kernel_size=1)\r\n        std = torch.Tensor(rgb_std)\r\n        self.weight.data = torch.eye(3).view(3, 3, 1, 1)\r\n        self.weight.data.div_(std.view(3, 1, 1, 1))\r\n        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)\r\n        self.bias.data.div_(std)\r\n        self.requires_grad = False\r\n\r\nclass BasicBlock(nn.Sequential):\r\n    def __init__(\r\n        self, in_channels, out_channels, kernel_size, stride=1, bias=False,\r\n        bn=True, act=nn.ReLU(True)):\r\n\r\n        m = [nn.Conv2d(\r\n            in_channels, out_channels, kernel_size,\r\n            padding=(kernel_size//2), stride=stride, bias=bias)\r\n        ]\r\n        if bn: m.append(nn.BatchNorm2d(out_channels))\r\n        if act is not None: m.append(act)\r\n        super(BasicBlock, self).__init__(*m)\r\n\r\nclass ResBlock(nn.Module):\r\n    def __init__(\r\n        self, conv, n_feats, kernel_size,\r\n        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\r\n\r\n        super(ResBlock, self).__init__()\r\n        m = []\r\n        for i in range(2):\r\n            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\r\n            if bn: m.append(nn.BatchNorm2d(n_feats))\r\n            if i == 0: m.append(act)\r\n\r\n        self.body = nn.Sequential(*m)\r\n        self.res_scale = res_scale\r\n\r\n    def forward(self, x):\r\n        res = self.body(x).mul(self.res_scale)\r\n        res += x\r\n\r\n        return res\r\n\r\n\r\nclass Upsampler(nn.Sequential):\r\n    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\r\n\r\n        m = []\r\n        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\r\n            for _ in range(int(math.log(scale, 2))):\r\n                m.append(conv(n_feats, 4 * n_feats, 3, bias))\r\n                m.append(nn.PixelShuffle(2))\r\n                if bn: m.append(nn.BatchNorm2d(n_feats))\r\n\r\n                if act == 'relu':\r\n                    m.append(nn.ReLU(True))\r\n                elif act == 'prelu':\r\n                    m.append(nn.PReLU(n_feats))\r\n\r\n        elif scale == 3:\r\n            m.append(conv(n_feats, 9 * n_feats, 3, bias))\r\n            m.append(nn.PixelShuffle(3))\r\n            if bn: m.append(nn.BatchNorm2d(n_feats))\r\n\r\n            if act == 'relu':\r\n                m.append(nn.ReLU(True))\r\n            elif act == 'prelu':\r\n                m.append(nn.PReLU(n_feats))\r\n        else:\r\n            raise NotImplementedError\r\n\r\n        super(Upsampler, self).__init__(*m) \r\n        \r\n        return self\r\n\r\n\r\n# This is a bad idea.\r\n# I will not tell you anything.\r\n# I will not tell you what you want to do.\r\n# This is a bad idea"
  },
  "feature_stats": {
    "indices": [
      1,
      2242,
      1201,
      5731,
      1829,
      820,
      1563,
      6301,
      4446,
      3117,
      8089
    ],
    "f_before": [
      22.16903305053711,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "f_after": [
      28.35457992553711,
      51.79043960571289,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      1.3555512428283691
    ],
    "g_before": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "g_after": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "num_batches_for_stats": 10
  },
  "loss_summary": {
    "train_mean_loss": 7.146925932589919,
    "train_mean_l2": 6.325844486102461,
    "train_mean_l1": 3.0792910116314887,
    "num_steps": 2000,
    "num_batches": 2000
  },
  "feature_std_summary": {
    "plot_path": "outputs/plots/20251128-181503/feature_std_layer_12.html",
    "mean_std": 1.673189401626587,
    "max_std": 71.08536529541016
  },
  "hook_comparison": {
    "hook_layer_idx_minus1": {
      "hook_layer_idx": 11,
      "feature_stats": {
        "indices": [
          1,
          2242,
          1201,
          5731,
          1829,
          820,
          1563,
          6301,
          4446,
          3117,
          8089
        ],
        "f_before": [
          22.16903305053711,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          28.35457992553711,
          51.79043960571289,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          1.3555512428283691
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 0,
            "f_before": 143.96719360351562,
            "f_after": 82.44408416748047,
            "delta_f": -61.523109436035156
          },
          {
            "index": 2242,
            "f_before": 0.0,
            "f_after": 51.79043960571289,
            "delta_f": 51.79043960571289
          },
          {
            "index": 2291,
            "f_before": 0.0,
            "f_after": 34.35653305053711,
            "delta_f": 34.35653305053711
          },
          {
            "index": 3569,
            "f_before": 147.0191650390625,
            "f_after": 178.61659240722656,
            "delta_f": 31.597427368164062
          },
          {
            "index": 4463,
            "f_before": 15.286067008972168,
            "f_after": 0.0,
            "delta_f": -15.286067008972168
          },
          {
            "index": 995,
            "f_before": 12.716343879699707,
            "f_after": 26.824581146240234,
            "delta_f": 14.108237266540527
          },
          {
            "index": 1,
            "f_before": 22.16903305053711,
            "f_after": 28.35457992553711,
            "delta_f": 6.185546875
          },
          {
            "index": 5609,
            "f_before": 0.011559674516320229,
            "f_after": 4.41121768951416,
            "delta_f": 4.39965801499784
          },
          {
            "index": 4237,
            "f_before": 0.0,
            "f_after": 3.336395263671875,
            "delta_f": 3.336395263671875
          },
          {
            "index": 8121,
            "f_before": 0.0687761977314949,
            "f_after": 3.233869791030884,
            "delta_f": 3.165093593299389
          },
          {
            "index": 7834,
            "f_before": 0.005299034528434277,
            "f_after": 3.070262908935547,
            "delta_f": 3.0649638744071126
          },
          {
            "index": 7922,
            "f_before": 0.0,
            "f_after": 2.9982924461364746,
            "delta_f": 2.9982924461364746
          },
          {
            "index": 8213,
            "f_before": 0.0,
            "f_after": 2.925659656524658,
            "delta_f": 2.925659656524658
          },
          {
            "index": 8103,
            "f_before": 0.0,
            "f_after": 2.890540838241577,
            "delta_f": 2.890540838241577
          },
          {
            "index": 7817,
            "f_before": 0.0,
            "f_after": 2.8547897338867188,
            "delta_f": 2.8547897338867188
          },
          {
            "index": 8231,
            "f_before": 0.0,
            "f_after": 2.804415464401245,
            "delta_f": 2.804415464401245
          }
        ],
        "k": 16
      },
      "output": {
        "before": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0.485, 0.456, 0.406), rgb_std=(0.229, 0.224, 0.225), kernel_size=(3,",
        "after": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0,0,0)): # mean shift is an action to shift the colors of the image\r\n        self.rgb_range = rgb_range # RGB range is a function of the user, this is not a function of me, I"
      }
    },
    "hook_layer_idx_same": {
      "hook_layer_idx": 12,
      "feature_stats": {
        "indices": [
          1,
          2242,
          1201,
          5731,
          1829,
          820,
          1563,
          6301,
          4446,
          3117,
          8089
        ],
        "f_before": [
          22.16903305053711,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "f_after": [
          22.16903305053711,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_before": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ],
        "g_after": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "top_activated_features": {
        "features": [
          {
            "index": 8,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 10,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 4,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 15,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 12,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 3,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 9,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 1,
            "f_before": 22.16903305053711,
            "f_after": 22.16903305053711,
            "delta_f": 0.0
          },
          {
            "index": 11,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 5,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 7,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 13,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 0,
            "f_before": 143.96719360351562,
            "f_after": 143.96719360351562,
            "delta_f": 0.0
          },
          {
            "index": 2,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 6,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          },
          {
            "index": 14,
            "f_before": 0.0,
            "f_after": 0.0,
            "delta_f": 0.0
          }
        ],
        "k": 16
      },
      "output": {
        "before": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0,0,0), rgb_std=(1,1,1), kernel_size=3, bias=True, padding=0):\r\n        super(MeanShift, self).__init__(kernel_size, padding, bias=bias",
        "after": "import math\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nfrom torch.autograd import Variable\r\n\r\ndef default_conv(in_channels, out_channels, kernel_size, bias=True):\r\n    return nn.Conv2d(\r\n        in_channels, out_channels, kernel_size,\r\n        padding=(kernel_size//2), bias=bias)\r\n\r\nclass MeanShift(nn.Conv2d):\r\n    def __init__(self, rgb_range, rgb_mean=(0.0, 0.0), bias=False):\r\n        if rgb_mean == None:\r\n            print(\"Please enter a valid mean for this action, I can't help you.\") \r\n        else:\r\n            print"
      }
    }
  }
}